[
  {
    "url": "https://docs.godspeed.systems/markdown-page",
    "content": "Title: Markdown page example  Markdown page example. Content: You don't need React to write simple standalone pages.",
    "title": "Markdown page example  Markdown page example",
    "tokens": 11,
    "length": 54
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/tutorial/learning-module/beginner-track",
    "content": "Title: Learning Module - Level 1 [Beginner Track]. Content: March 26, 2023  · 3 min read",
    "title": "Learning Module - Level 1 [Beginner Track]",
    "tokens": 10,
    "length": 28
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/tutorial/learning-module/intermediate-track",
    "content": "Title: Learning Module - Level 2 [Intermediate Track]. Content: March 27, 2023  · 3 min read",
    "title": "Learning Module - Level 2 [Intermediate Track]",
    "tokens": 10,
    "length": 28
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/tutorial/learning-module/advanced-track",
    "content": "Title: Learning Module - Level 3 [Advanced Track]. Content: March 28, 2023  · One min read",
    "title": "Learning Module - Level 3 [Advanced Track]",
    "tokens": 10,
    "length": 30
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/archive",
    "content": "Title: Archive  Archive. Content: Archive",
    "title": "Archive  Archive",
    "tokens": 2,
    "length": 7
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/archive",
    "content": "Title: Archive  2023. Content: March 26, 2023 - Learning Module - Level 1 [Beginner Track]March 27, 2023 - Learning Module - Level 2 [Intermediate Track]March 28, 2023 - Learning Module - Level 3 [Advanced Track]",
    "title": "Archive  2023",
    "tokens": 47,
    "length": 181
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/learning-module/advanced-track",
    "content": "Title: Learning Module - Level 3 [Advanced Track]  Learning Module - Level 3 [Advanced Track]. Content: March 28, 2023  · One min read",
    "title": "Learning Module - Level 3 [Advanced Track]  Learning Module - Level 3 [Advanced Track]",
    "tokens": 10,
    "length": 30
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/learning-module/beginner-track",
    "content": "Title: Learning Module - Level 1 [Beginner Track]  Learning Module - Level 1 [Beginner Track]. Content: March 26, 2023  · 3 min read",
    "title": "Learning Module - Level 1 [Beginner Track]  Learning Module - Level 1 [Beginner Track]",
    "tokens": 10,
    "length": 28
  },
  {
    "url": "https://docs.godspeed.systems/tutorial/learning-module/intermediate-track",
    "content": "Title: Learning Module - Level 2 [Intermediate Track]  Learning Module - Level 2 [Intermediate Track]. Content: March 27, 2023  · 3 min read",
    "title": "Learning Module - Level 2 [Intermediate Track]  Learning Module - Level 2 [Intermediate Track]",
    "tokens": 10,
    "length": 28
  },
  {
    "url": "https://docs.godspeed.systems/docs/",
    "content": "Title: Hello World!  Hello World!. Content:",
    "title": "Hello World!  Hello World!",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/communication/intro",
    "content": "Title: Introduction  Introduction. Content:",
    "title": "Introduction  Introduction",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/communication/intro#external-to-api-gateway",
    "content": "Title: Introduction  External to API gateway  ​. Content: External services will communicate with API gateway synchronously and will follow the request - response cycle.",
    "title": "Introduction  External to API gateway  ​",
    "tokens": 18,
    "length": 111
  },
  {
    "url": "https://docs.godspeed.systems/docs/communication/intro#microservices-communication",
    "content": "Title: Introduction  Microservices communication  ​. Content: Communication between microservices could either be synchronous or asynchronous. All synchronous communication will happen, either through HTTP or gRPC, via the service mesh (using proxy sidecar). Asynchronous communication will follow event-driven architecture (EDA) through messages/events. The event format will follow the CloudEvents specification (a standard open format.",
    "title": "Introduction  Microservices communication  ​",
    "tokens": 71,
    "length": 376
  },
  {
    "url": "https://docs.godspeed.systems/docs/communication/intro#triggered-workflows",
    "content": "Title: Introduction  Triggered workflows  ​. Content: A workflow is a serverless function which could be triggered by an event or a schedule, being listened to by ArgoEvents. Examples include AI/ML computation, CI/CD workflows, ETLs.",
    "title": "Introduction  Triggered workflows  ​",
    "tokens": 43,
    "length": 179
  },
  {
    "url": "https://docs.godspeed.systems/docs/communication/technology-used/intro",
    "content": "Title: Technologies used (Default)  Technologies used (Default). Content: Linkerd  (service mesh for sync communication)   Kafka with CloudEvents format messages  (Message bus for async communication)   Argo Events  (for listening to events from multiple sources and triggering workflows)",
    "title": "Technologies used (Default)  Technologies used (Default)",
    "tokens": 45,
    "length": 214
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API",
    "content": "Title: API specs  API specs. Content:",
    "title": "API specs  API specs",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#getting-started",
    "content": "Title: API specs  Getting Started ​. Content:",
    "title": "API specs  Getting Started ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#importing-crud-module-to-your-project",
    "content": "Title: API specs Getting Started ​ Importing CRUD module to your project ​. Content: Make sure that you have appropriate  model specifications  in your project. The CLI will guide the user for the project specific CRUD setup.Importing your project in a microservice ​ When you start Godspeed microservice with your project, it will [autogenerate the REST, Socket and Message bus endpoints] for the functions exported by your project. You can customize your exports in  config/global-exports.yaml  file. --> It will export the CRUD functions  It will also export any other functions you have in your project structure.",
    "title": "API specs Getting Started ​ Importing CRUD module to your project ​",
    "tokens": 115,
    "length": 532
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#universal-crud-api",
    "content": "Title: API specs Getting Started ​ Universal CRUD API ​. Content: The query interface of these functions is generic, and vendor independent. Yet, there are ways to run SQL and native queries on every vendor.        //SQL query to Postgres        godspeed.find({          _sql_query: “select * from….”,          source: “postgres” //Can be any configured database which supports SQL        })              //Mongodb query        godspeed.findOrCreate({          _type: “article”, //Godspeed uses the terminology _type for entity type. It translates to collection/index/table names automatically in its pluralized form.          _native_query : { tags: [\"technology\", \"low-code\"] },          source: “mongodb”        })                            All of the functions below can be run in any combination as a function DAG.",
    "title": "API specs Getting Started ​ Universal CRUD API ​",
    "tokens": 285,
    "length": 754
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#crud-api-available-functions",
    "content": "Title: API specs  CRUD API available functions ​. Content:",
    "title": "API specs  CRUD API available functions ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#create",
    "content": "Title: API specs CRUD API available functions ​ Create ​. Content: Saves the entity in the target database.Params ​        _type: String //One of the types from the model        _id: String | Number //Optional. If not given, a UUID is autogenerated.        body: Object //A body as per the defined fields of the entity. This will be validated against the respective model                      Example request      {        '_type': 'borrower_profile',        'body': {          'english': {            'name': 'Deepti'          },          'hindi': {            'name': 'दीप्ति'          },          pan: 'AKJPG810**',          pincode: 176057,          product: { //While creating an entity, it can also be linked to an existing entity, by their valid relationship            _id: 5 //Link to the product with id 5          }        }      }                     Response ​ On Success ​        _id: id as specified in the request        _type: type of the entity as sent in the request        status: status code as per the standards        message: Explanatory message                     On failure ​        //A GSError object        status: status code, extending the standards        message: Error message        stack: Error stack        errors: [GSError]",
    "title": "API specs CRUD API available functions ​ Create ​",
    "tokens": 533,
    "length": 1194
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#update",
    "content": "Title: API specs CRUD API available functions ​ Update ​. Content: Params ​      _id: id of the entity field needs to be updated      _type: the type of the entity      update: the update instructions                      Update instructions follow the API specified  here   Example update instructions      {        _id: 'AVeawbnNW2vhiwtp9F2D',        _type: 'event',        update: {          set: {            title: 'Finding Common Ground',            x: [1, 2],            yString: ['Music']          },          push: {            x: 567,            yString: ['for', 'life']          },          addToSet: {            x: [567],            yString: ['for']          },          unset: [            'y'          ]        }      }                           Response ​ On Success ​        status: 201        message: Successfully updated        data:          _id: id as specified in the request          _type: type of the entity updated                     On failure ​        //A GSError object        status: status code, extending the standards        stack: Error stack        message: Error message        errors: [GSError]",
    "title": "API specs CRUD API available functions ​ Update ​",
    "tokens": 560,
    "length": 1066
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#delete",
    "content": "Title: API specs CRUD API available functions ​ Delete ​. Content: Deletes are cascading. Deleting an entity also removes its references (and any denormalized data) in other entities to which the entity is liked.Params ​      _id: id of the entity field needs to be updated      _type: the type of the entity                     Response ​ On Success ​        status: 204        message: Deleted successfully        data:           _id: id as specified in the request          _type: type of the entity as sent in the request                     On failure ​        //A GSError object        status: status code, extending the standards        stack: Error stack        message: Error message        errors: [GSError]",
    "title": "API specs CRUD API available functions ​ Delete ​",
    "tokens": 250,
    "length": 650
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#get-by-id",
    "content": "Title: API specs CRUD API available functions ​ Get by Id ​. Content: One can retrieve an entity of a given type by its _id.     // Fetch borrower profile with selected fields and also some fields(GMV) from its relationship            {        _type: 'borrower_profile',        _id: 'AVeuJeQ9jGz7t7QfUg_M',        langs: ['hindi']        returnData: {          name: 1, //multi lingual field in DB model spec          mid: 1,          linkedProduct: {            name: 1          }        }      }            // Returns      {          \"message\": \"Successfully read borrower_profile\",          \"status\": 200,          \"data\": {              \"_type\": \"borrower_profile\",              \"_id\": \"AVeuJeQ9jGz7t7QfUg_M\",              \"data\": {                 'hindi': {                    'name': 'दीप्ति'                  },                  'mid': '87asdf87',                  'linkedProduct': {                    '_id': 5,                    '_type': 'product'                    'data': {                      'name': \"Existence\"                    }                  }              }          }      }                     Params ​      _type: type of the entity      _id: id of the entity      returnData: The data to return including the entity's own properties and those of its related entities.      langs: Optional. The retrieved data is to be brought only for these languages. Other language data will not be retrieved. By default, all language data is retrieved.                     Response ​ On Success ​        status: 200        data: the data including the id, type and the requested returnData        message: Successfully retrieved                     On failure ​        //A GSError object        status: status code, extending the standards        stack: Error stack        message: Error message        errors: [GSError]",
    "title": "API specs CRUD API available functions ​ Get by Id ​",
    "tokens": 908,
    "length": 1766
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#find",
    "content": "Title: API specs CRUD API available functions ​ Find ​. Content: Find entities matching specified criteria with pagination.     // Fetch borrower profile with selected fields and also some fields(GMV) from its relationship            {        _type: 'borrower_profile',        query: {          name: 'दीप्ति'        },        langs: ['hindi'],        returnData: {          name: 1, //multi lingual field in DB model spec          mid: 1,          linkedProduct: {            name: 1          }        }      }            // Returns      {          \"message\": \"Successfully read borrower_profile\",          \"status\": 200,          \"data\": {            \"count\" : 11,            \"data\": [                {                  \"_type\": \"borrower_profile\",                  \"_id\": \"AVeuJeQ9jGz7t7QfUg_M\",                  \"data\": {                    'hindi': {                        'name': 'दीप्ति'                      },                      'mid': '87asdf87',                      'linkedProduct': {                        '_id': 5,                        '_type': 'product'                        'data': {                          'name': \"Existence\"                        }                      }                  }              }            ]          },            }                     Params ​        _type: A single entity type or multiple types in an array        returnData: The data to return (same as get by id above)        query: The matching criteria in GS syntax        _sql_query: The matching criteria in SQL format        _native_query: The matching criteria in native DB format        size: The number of matching results wanted        offset: The offset for pagination        langs: The languages in which data is to be retrieved                      Note: among the query, _sql_query, _native_query clauses, only one of them must be present, else an error is raised Response ​ On Success ​        status: 200        data: matched entities with their respective id, type and returnData        message: Successfully retrieved                     On failure ​        //A GSError object        status: status code, extending the standards        message: Telling what happened        errors: List of GSError objects explaining errors in details",
    "title": "API specs CRUD API available functions ​ Find ​",
    "tokens": 1137,
    "length": 2198
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#search",
    "content": "Title: API specs CRUD API available functions ​ Search ​. Content: It is an extension of 'find' with where clause including additional text search capabilities like match_phrase and autosuggest. Currently works with Elasticsearch backend.Request ​        _type: A single entity type or multiple types in an array        returnData: The data to return (same as get by id)        query: The matching criteria in GS syntax        _native_query: Elasticsearch API        _sql_query: Elasticsearch supported SQL syntax        size: The number of matching results wanted        offset: The offset for pagination        langs: The languages in which data is to be retrieved                           Response ​ On Success ​        _id: id as specified in the request        _type: type of the entity as sent in the request        status: status code as per the standards                     On failure ​        //A GSError object        status: status code, extending the standards        message: Telling what happened        errors: List of GSError objects explaining errors in details",
    "title": "API specs CRUD API available functions ​ Search ​",
    "tokens": 335,
    "length": 1013
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation",
    "content": "Title: Data Federation  Data Federation. Content:",
    "title": "Data Federation  Data Federation",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation#introduction",
    "content": "Title: Data Federation  Introduction ​. Content: Godspeed has in-built support for federating data from multiple sources like database, search engine, warehouse, third party API & another microservice in both sync and async manner. One can execute multiple queries to configured sources within a single query Read only, write only or mixed. i.e. a single instruction can contain a combination of multiple reads and writes.  Non transactional or as a distributed transaction.  Retry logic, circuit breaker.  Notes  In case there are multiple independent transactions in the call or queries of any nature, and one is ok for some to fail but some not, then one can specify  ignoreError:true  in those calls.   It is recommended that the developer defines all the API schema on server side when going to production. They should export native functions like federate(shown below) as API contract with caution.",
    "title": "Data Federation  Introduction ​",
    "tokens": 175,
    "length": 855
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation#the-uses-of-data-federation-can-be",
    "content": "Title: Data Federation Introduction ​ The uses of data federation can be ​. Content: Dedicated Backend For Frontend (BFF) service  As part of a custom Godspeed service.",
    "title": "Data Federation Introduction ​ The uses of data federation can be ​",
    "tokens": 23,
    "length": 83
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation#sample-instruction",
    "content": "Title: Data Federation Introduction ​ Sample instruction ​. Content: POST /api/v1/${domain}/${microserviceName}/federate      {          'searchResponse': { //The response of the query will come under this key in response from the service              \"instruction\": “findAll”, //This instruction has been declared on the server side in the API schema              \"params”: {                  query_gs: {                      “match_phrase”: {“borrower.city.name”: “patna”},                      “exists”: “pincode”,                      “anyOneOf”: [                          {range: {annualIncome”: {\"gte\": 1000000}}},                          {“match”: {“hasOwnHouse”: true}},                         ]                  }              }          },                'saveBorrowerProfileResponse': {              “instruction”: “saveBorrowersProfile”,              “ignoreError”: true,              \"retry\": {                  \"count\": 3,                  \"timeout\": 200 //milliseconds              },              \"params”: {                  “name”: 1,                  “pan”: “asdfadsf”              }          }      }",
    "title": "Data Federation Introduction ​ Sample instruction ​",
    "tokens": 664,
    "length": 1054
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro",
    "content": "Title: CRUD Module Introduction  CRUD Module Introduction. Content:",
    "title": "CRUD Module Introduction  CRUD Module Introduction",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#single-universal-api-for-multiple-database",
    "content": "Title: CRUD Module Introduction  Single Universal API for multiple database ​. Content: In Godspeed, one can query multiple databases through single API layer.\nThis generic API decouples The application code from underlying DB.  Common params      request:              ds //datasource              {queryType} : // can be one of  query_sql, query_native, query_gsl                          { actual query}                  response:              status_code              message              _score //total score              result [                    {_score://indivual score for each match                     data : { fields value corresponding to returnData }                    }                    ]                                   A sample query  \nThis query will be sent to the underlying primary database, which is typically a transactional store.       /** The default datasource for executing queries is the         * primary datastore (as per the configuration) unless specifically mentioned in the         * query with the 'source' argument.         */              /api/v2/search        {          type: 'user',          where: {            name: \"ayush\" //Executes an exact match          }        }                     One may want to leverage Elasticsearch for text search or faster reads.\nIf setup as secondary datastore, it will be synced with the primary\nas per the data model configuration.\nThe following query is targetted specifically to Elasticsearch.\nBut any supported database can be set as secondary, not just Elasticsearch.       /api/v2/search        {          source: 'elasticsearch', //can be 'cache', 'mongodb' or an in memory object etc.          query: {            type: 'user',            where: {              age: {                gte: 'ayush'              },              'city.name': {                matchPhrase: 'delhi' //Executes a text search              }            }          }        }",
    "title": "CRUD Module Introduction  Single Universal API for multiple database ​",
    "tokens": 852,
    "length": 1852
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#support-for-native-and-sql-queries",
    "content": "Title: CRUD Module Introduction  Support for native and SQL queries ​. Content: A developer is not limited to use only the generic interface. Infact Godspeed design allows developer to execute SQL queries and native queries both.\nIn case,source is cache or in-memory object store, then the native query or SQL query may or may not be available as the constraint imposed by underlying cache or in-memory object store.       /api/v2/search        {           source: “postgres” //Can be any configured database and supporting SQL          _sql_query: {                        'select * from user where age > 8 and name='Ayush'                      }              }              //OR to a secondary datastore        {          source: 'mongoDB',          _native_query : { tags: [\"technology\", \"low-code\"] },              }",
    "title": "CRUD Module Introduction  Support for native and SQL queries ​",
    "tokens": 291,
    "length": 740
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#relationship-awareness",
    "content": "Title: CRUD Module Introduction  Relationship awareness ​. Content: This API is relationship aware, even with NoSQL stores like Elasticsearch and MongoDB. Based on the relationship definitions,\nthe following is managed by this library out of the box. (No code) Bidirectional relationship maintenance. i.e. A single API call establishes relationships from A to B and B to A  It is also possible to configure storage of foreign keys only on one side, yet traverse from both sides. (Similar to Graph databases)    Denormalisation support is also provided out of the box, across all NoSQL stores support. i.e. MongoDB and Elasticsearch      //An example of many to many relationships. An Event has multiple speakers, and a speaker can speak in many events.      speakers <> events      [event] <> [speaker]      Don't store foreign key in speaker //Means only event will have the foreign key of speaker stored in it.            //For denormalization, the following rule in schema/denormalisation.txt stores the names of speakers in the event      [event]      speakers{name} //Whenever a speaker and event are linked, the speaker's name is automatically copied to the event along with the foreign key (speaker's id).                     //When unlinked, the name of the speaker is also removed along with the foreign key.                     //When the name of the speaker is changed, the new name reflects across all the events where that speaker is linked.",
    "title": "CRUD Module Introduction  Relationship awareness ​",
    "tokens": 370,
    "length": 1386
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#batching-of-queries",
    "content": "Title: CRUD Module Introduction  Batching of queries ​. Content: In order to optimize the performance of databases and the microservices, the framework allows to  batch the CRUD queries, per database  (by query category, i.e. get, create, find, delete, update)\n.  All queries of one type and to one DB (irrespective of their arguments like entity type, where clause) are batched by default, unless specified otherwise.    Queries and their reponse are multiplexed and demultiplexed internally so that the client never knows what else went in a batch.    All queries including transactions are batched together internally in same sequence as arrival of the queries    Error in one query does not affect the result of the other queries. The callers of each get their respective success or failure response as if they had executed the query without any batching in the first place.     In config/collect.toml      //Project level setting for batching.      //Specify the batch size or timeout, for every query category            noBatch = false // Can be set to true, in which case batching will not happen by default.      [batchSizes]        find = 20        create = 20        get = 20        update = 20        delete = 20      [timeouts] //in milli seconds        find = 20        create = 20        get = 20        update = 20        delete = 20            When invoking through JS        gs.find.collect() //Executes with batching            //When exposing the function externally through a microservice, it is batched by default        gs.find({          query: {}        })                      And, batching is optional        //When invoking through JS, don't add .collect() to the CRUD function calls        gs.find()        //When exposing the function externally through a microservice, you can add noBatch: true        gs.find({          noBatch: true        }                      You can set default setting of the API to noBatch. In that case you will need to say  noBatch: false  exlicitly to batch a kind of query.",
    "title": "CRUD Module Introduction  Batching of queries ​",
    "tokens": 658,
    "length": 1968
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#transactions",
    "content": "Title: CRUD Module Introduction  Transactions ​. Content: When writing to a datasource which support transactions, all writes are always transactions.\nA single write allows to update multiple entities/rows.",
    "title": "CRUD Module Introduction  Transactions ​",
    "tokens": 28,
    "length": 148
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#dual-writes",
    "content": "Title: CRUD Module Introduction  Dual writes ​. Content: Developer does not need to worry about dual writes\nfor data syncing across multiple types of databases used in the app.Main featues of the dual writes are following: Just configure the federated DB model, write only to your primary. Your secondary databases will get eventually synced, as per your model settings.  It is intended for future to also handle transactions spread across multiple databases via Saga pattern.",
    "title": "CRUD Module Introduction  Dual writes ​",
    "tokens": 81,
    "length": 419
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup",
    "content": "Title: Model Setup  Model Setup. Content:",
    "title": "Model Setup  Model Setup",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#introduction",
    "content": "Title: Model Setup  Introduction ​. Content: Based on scaffolding of microservice project,\nthere will be right place to put project configurations for each module and also common settings.\nThe model configuration discussed in this document is a part of the project configuration.The configurations for model/data setup cover not only the entity model with relationships\nbut also all the different databases the project will use, how the data syncs between them\nand the Single Source of Truth settings for all entities.",
    "title": "Model Setup  Introduction ​",
    "tokens": 89,
    "length": 473
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#setup-of-the-dbs",
    "content": "Title: Model Setup  Setup of the DBs ​. Content: In the configuration/databases/{db.toml} files there will be settings for respective dbs that are included in this project.     //elasticsearch.toml      name = elasticsearch      maxConnections = 200      apiVersion = '7.4'      requestTimeout = 90000      node = 'http://localhost:9200'      sniffOnStart = true",
    "title": "Model Setup  Setup of the DBs ​",
    "tokens": 107,
    "length": 313
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#entities-and-model",
    "content": "Title: Model Setup  Entities and model  ​. Content: We use the word entities (similar to rows in MySQL, or nodes in a Graph) for\nrefering to individual data points of a particular type.\nEach entity has an id, type, fields like text, date etc. and relationships (akin to foreign keys).\nThe configurations of a field are all declared in one file.Each entity is stored in a separate table/index/colelction depending on the database used.\nThe name of that will be pluralized and autogenerated as {entity._type + ‘s’}For example, for type video, the collection/index/table name will be videos The simple fields of an entity and their settings are defined in  configFolder/schema/entities/{entityType}.toml As per the definitions, the schema in the datastores (ES or PG) is generated from here. The migrations also make use of these definitions, to run.Here is a sample config for a sample entity type in TOML format     sstDB = postgres //The main DB for this entity as its SST.      All writes will happen here first, and later the other DBs      will get eventually (automatically) synced through CDC mechanism.            [name]      type = 'String'      enum = ['value1', 'value2']      multiLingual = true      [name.postgres]      sortable = true //Will create index for this to sort on, in PG      [name.elasticsearch] //Create appropriate indices in ES for      the queries we wish to do on this field      autoSuggestion = true      exactMatch = true      sortable = true                     Corresponding document of an Event, when returned from the\nAPI will look like shown below. It does not matter\nwhich underlying database the information is being fetched from.     {        \"_type\": \"person\",        \"_id\": \"294464\",        \"_version\": 4,        \"data\": {          \"tibetan\": {            \"name\": \"ཆེན་པོ་མཆོག་ནས་ནང་ཆོས་ངོ་སྤྲོད་སྩལ་།\",          },          \"english\": {            \"name\": \"His Holiness the Fourteenth Dalai Lama.\",          }        }      }                     The data model you set is used to generate the appropriate schema in respective databases.",
    "title": "Model Setup  Entities and model  ​",
    "tokens": 759,
    "length": 2028
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#relationships",
    "content": "Title: Model Setup  Relationships  ​. Content: You must define the relationships of your data model in  configFolder/schema/relationships.txt  It is compulsory to maintain relationship name both ways, from Entity A to B, and B to A.  This is so that one can express Graph traversal from both sides.The format for specifying relationships in relationship file is     relationNameFromAToB <> relationNameFromBToA      entityTypeA <> entityTypeB //One to one            relationNameFromAToB <> relationNameFromBToA      [entityTypeA] <> entityTypeB //Many to one            relationNameFromAToBs <> relationNameFromBToA      entityTypeA <> [entityTypeB] //One to many            relationNameFromAsToBs <> relationNameFromBsToAs      [entityTypeA] <> [entityTypeB] //many to many                      As you can see, when an entity type is surrounded by square brackets [], it means cardinality of many Some examples     speakers <> events      [event] <> [speaker]      sessions <> event      event <> [session]                           Example link call     es.deep.link({          e1: {              _type: ‘event’,              _id: ‘674’          },          e2: {              _type: session,              _id: 4          },          e1ToE2Relation: ‘sessions’      })      .then(console.log)",
    "title": "Model Setup  Relationships  ​",
    "tokens": 527,
    "length": 1248
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#denormalisation",
    "content": "Title: Model Setup  denormalisation ​. Content: We use denormalisation to make it fast  Settings configFolder/schema/denormalisation.txt Imagine you have a database composed of events, speakers and persons.And, you wish to do the following two queries. Search events by speakers.person.name  Show countwise breakup of search results on events, based on speakers.person.name (like on ecommerce sites)  If your tables have only the foreign keys, you will have to do multiple hits to implement such cross table queries. And they will be slow. Depending on your data size, this may take a long long time before the final query result is returned. Also, your database will most probably get under heavy load.  With Godspeed you can denormalize based on simple rule setting and achieve the same result with a single hit to the database.  By denormalizing (always ensuring latest copy of) the speaker.person.name information within the event object,  during index, update, link or unlink calls .For example, here is how ‘event’ may look like in denormalization settings (in the file joins/index.txt)     [event]      sessions{title, description}      speakers.person{name}                     Based on your configuration the CRUD module works to automatically maintain the denormalised storage of speaker and session data in the event entities.\n  You only need to link or unlink two entities by a relationship. Everything else is taken care by Godspeed.  Maintenance of the denormalised state ​ Here are some scenarios in which the automatic denormalization will trigger in our example database.  Whenever you update the name of a person, the events where he or she spoke, will also get updated with person’s new name.    When you index (store) the event for first time in the database, and it contains speakers ids, the speaker’s name will also get copied inside the event entity as it gets stored/indexed.    When the event is linked to a speaker, the speaker’s name will get copied inside the event entity    When the event is unlinked from a speaker, the speaker’s id, name etc will get removed from the event entity  The Butterfly effect ​ As you just saw, any update can potentially create a ripple update across entire Graph, for maintaining correct data state as per the denormalisation and also the data dependency rules like union and copy (more on the latter below).Since this is handled automatically, it saves the developer from the overhead of maintaining a consistent, denormalised graph state across all updates. Her code doesn’t need to save the updated field value at multiple places in the database- a big overhead, lots of confusing code, more bugs... Instead, she simply declares the behavior just once, in a human readable way. After that she leaves it to Godspeed to do all the internal bookkeeping to upkeep a correct denormalised graph state all the time.In ElasticSearch, MongoDB and other NoSQL stores, we can make use of the JSON style storage and do the joins within one document. In comparison to SQL way of rows, the document way of NoSQL allows for the denormalization easily. Have a look at how the denormalized speakers relationship is stored within an Godspeed event document.      {        \"_index\": \"events\",        \"_type\": \"event\",        \"_id\": \"294464\",        \"_version\": 4,        \"_source\": {          \"speakers\": [            {              \"_id\": \"c6c35e3b21815a4209054505ac5e1680a954efdf\",              \"own\": true,              \"data\": {                \"person\": {                  \"_id\": \"1\",                  \"_version\": 1,                  \"data\": {                    \"english\": {                      \"name\": \"His Holiness the 14th Dalai Lama\"                    },                    \"tibetan\": {                        \"name\" : \"ང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་\"                    }                  }                }              }            }          ]        }      }",
    "title": "Model Setup  denormalisation ​",
    "tokens": 1268,
    "length": 3863
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#data-dependency-implementation",
    "content": "Title: Model Setup  Data dependency implementation  ​. Content: Note: This strategy is perhaps best applied in write less and read more scenarios. In many data models, data of an entity in your graph may depend on the data of other related entities. For ex. if a married woman has a new child, the husband also has a new child. And vice versa.\nGodspeed gives you an easy way to manage complex data dependencies between related entities of your information graph. As any update is made to any Entity in your Graph, Godspeed checks if any part of the remaining Graph should be updated by this change as per your data model settings. If yes, it updates the entire affected Graph (Butterfly effect). This saves LOTS of lines of code, time and effort in maintaining your inter-dependent data state so that you can move faster with your development goals. For now Godspeed supports two kinds of dependencies - Union from and Copy.  Union from   Settings are in configFolder/schema/union.toml Union from operation can be used to compute and store distinct values, whether relationships or data values, merged from field values of multiple related entities.This is useful for one to many or many to many relationships. Please look at the following examples to understand.     [conference]      speakers = '+talks.speaker' #As soon as a talk is linked to a conferece, or an already linked talk gets linked to a speaker, *the talk’s speaker is also linked to the conference as one of its speakers, if not already linked before*. Vice versa happens if the talk is unlinked to its speaker, or the talk is removed from the conference      topics = '+talks.topics' #As soon as a talk is linked to an conference, or a topic is set to an already linked talk, the talk’s topic is also added to the conference as one of its topics, if not already there. Vice versa happens if the talk is unliked to the conference, or the topic is removed from the talk.      [‘person’]      grandChildren = +‘children.children’ #Whenever a person’s child gets a new child, the new child gets added to the person’s grandchildren      [‘folder’]      fileTypes = ‘+childFolders.fileTypes + childFiles.type’ #Calculate union of all file types existing in the entire folder tree (recursively). Anytime, any file gets added to any child folder in this tree, the type of that file gets unioned with the list of fileTypes of that child folder, and all its parent folders up in the hierarchy.                       Copy   Settings are in configFolder/schema/union.toml Currently the copy functionality is achieved from within the union configuration.This is effective for many to one or one to one relations. For ex.     [person]      inLaws = \"+spouse.parents\" #This will ensure copy of in laws between husband and wife      [file]      permissions = \"+folder.permissions\" #Whenever a folder’s permissions are updated the underlying files’ permissions are updated automatically. You can still manually override them, without affecting the folder. But whenever the folder’s permissions are updated again, the file’s permissions will get overwritten.",
    "title": "Model Setup  Data dependency implementation  ​",
    "tokens": 753,
    "length": 3043
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#multi-linguality",
    "content": "Title: Model Setup  Multi Linguality  ​. Content: Settings file: configFolder/common.toml. In that set,  supportedLanguages = [‘english’ , ‘tibetan’, ‘thirdLanguage’] If your data is in a single language or is language agnostic, then supportedLanguages = []The fields which are declared multilingual, are stored like this in the _source of the entities.     \"english\": {          \"name\": \"His Holiness the 14th Dalai Lama\"      },      \"tibetan\": {          \"name\": \"ྋགོང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་པ།\"      }                      When creating, updating, searching or getting an entity, you have to specify the full path of every field, including its language. In search and get calls, you specify langs parameter, for the languages in which the data is to be fetched. By default data in all supported languages is fetched.",
    "title": "Model Setup  Multi Linguality  ​",
    "tokens": 305,
    "length": 766
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding",
    "content": "Title: Introduction  Introduction. Content: The data related settings of any project are all contained in  config/data  folder, in a nested hierarchy.\nThe configLoader of GS_data reads the config/data path and loads all the configurations in a JSON for use by the  gs_data  module.",
    "title": "Introduction  Introduction",
    "tokens": 57,
    "length": 237
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding#folder-location",
    "content": "Title: Introduction  Folder location ​. Content: The data config folder is located within  config  folder of the project, just like all other configurations like exports, telemetry.     .                   //Project root          ./src              ./actions   //This will contain all the API contracts defined in this project by developer (For API schema driven development)          ./config              ./exports   //The exported functions from ../src or imported modules              ./data      //Here will lie the data specific configurations read by the GS_data module.              ./telemetry              ...         //So on and so forth for other modules",
    "title": "Introduction  Folder location ​",
    "tokens": 224,
    "length": 617
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding#folder-structure",
    "content": "Title: Introduction  Folder structure ​. Content: The folder will contain the following information in heirarchy         ./config/data              index.(yaml | toml | json)                  //For common fields like supportedLanguages, defaultPrimaryDB, requestTimeout etc.              ./schema                  ./entities                      entityA.(yaml | toml)                      entityB.(yaml | toml)                  ./relationships                      definitions.yaml | definitions.toml | definitions.gsl                      ./definitions                               // Alternatively from above line                          `${entityA} <> ${entityB}`.(gsl | yaml) // Keep all the relationships aggregated by the two entities.                      dataDependencies.gsl                        // All automatically aggregated fields with functions like union, copy and in future (average, max, min).                      denormalization.gsl                         // Copy of current elasticgraph's joins/index.txt              ./performance                  ./batching //Or batching.yaml containing batch size and timeouts for different DBs of each kind                      elasticsearch.yaml                      postgres.yaml                      mongodb.yaml              ./databases //Database settings                  elasticsearch.(yaml | toml)                  mongodb.(yaml | toml)                  postgres.(yaml | toml)              ./environments                  dev.env                  staginv.env                  production.env",
    "title": "Introduction  Folder structure ​",
    "tokens": 792,
    "length": 1511
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding#environment-variables",
    "content": "Title: Introduction  Environment variables ​. Content: There will also be variables definable in environment files, i.e. dev.env, staging.env and production.env files.\nThese files will have some predefined variables, some empty variables. They will get their data replaced/filled by devops process as per the business use case.",
    "title": "Introduction  Environment variables ​",
    "tokens": 61,
    "length": 272
  },
  {
    "url": "https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/technology-used/intro",
    "content": "Title: Technologies used (Default)  Technologies used (Default). Content: Argo Events    Argo Workflows    Debezium    Kafka",
    "title": "Technologies used (Default)  Technologies used (Default)",
    "tokens": 21,
    "length": 50
  },
  {
    "url": "https://docs.godspeed.systems/docs/development-process",
    "content": "Title: Development Process  Development Process. Content:",
    "title": "Development Process  Development Process",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/development-process#developer-culture-practises-and-upskilling",
    "content": "Title: Development Process  Developer culture practises and upskilling ​. Content: Development environment ​  Dockerized  Linux or Mac Development practices ​  Sprint planning  Properly formatted issue/task creation  read more   Documentation  Coding standards  Test Coverage  Git ops  read more Diversity & cutting edge ​  Everything is better than the others for something  Learn and adopt different languages, frameworks & technologies  Be quick to discover and adapt new technologies and practices",
    "title": "Development Process  Developer culture practises and upskilling ​",
    "tokens": 78,
    "length": 418
  },
  {
    "url": "https://docs.godspeed.systems/docs/development-process#developer-portal--forum",
    "content": "Title: Development Process  Developer portal & forum ​. Content:",
    "title": "Development Process  Developer portal & forum ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/development-process#portal",
    "content": "Title: Development Process Developer portal & forum ​ Portal ​. Content: Documentation of every product and microservice  Coding standards  Training modules  Docker files and image links  Git repository links  Other useful links and reading material  Recommended: Docusauras",
    "title": "Development Process Developer portal & forum ​ Portal ​",
    "tokens": 39,
    "length": 201
  },
  {
    "url": "https://docs.godspeed.systems/docs/development-process#developer-forum",
    "content": "Title: Development Process Developer portal & forum ​ Developer forum ​. Content: Informtaion exchange  Fast communication  Helping each other  Recommended stack: Discourse and Slack",
    "title": "Development Process Developer portal & forum ​ Developer forum ​",
    "tokens": 21,
    "length": 100
  },
  {
    "url": "https://docs.godspeed.systems/docs/development-process#devops-practices",
    "content": "Title: Development Process  DevOps Practices ​. Content: As part of our devops, we have automated our system & infra using Gitops, Kubernetes, ArgoCD, Crossplane.\nOur system infra automation can easily be integrated with existing or legacy apps.For example:\nvideo demo of  springboot integration",
    "title": "Development Process  DevOps Practices ​",
    "tokens": 58,
    "length": 238
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq",
    "content": "Title: COMMON FAQs  COMMON FAQs. Content:",
    "title": "COMMON FAQs  COMMON FAQs",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#161-what-is-the-learning-curve-of-the-microservice-framework",
    "content": "Title: COMMON FAQs  16.1 What is the learning curve of the microservice framework? ​. Content: Our entire effort is to be a low code, easy to learn platform without too many things to learn, while getting big jobs done. A bunch of engineers have already trained and are developing microservices. Based on our data, it takes around 3~5 days for a young intern or engineer to get started on delivering enterprise level microservices.",
    "title": "COMMON FAQs  16.1 What is the learning curve of the microservice framework? ​",
    "tokens": 68,
    "length": 336
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#162-what-is-the-development-process-and-quality-metrics",
    "content": "Title: COMMON FAQs  16.2 What is the development process and quality metrics? ​. Content: All our upgrades go through peer reviews and test coverage (80%). We follow feature based branching. As part of our CI workflow, a developer can't commit/merge to the dev/master branches, unless all the test cases are passing. This ensures continuous sanity checks of our main branches.Documentation and test coverage are integral parts of quality metrics.\nCode and image vulnerability scans are also followed to ensure security within the code and images.Story/Bug Life Cycle ​        tip     Todo  - Created by product owner or ticket creator.   In Progress  - By developer when they start the work.   Documentation  - By developer when they implement the feature.   Code Review  - By developer when they finish the documentation.   QA  - By a peer developer when they are testing the feature.   Done  - By person merging the pull request.",
    "title": "COMMON FAQs  16.2 What is the development process and quality metrics? ​",
    "tokens": 189,
    "length": 841
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#163-how-can-we-adopt-new-versions-of-used-technology-easily-and-fast-for-example-the-new-postgres-release",
    "content": "Title: COMMON FAQs  16.3 How can we adopt new versions of used technology easily and fast? For example, the new Postgres release. ​. Content: Many times, the upgrades work with a simple update in package.json and  updating the project .    If at all a core framework update is needed, it is done as per the SLA. Security patches, fixes or feature inclusion will be part of the SLA itself.    Irrespective of our SLAs, we also take an initiative to proactively support important integrations and upgrades from its side, and make it available to all clientele and potential users.    The system will have default support for free and open source software. But based on client requirements, we can provide integrations for paid versions as well based on SLA and priority. If an upgrade has a license cost, it shall be borne by the client should it decide to use it.    These changes can be done by the client team itself, because it will have proper documentation, access and right to modify source for its internal uses, and there will be minimum 80% test coverage with test automation, and KT/support by us (latter as per the SLA).",
    "title": "COMMON FAQs  16.3 How can we adopt new versions of used technology easily and fast? For example, the new Postgres release. ​",
    "tokens": 219,
    "length": 988
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#164-how-easy-is-it-to-add-new-technology-in-place-of-an-existing-one-or-add-something-absolutely-new-and-unique-not-existing-in-the-framework",
    "content": "Title: COMMON FAQs  16.4 How easy is it to add new technology in place of an existing one, or add something absolutely new and unique (not existing in the framework)? ​. Content: Since all the implementation is done against the open standards and pluggable interfaces, as long as the new technology is adhering to those standards drop-in replacement will be feasible.    If the technology is introduced that does not adhere to the open standards, then some work will be needed to create adapters and avoid vendor lock-ins. But still, the integration will have to be compliant to the interfaces, for them to work, giving a uniformity of implementation and replacement. The modular architecture and modular design is plugin based, allowing for new integrations without much hassle.    This can be done by the client itself, or by us, depending on our engagement.",
    "title": "COMMON FAQs  16.4 How easy is it to add new technology in place of an existing one, or add something absolutely new and unique (not existing in the framework)? ​",
    "tokens": 138,
    "length": 681
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#165-which-databases-are-currently-supported-what-is-the-roadmap-for-future-support",
    "content": "Title: COMMON FAQs  16.5 Which databases are currently supported? What is the roadmap for future support? ​. Content: We currently support Mongodb, Postgres, MySQL, SQLServer, SQLite, MariaDB, CockroachDB, AWS Aurora, Azure SQL via  Prisma . We are in the process of adding Elasticsearch in Q2, 2022.",
    "title": "COMMON FAQs  16.5 Which databases are currently supported? What is the roadmap for future support? ​",
    "tokens": 51,
    "length": 182
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#166-does-the-api-handle-db-transactions",
    "content": "Title: COMMON FAQs  16.6 Does the API handle DB transactions? ​. Content: Yes there is an extensive support for  DB transactions .",
    "title": "COMMON FAQs  16.6 Does the API handle DB transactions? ​",
    "tokens": 11,
    "length": 56
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#167-how-can-apps-be-decoupled-or-loosely-coupled-with-dbs",
    "content": "Title: COMMON FAQs  16.7 How can apps be decoupled or loosely coupled with DBs? ​. Content: This decoupling is possible because of the universal datastore schema, CRUD API and migration process.\nFor more, please refer  prisma docs .",
    "title": "COMMON FAQs  16.7 How can apps be decoupled or loosely coupled with DBs? ​",
    "tokens": 33,
    "length": 140
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#168-when-using-godspeed-service-alongside-springboot-what-will-be-the-impact-on-performance-with-another-hop-versus-direct-connection-with-db-from-spring-boot",
    "content": "Title: COMMON FAQs  16.8 When using Godspeed service alongside SpringBoot, what will be the impact on performance with another hop, versus direct connection with DB from Spring Boot? ​. Content: The performance of an API endpoint depends on the service PLUS DB working together. For example, DB connection pooling and utilization, transaction handling, batching of independent queries, optimization of indexes and queries, denormalization (for cross table queries and aggregations), memoization/caching (for faster read and solving N+1 queries problem), CQRS setup between multiple DBs.Godspeed includes algorithms and best performance practices like the ones mentioned above. We are constantly striving to improve the performance. Next up is the feature of caching of output of workflow tasks and DB queries.",
    "title": "COMMON FAQs  16.8 When using Godspeed service alongside SpringBoot, what will be the impact on performance with another hop, versus direct connection with DB from Spring Boot? ​",
    "tokens": 117,
    "length": 614
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#169-what-is-the-strategic-advantage-of-making-db-queries-through-godspeed",
    "content": "Title: COMMON FAQs  16.9 What is the strategic advantage of making DB queries through Godspeed? ​. Content: First of all, the hop is completely optional. There are a few benefits of using this hop, however, including  Become decoupled with the choice of database provider, so that if a DB changes ,the app code does not change.    Low code configuration of CRUD service (saves effort of development, QA & maintenance)    Data federation across multiple DBs and APIs. One can execute multiple queries to configured sources within a single query.",
    "title": "COMMON FAQs  16.9 What is the strategic advantage of making DB queries through Godspeed? ​",
    "tokens": 96,
    "length": 436
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1610-how-to-achieve-multi-tenancy-in-dbs-for-a-single-application",
    "content": "Title: COMMON FAQs  16.10 How to achieve multi-tenancy in DBs, for a single application? ​. Content: It shall be done in two ways.  By having separate DBs for every tenant. This will be costly but will be PCI compliant. It will also provide data isolation if needed for each tenant.    By having a tenant_id in every row/document of every table/collection/index in the database.This will be cost effective and easy to maintain but the data across multiple tenants will be in a single database.",
    "title": "COMMON FAQs  16.10 How to achieve multi-tenancy in DBs, for a single application? ​",
    "tokens": 87,
    "length": 392
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1611-how-can-we-start-adopting-the-godspeed-framework",
    "content": "Title: COMMON FAQs  16.11 How can we start adopting the Godspeed framework? ​. Content: Start by creating a new microservice in  10 minutes , referring our docs.  Migration of existing microservices or monoliths:  Generate CRUD APIs and workflows out of the box, by introspecting the database of an existing app, via the CLI. Then start customizing and using it as per your need.  If you have existing Open API spec for a service, then you can generate the Godspeed event schema out of the box. (Coming soon)",
    "title": "COMMON FAQs  16.11 How can we start adopting the Godspeed framework? ​",
    "tokens": 98,
    "length": 420
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1612-how-to-move-out-of-the-godspeed-framework-can-we-have-a-two-door-exit-ie-can-we-move-out-of-technology-and-data-both",
    "content": "Title: COMMON FAQs  16.12 How to move out of the Godspeed framework? Can we have a two door exit? I.e. Can we move out of technology and data both? ​. Content: It is possible to opt out of the Godspeed framework without any kind of lock-in in which case all the microservices specific to the client can be developed using some other technology stack. The DBs can be self managed.The data will anyway be hosted on the client’s premise/cloud or its vendor’s cloud. The control of the data is subject to the client’s agreement with their respective cloud vendor, whose hosted database services are being used. But if the client uses self managed DBs, then they are fully in control of their data. This has got nothing to do with Godspeed. The framework comes with no lock-in of any kind and will never do so, as part of our philosophy.",
    "title": "COMMON FAQs  16.12 How to move out of the Godspeed framework? Can we have a two door exit? I.e. Can we move out of technology and data both? ​",
    "tokens": 150,
    "length": 672
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1613-how-will-we-prevent-unified-crud-api-from-limiting-or-choking-us",
    "content": "Title: COMMON FAQs  16.13 How will we prevent unified CRUD API from limiting or choking us? ​. Content: The framework, via Prisma, facilitates developers to access full functionality of any database or tool without being limited by the universal API. They shall be able to execute native database queries directly or via the API itself.",
    "title": "COMMON FAQs  16.13 How will we prevent unified CRUD API from limiting or choking us? ​",
    "tokens": 42,
    "length": 232
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1614-what-kind-of-api-standards-does-the-framework-support",
    "content": "Title: COMMON FAQs  16.14 What kind of API standards does the framework support? ​. Content: We currently support REST and planned to support GraphQL and gRPC in Q2, 2022.",
    "title": "COMMON FAQs  16.14 What kind of API standards does the framework support? ​",
    "tokens": 20,
    "length": 78
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1615-why-rest-first-approach--why-not-graphql-first-approach",
    "content": "Title: COMMON FAQs  16.15 Why Rest first approach ? Why not Graphql first approach? ​. Content: Every existing Graphql server in the industry supports REST/JSON interface, custom DSL and along with it, a Graphql interface (Ex. DGraph, Hasura, Apollo, Postgraphile). We are also going the same route by first being REST/JSON based, custom DSL and then adding Graphql in future. This is primarily because of greater familiarity of the REST standard across industry. At the same time, our REST implementation brings some good concepts to include in the development methodology like the concept of giving power to the frontend team to decide what data they want in response, and to get data from multiple sources in one go. We are including the features of Graphql in our design. The foundation our API interface is the unified event schema which we plan to use to generate GraphQL API (planned for Q2, 2022)Having said that, we would like to add that the Graphql standard specification does not specify a few critical things, like “where clause”, “aggregations”, “filters in joins”, “specifying relationships in model”, search/suggest queries, custom annotations, how to migrate, code first or schema first approach, etc. Every vendor has its own flavour of Graphql implementation/API, and there is no compatibility or out-of-the-box interoperability between implementations from different vendors. If the client also implements Graphql by any vendor, including Godspeed, it will be still having its own unique flavor of implementation, and the concept of data federation will not work for consumers of the API, just out of the box, as it appears to be so in theory of Graphql data federation. It will need developers to write custom resolvers to federate request/response from multiple Graphql services.In short Graphql standard lacks standard and unified implementation across industry. Further, we believe based on our survey that the Graphql ecosystem is complex and difficult to learn and extend for the uninitiated, and most developers even today do not know Grapqhl. Those who know find it complex. It lacks bringing agility for a typical developer team who is more comfortable with REST/JSON. It already took banks years to move from XML to JSON. Expecting third party consumers to consume Graphql is another big ask, a few years ahead of time.Still, it's an new upcoming standard with its own benefits. We wish to roll out our own flavor in 2022.",
    "title": "COMMON FAQs  16.15 Why Rest first approach ? Why not Graphql first approach? ​",
    "tokens": 500,
    "length": 2356
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1616-how-are-we-doing-testing-given-there-is-quite-a-bit-of-custom-dsl-in-the-framework-how-do-we-ensure-the-correctness",
    "content": "Title: COMMON FAQs  16.16 How are we doing testing given there is quite a bit of custom DSL in the framework. How do we ensure the correctness? ​. Content: DSL will not get loaded if it's not in the right format.  We are planning to add language feature in VSCode for compile time checks.  We have automated test suite generation through the event schema and the developer can add testing as a part of CI process.",
    "title": "COMMON FAQs  16.16 How are we doing testing given there is quite a bit of custom DSL in the framework. How do we ensure the correctness? ​",
    "tokens": 56,
    "length": 257
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1617-how-will-the-upgrades-and-migrations-be-done-to-the-framework",
    "content": "Title: COMMON FAQs  16.17 How will the upgrades and migrations be done to the framework? ​. Content: We follow a semantic release process using  semantic version (semver)  with autogenerated Changelog. The developers can change/upgrade the version of the framework for any microservice  via the CLI . After this, they can run the test cases and confirm if everything goes well.",
    "title": "COMMON FAQs  16.17 How will the upgrades and migrations be done to the framework? ​",
    "tokens": 61,
    "length": 276
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1618-how-crud-apis-will-support-the-paid-as-well-as-the-non-paid-features-of-databases-such-as-mongodb-for-example-mongodb-free-vs-paid-versions-will-support-different-features",
    "content": "Title: COMMON FAQs  16.18 How CRUD APIs will support the paid as well as the non paid features of databases such as MongoDB. For example MongoDB free vs paid versions will support different features. ​. Content: The framework uses Prisma which already supports paid and non paid features of databases.",
    "title": "COMMON FAQs  16.18 How CRUD APIs will support the paid as well as the non paid features of databases such as MongoDB. For example MongoDB free vs paid versions will support different features. ​",
    "tokens": 16,
    "length": 89
  },
  {
    "url": "https://docs.godspeed.systems/docs/faq#1619-how-to-ship-new-models-easily",
    "content": "Title: COMMON FAQs  16.19 How to ship new models easily? ​. Content: Prisma provides a standardized and widely used migration process, which can be used out of the box.",
    "title": "COMMON FAQs  16.19 How to ship new models easily? ​",
    "tokens": 20,
    "length": 99
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application",
    "content": "Title: Application deployment procedure  Application deployment procedure. Content:",
    "title": "Application deployment procedure  Application deployment procedure",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#prerequisite",
    "content": "Title: Application deployment procedure  Prerequisite ​. Content: Kubernetes Cluster ​     ArgoCD, Argo events and argo workflow installed on kubernetes cluster ​     Git repo with CI and application manifests ​     Spring boot application already containerized ​     Docker registry ​",
    "title": "Application deployment procedure  Prerequisite ​",
    "tokens": 59,
    "length": 219
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#step-1",
    "content": "Title: Application deployment procedure  Step 1 ​. Content: Cloning the git repo ​        $ https://github.com/Mindgreppers/demo-k8s-manifests.git",
    "title": "Application deployment procedure  Step 1 ​",
    "tokens": 36,
    "length": 86
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#step-2",
    "content": "Title: Application deployment procedure  Step 2 ​. Content: Create event source with ingress for the webhook and git secret token ​        $ cd demo-k8s-manifests/CI-manifests/      $ kubectl create secret generic git-credentials  \\        --from-literal=GIT_TOKEN=TOKEN      $ kubectl create -f spring-webhook.yaml",
    "title": "Application deployment procedure  Step 2 ​",
    "tokens": 101,
    "length": 255
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#step-3",
    "content": "Title: Application deployment procedure  Step 3 ​. Content: Create workflow template containing CI steps ​        $ kubectl create -f CI-workflow-templates.yaml",
    "title": "Application deployment procedure  Step 3 ​",
    "tokens": 32,
    "length": 100
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#step-4",
    "content": "Title: Application deployment procedure  Step 4 ​. Content: Create CI/CD for the master branch ​        $ kubectl create -f spring-master-CI.yaml",
    "title": "Application deployment procedure  Step 4 ​",
    "tokens": 32,
    "length": 85
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#step-5",
    "content": "Title: Application deployment procedure  Step 5 ​. Content: Create CI/CD for the non master branch ​        $ kubectl create -f spring-non-master-CI.yaml",
    "title": "Application deployment procedure  Step 5 ​",
    "tokens": 35,
    "length": 93
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#step-6",
    "content": "Title: Application deployment procedure  Step 6 ​. Content: Configure the Argo application to sync the git repo folder with kubernetes ​        $ argocd app create spring-app --repo https://github.com/Mindgreppers/demo-k8s-manifests.git --path spring-app --dest-namespace demo --dest-server https://kubernetes.default.svc --directory-recurse --sync-policy auto",
    "title": "Application deployment procedure  Step 6 ​",
    "tokens": 95,
    "length": 300
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/Application#step-7",
    "content": "Title: Application deployment procedure  Step 7 ​. Content: Add the webhook address in the spring boot git repo under webhooks ​   every push will have a CI trigger the application build. The deployment is done for the master branch only. ​",
    "title": "Application deployment procedure  Step 7 ​",
    "tokens": 40,
    "length": 180
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro",
    "content": "Title: Introduction  Introduction. Content: The developer will need to provide abstracted, templated configurations for all the infra and system-level setup. They should not need to learn any underlying technologies for dev ops or automation. The platform will handle the provisioning, securing, configuring, health, scaling, failover and management of the infra and system, in an automated way. The platform will deploy & manage the lifecycle of the following components and functionalities: hardware spanning multiple cloud providers (or on-premise), operating system, network, tools, libraries, data stores, gateways, microservice mesh, message bus, observability, CI/CD, microservices (domain & functional), pipelines & workflows. Technologies used by default  Crossplane  ArgoCD (delivery)  Linkerd (service mesh)  OpenTelemetry (for standardized tracing and monitoring via Jaeger and Prometheus)  Elasticsearch/Kibana /Fluentd (Log collection, transformation, dashboard, alerts)  Jaeger/Elasticsearch (Tracing)  Prometheus/Grafana or Elasticsearch APM (metrics collection, monitoring & alerts)  Proposed opensource framework for Auth - ORY Kratos or Keycloak (IAM), ORY OATHKEEPER (For gateway authorization)",
    "title": "Introduction  Introduction",
    "tokens": 266,
    "length": 1170
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#salient-features",
    "content": "Title: Introduction  Salient Features ​. Content: Infrastructure as code ​   We will use declarative YAML configuration for Crossplane. for seamless integration with CI/CD pipelines to have a single source for infra configuration.  Cloud federation & vendor independence ​   The deployment will be done using the Kubernetes cluster with  Crossplane  that provides extensive support for cloud providers such as AWS, GCP, Azure and others, along with on-premise. Using this one can not only be vendor-independent but also operate across multiple vendors.  Application portability ​   The API centric control plane is directly used by the application teams to deploy their changes easily, with the least involvement of the devOps team. The configurations & APIs hide infrastructure complexity & reduce learning curve, hence empowering the dev teams to develop, deploy or shift auto-managed applications on the fly.  Gitops and CI/CD based provisioning and configuring ​   All the dev team needs to make a commit to the git repo. The intended changes(as per the diff in the configuration files and code) should get automatically tested & deployed in production, using CI/CD and canary or blue-green deployment approaches. The pull request will need to be accepted by the stakeholders including but not limited to the product manager, engineering head, QA lead. Every commit to git will trigger unit and integration tests whether for infra, microservice or serverless function deployments. In case of test failures, the latest commit should fail to deploy in production. Deployments will not hinder the ongoing service at any time, ensuring high availability. We will use  ArgoCD  for the same  Observability stack ​   The stack for observability will be provided out of the box, with certain functionality preset and working without developer intervention.  Logging ​   There will be provision for centralized logs stored into Elasticsearch via Fluentd, & visualized via Kibana or Grafana. It is to be used by the microservice framework for fundamental request/response/error logging and by developers for business-level logging.    Monitoring ​   All the application performance metrics (uptime, CPU, RAM, sync request latency, sync request success/failure) will be automatically stored & monitored centrally via the service mesh. The latency/success/failure metric of the async requests will be stored by the microservice framework. The data will be collected in Prometheus; and the dashboard will be rendered in Grafana.    Tracing ​   Jaeger, along with Elasticsearch backend will be used to collect the trace information for every request. Traces will be collected across both sync and async flows. Every incoming HTTP or async request will carry trace information in its headers. The same will be propagated further through the microservice framework when it makes a sync or async hit to another service. In case of sync hits which shall be routed via the service mesh, the mesh will store the tracing information in the tracing backend. Async hit tracing will be the responsibility of the microservice framework itself, when it will consume an async message. The standard event format being used will carry the tracing headers.    Alerting ​   Grafana can be used to configure alerts based on the monitored metrics.    Authentication ​    ORY Kratos  will be used to provide authentication and role management service out of the box. But the system is not confined to using ORY Kratos only. The platform users can use any IAM service they wish to use, and it shall be made to work with the remaining system and microservice framework.  Scaffolding ​   A microservice project structure will be auto-generated from the CLI. There will be a scaffolding mechanism through CLI which will generate the project structure for the custom business logic (route, controller, api definition, validation, authorization, data model) of a custom microservice. The framework will also provide a configuration template that can be customized as per the development need.",
    "title": "Introduction  Salient Features ​",
    "tokens": 825,
    "length": 4006
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#infrastructure-as-code",
    "content": "Title: Introduction  Infrastructure as code ​. Content:",
    "title": "Introduction  Infrastructure as code ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#cloud-federation--vendor-independence",
    "content": "Title: Introduction  Cloud federation & vendor independence ​. Content:",
    "title": "Introduction  Cloud federation & vendor independence ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#application-portability",
    "content": "Title: Introduction  Application portability ​. Content:",
    "title": "Introduction  Application portability ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#gitops-and-cicd-based-provisioning-and-configuring",
    "content": "Title: Introduction  Gitops and CI/CD based provisioning and configuring ​. Content:",
    "title": "Introduction  Gitops and CI/CD based provisioning and configuring ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#observability-stack",
    "content": "Title: Introduction  Observability stack ​. Content:",
    "title": "Introduction  Observability stack ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#authentication",
    "content": "Title: Introduction  Authentication ​. Content:",
    "title": "Introduction  Authentication ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#scaffolding",
    "content": "Title: Introduction  Scaffolding ​. Content:",
    "title": "Introduction  Scaffolding ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#dashboards-available",
    "content": "Title: Introduction  Dashboards available ​. Content: Follwoing dashboards will be available:  Service & function dashboard: ​   All the services will be managed using OpenFAAS which provides an infra agnostic way of deploying services and functions using Docker over Kubernetes.    Data dashboard: ​   It will allow the admins or team to search, view and edit data in the DB of any microservice.    Monitoring dashboard: ​   It will be used to monitor the state of the live production environment. We plan to use Grafana for the same.    Workflows dashboard: ​   Monitor the workflows running or erroring out in the system. For example, ETLs, CI/CD, scheduled jobs, triggered workflows. This will be provided by the tool used underneath.For example, ARGO workflow.    Analytics dashboard: ​   A dashboard to view & download statistics, graphs and reports will be available. Also other dashboards available in open source can be adopted to work with the same data.",
    "title": "Introduction  Dashboards available ​",
    "tokens": 215,
    "length": 910
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#service--function-dashboard",
    "content": "Title: Introduction  Service & function dashboard ​. Content: All the services will be managed using OpenFAAS which provides an infra agnostic way of deploying services and functions using Docker over Kubernetes.",
    "title": "Introduction  Service & function dashboard ​",
    "tokens": 31,
    "length": 150
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#data-dashboard",
    "content": "Title: Introduction  Data dashboard ​. Content: It will allow the admins or team to search, view and edit data in the DB of any microservice.",
    "title": "Introduction  Data dashboard ​",
    "tokens": 22,
    "length": 93
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#monitoring-dashboard",
    "content": "Title: Introduction  Monitoring dashboard ​. Content: It will be used to monitor the state of the live production environment. We plan to use Grafana for the same.",
    "title": "Introduction  Monitoring dashboard ​",
    "tokens": 25,
    "length": 109
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#workflows-dashboard",
    "content": "Title: Introduction  Workflows dashboard ​. Content: Monitor the workflows running or erroring out in the system. For example, ETLs, CI/CD, scheduled jobs, triggered workflows. This will be provided by the tool used underneath.For example, ARGO workflow.",
    "title": "Introduction  Workflows dashboard ​",
    "tokens": 48,
    "length": 201
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#analytics-dashboard",
    "content": "Title: Introduction  Analytics dashboard ​. Content: A dashboard to view & download statistics, graphs and reports will be available. Also other dashboards available in open source can be adopted to work with the same data.",
    "title": "Introduction  Analytics dashboard ​",
    "tokens": 33,
    "length": 170
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#developer-workflow-in-action",
    "content": "Title: Introduction Dashboards available ​ Developer workflow in action ​. Content: The following diagram gives an detailed overview of the workflow.",
    "title": "Introduction Dashboards available ​ Developer workflow in action ​",
    "tokens": 11,
    "length": 65
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/intro#a-sample-setup",
    "content": "Title: Introduction  A SAMPLE SETUP ​. Content: IMPORTANT NOTE - While Godspeed is providing some standard tools as part of the platform, developers can integrate other tools to cover the same functionality as per the defined API contracts. Because we are using standard protocols like CloudEvents, OpenTelemetry, unified CRUD API, they can integrate any database, cache, message bus, APM/BPM tools, as long as the same API contract is maintained. Most of the tools mentioned below are replaceable as a platform goal. The only exceptions will be tools like Crossplane & Nodejs which are very fundamental to our platform and microservice framework respectively.  All the dev team needs to do is to make a commit to the git repo and the intended changes as per the diff in the configuration files and code, should get automagically tested & deployed in production, using CI/CD and canary or blue-green deployment approaches.The pull request will need to be accepted by the stakeholders including but not limited to product manager, engineering head, QA lead. Every commit to git will trigger unit and integration tests whether for infra, microservice or serverless function deployments. In case of test failing, the latest commit should fail to deploy in production. Deployments will not hinder the ongoing service at any time, ensuring high availability. We will use  ArgoCD  for the same",
    "title": "Introduction  A SAMPLE SETUP ​",
    "tokens": 270,
    "length": 1339
  },
  {
    "url": "https://docs.godspeed.systems/docs/infra-and-system/technology-used/intro",
    "content": "Title: Technologies used (Default)  Technologies used (Default). Content: Crossplane    ArgoCD  (delivery)   Linkerd  (service mesh)   OpenTelemetry  (for standardized tracing and monitoring via Jaeger and Prometheus)   Elasticsearch / Kibana  / Fluentd  (Log collection, transformation, dashboard, alerts)   Jaeger / Elasticsearch  (Tracing)   Prometheus / Grafana  or  Elasticsearch APM  (metrics collection, monitoring & alerts)   ORY Kratos or Keycloak (IAM) ,  ORY OATHKEEPER  (For gateway authorization)",
    "title": "Technologies used (Default)  Technologies used (Default)",
    "tokens": 130,
    "length": 435
  },
  {
    "url": "https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker",
    "content": "Title: Local Dev SetupInstall docker composecreating folder under home directory-  Local Dev Setup. Content:",
    "title": "Local Dev SetupInstall docker composecreating folder under home directory-  Local Dev Setup",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#local-debian-setup",
    "content": "Title: Local Dev SetupInstall docker composecreating folder under home directory-  Local Debian Setup ​. Content: 1: Update the apt package index and install packages to allow apt to use a repository over HTTPS: ​      $ sudo apt-get update      $ sudo apt-get install \\          ca-certificates \\          curl \\          gnupg \\          lsb-release                     2: Add Docker’s official GPG key: ​      $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg                     3: Adding docker apt repository: ​      $ echo \\        \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\        $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null                     4: Installing docker package using apt: ​      $ sudo apt-get update      $ sudo apt-get install docker-ce docker-ce-cli containerd.io -y                     5. Giving permission to user for docker and reboot the system ​      $ sudo usermod -aG docker $USER      $ reboot                     6: Verifying docker installation and working: ​      $ sudo docker run hello-world",
    "title": "Local Dev SetupInstall docker composecreating folder under home directory-  Local Debian Setup ​",
    "tokens": 476,
    "length": 1133
  },
  {
    "url": "https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#docker-install-on-ubuntu",
    "content": "Title: Local Dev SetupInstall docker composecreating folder under home directory-  Docker install on Ubuntu ​. Content: 1: Update the apt package index and install packages to allow apt to use a repository over HTTPS: ​      $ sudo apt-get update      $ sudo apt-get install \\          ca-certificates \\          curl \\          gnupg \\          lsb-release                     2: Add Docker’s official GPG key: ​      $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg                     3: Adding docker apt repository: ​      $ echo \\        \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\        $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null                     4: Installing docker package using apt: ​      $ sudo apt-get update      $ sudo apt-get install docker-ce docker-ce-cli containerd.io -y                     5. Giving permission to user for docker and reboot the system ​      $ sudo usermod -aG docker $USER      $ reboot                     6: Verifying docker installation and working: ​      $ sudo docker run hello-world",
    "title": "Local Dev SetupInstall docker composecreating folder under home directory-  Docker install on Ubuntu ​",
    "tokens": 476,
    "length": 1133
  },
  {
    "url": "https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#install-docker-on-windows",
    "content": "Title: Local Dev SetupInstall docker composecreating folder under home directory-  Install docker on windows ​. Content: To download docker binary  Click here  ​",
    "title": "Local Dev SetupInstall docker composecreating folder under home directory-  Install docker on windows ​",
    "tokens": 9,
    "length": 40
  },
  {
    "url": "https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#install-docker-on-mac",
    "content": "Title: Local Dev SetupInstall docker composecreating folder under home directory-  Install docker on Mac ​. Content: To download docker binary  Click here  ​",
    "title": "Local Dev SetupInstall docker composecreating folder under home directory-  Install docker on Mac ​",
    "tokens": 9,
    "length": 40
  },
  {
    "url": "https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker",
    "content": "Title: Local Dev SetupInstall docker composecreating folder under home directory-  Install docker compose. Content: To download docker binary  Click here  ​",
    "title": "Local Dev SetupInstall docker composecreating folder under home directory-  Install docker compose",
    "tokens": 9,
    "length": 40
  },
  {
    "url": "https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker",
    "content": "Title: Local Dev SetupInstall docker composecreating folder under home directory-  creating folder under home directory-. Content: example: supports-app     copy docker compose file in directory:-      version: \"3.0\"      services:        zookeeper:          image: confluentinc/cp-zookeeper:7.0.1          environment:            ZOOKEEPER_CLIENT_PORT: 2181            ZOOKEEPER_TICK_TIME: 2000          ports:            - 2181:2181              kafka:          image: confluentinc/cp-kafka:7.0.1          depends_on:            - zookeeper          ports:            - 29092:29092            - 9092:9092          environment:            KAFKA_BROKER_ID: 1            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1              elasticsearch:          container_name: es01          image: elasticsearch:7.4.2          environment:            - node.name=es01            - discovery.type=single-node            - bootstrap.memory_lock=true            - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"          ulimits:            memlock:              soft: -1              hard: -1          volumes:            - /home/gurjot/elasticsearch/es-data:/usr/share/elasticsearch/data          ports:            - 9200:9200            - 9300:9300          networks:            - elastic          restart: always            networks:        elastic:          driver: bridge                          create a folder under file with name:      es-data                          edit the path of esdata:-       ~/support-apps/es-data.",
    "title": "Local Dev SetupInstall docker composecreating folder under home directory-  creating folder under home directory-",
    "tokens": 952,
    "length": 1668
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author",
    "content": "Title: Authentication & Authorization  Authentication & Authorization. Content:",
    "title": "Authentication & Authorization  Authentication & Authorization",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#121-authentication",
    "content": "Title: Authentication & Authorization  12.1 Authentication ​. Content: The framework provides  JWT authentication  for securely transmitting information among microservices.\nThe user agent should send the JWT in the Authorization header using the Bearer schema. The content of the header should look like the following:     Authorization: Bearer <token>",
    "title": "Authentication & Authorization  12.1 Authentication ​",
    "tokens": 57,
    "length": 282
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#1211-jwt-configuration",
    "content": "Title: Authentication & Authorization 12.1 Authentication ​ 12.1.1 JWT Configuration ​. Content: You can do JWT configuration in  Configuration/Environment variables . For example, this is the sample configuration:     jwt:        iss: JWT_ISS #issuer        aud: JWT_AUD #audience        secretOrKey: JWT_SECRET                     You need to export these environment variables in your environment.12.1.1.1 Access JWT payload in Workflow DSL ​ You can access the complete JWT payload in  <% inputs.user %>  in workflow DSL as given below:     summary  :   Call an API and transform the         tasks  :              -     id  :   httpbin_step1              description  :   Hit http bin with some dummy data. It will send back same as response              fn  :   com.gs.http              args  :                  datasource  :   httpbin                data  :   <% inputs.body %  >                    jwt_payload  :   <% inputs.user %  >                  config  :                    url     :   /anything                  method  :   post",
    "title": "Authentication & Authorization 12.1 Authentication ​ 12.1.1 JWT Configuration ​",
    "tokens": 436,
    "length": 946
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#1212-event-spec",
    "content": "Title: Authentication & Authorization 12.1 Authentication ​ 12.1.2 Event spec ​. Content: Add  authn: true  in the event DSL to enable authentication for any event.     /v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post:         authn: true        fn: com.biz.kyc.ckyc.ckyc_initiate        on_validation_error: com.jfs.handle_validation_error        data:          schema:            body:               required: true              content:                application/json:                  schema:                    type: 'object'                    required: []                    properties:                      dob:  { type : 'string', format : 'date', pattern : \"[0-9]{4}-[0-9]{2}-[0-9]{2}\" }                      meta:                        type: 'object'            params:             - name: lender_loan_application_id              in: params              required: true              allow_empty_value: false              schema:                type: string        responses: #Output data defined as per the OpenAPI spec          200:            schema:              data:                 required: # default value is false                content:                  application/json:                    schema:                       type: object                      properties:                        application_id:                           type: string                      additionalProperties: false                      required: [application_id]",
    "title": "Authentication & Authorization 12.1 Authentication ​ 12.1.2 Event spec ​",
    "tokens": 824,
    "length": 1400
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#1213-generate-jwt",
    "content": "Title: Authentication & Authorization 12.1 Authentication ​ 12.1.3 Generate JWT ​. Content: Generally, you will get JWT from your authentication service. For testing purposes, you can generate JWT at  https://jwt.io/  by providing the  iss ,  aud  and  secretOrKey  to verify signature. Use the encoded token as JWT authentication token. For example,\n  In the above case, the Authorization header should look like:     Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtcy5zYW1wbGUuY29tIiwiYXVkIjoic2FtcGxlLmNvbSJ9._1fpM6VYq1rfKdTEqi8BcPTm8KIm4cNP8VhX0kQOEts",
    "title": "Authentication & Authorization 12.1 Authentication ​ 12.1.3 Generate JWT ​",
    "tokens": 193,
    "length": 486
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#1214-datasource-authentication",
    "content": "Title: Authentication & Authorization 12.1 Authentication ​ 12.1.4 Datasource authentication ​. Content: You can add authentication at datasource level on  API datasource . You can define an authn workflow at datasource level which requests to any authentication service for token/authentication then this workflow can return headers, params or statusCodes to the main workflow. Here is the sample spec:  \n Datasource      type  :   api        base_url  :   <% config.httpbin.base_url %  >          authn  :   com.jfs.httpbin_auth                     Here,  com.jfs.httpbin_auth  is the authentication workflow which gets called for the authentication of any request to this datasource. Sample workflow using the above datasource      summary  :   Call an API and transform the         tasks  :              -     id  :   httpbin_step1   # the response of this will be accessible within the parent step key, under the step1 sub key                description  :   Hit http bin with some dummy data. It will send back same as response              fn  :   com.gs.http              args  :                  datasource  :   httpbin                data  :   <% inputs.body %  >                  config  :                    url     :   /anything                  method  :   post                            Sample authentication workflow  com.jfs.httpbin_auth       summary  :   Auth workflow        tasks  :              -     id  :   auth_step1              description  :   Hit the authn request              fn  :   com.gs.http              args  :                  datasource  :   authapi                data  :   <% inputs.query.username %  >                  config  :                     url  :   /authenticate                  method  :   post            -     id  :   auth_step2              description  :   Transform the response received from authn api              fn  :   com.gs.transform              args  :                  headers  :                    Authorization  :   <% 'Bearer ' + outputs.auth_step1.auth.token %  >                  params  :                    queryid  :   <% outputs.auth_step1.params.queryid %  >                  statusCodes  :   <% outputs.auth_step1.status_code %  >                                 The authentication workflow should return response in this format:     headers  :             header1  :   val1        params  :            param1  :   val1        statusCodes  :     [  401  ,     403  ,     ...  .  ]                            note   The authentication workflow gets called when any request returns the specified  statusCodes .",
    "title": "Authentication & Authorization 12.1 Authentication ​ 12.1.4 Datasource authentication ​",
    "tokens": 1174,
    "length": 2483
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#122-authorization",
    "content": "Title: Authentication & Authorization  12.2 Authorization ​. Content: The framework provides authorization, to verify if any event/model is authorized to access specific information or is allowed to execute certain actions.",
    "title": "Authentication & Authorization  12.2 Authorization ​",
    "tokens": 26,
    "length": 153
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#1221-workflow-dsl",
    "content": "Title: Authentication & Authorization 12.2 Authorization ​ 12.2.1 Workflow DSL ​. Content: You can add authorization workflow at the task level in any workflow. The authorization workflow should return allow/deny or json output to the main worklfow.  Allow/Deny    \nIf authz workflow returns data as true/false, it means the task is allowed/denied to get executed.  JSON output    \nIf authz workflow returns JSON output then it is merged with args.data of the task for which authz is being executed.Here is the sample spec:  \n Sample workflow calling the authz workflow      summary  :   Call an API        tasks  :              -     id  :   httpbin_step1              description  :   Hit http bin with some dummy data. It will send back same as response              authz  :                  fn  :   com.jfs.authz                args  :   <% inputs %  >                fn  :   com.gs.http              args  :                  datasource  :   httpbin                data  :   <% inputs %  >                  config  :                    url     :   /anything                  method  :   post                      Sample authorization workflow  com.jfs.authz       summary  :   Authorization workflow        tasks  :            -     id  :   authz_step1            description  :   return allow/deny based upon user            fn  :   com.gs.http            args  :                 datasource  :   authz              data  :   <% inputs.body.user %  >                config  :                  url     :   /authorize                method  :   post          -     id  :   authz_step2            description  :   transform response from authz api            fn  :   com.gs.transform            args  :     |                <coffee% if outputs.authz_step1.data.code == 200 then {                  success: true                  data: true              } else if outputs.authz_step1.data.code == 201 then {                  success: true                  data:                    where:                      role: 'USER'              } else {                  success: false                  data: false              } %>                     The authorization workflow should return response in this format to allow/deny:     success  :   true/false        data  :   true/false/JSON output                      When data is returned as false i.e. deny then the framework will send  403 Unauthorized  response.",
    "title": "Authentication & Authorization 12.2 Authorization ​ 12.2.1 Workflow DSL ​",
    "tokens": 1154,
    "length": 2319
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/authen-author#1222-sample-db-query-call-authorization",
    "content": "Title: Authentication & Authorization 12.2 Authorization ​ 12.2.2 Sample DB query call authorization ​. Content: In DB query call, authz workflow can return JSON output with where clause, include clause etc. which will be merged with the args of the main workflow which is doing DB query.Here is the sample spec:  \n Sample workflow calling the authz workflow      summary  :   datastore demo        tasks  :            -     id  :   find_user            description  :   find users            authz  :                fn  :   com.jfs.auth              args  :   <% inputs %  >              fn  :   com.gs.datastore            args  :                datasource  :   mongo              data  :                  include  :   <% inputs.body.include %  >                  where  :   <% inputs.body.where %  >                config  :                  method  :   user.findMany                      Sample authorization workflow  com.jfs.authz       summary  :   Authorization workflow        tasks  :            -     id  :   authz_step1            description  :   return allow/deny based upon user            fn  :   com.gs.http            args  :                 datasource  :   authz              data  :   <% inputs.body.user %  >                config  :                  url     :   /authorize                method  :   post          -     id  :   authz_step2            description  :   transform response from authz api            fn  :   com.gs.transform            args  :     |                <coffee% if outputs.authz_step1.data.code == 200 then {                  success: true                  data:                    where:                      role: 'USER'              } else {                  success: false                  data: false              } %>                     When authorization workflow  com.jfs.authz  returns  success: true  then its  data  will be merged with the main workflow which is calling the authz workflow.  \nFor example, in the above authz workflow,  data  is returned as:     data  :            where  :              role  :     'USER'                     This data will be merged with the args.data of the main workflow i.e.     args  :            data  :              include  :   <% inputs.body.include %  >              where  :   <% inputs.body.where %  >     # where clause from authz workflow will be merged with this",
    "title": "Authentication & Authorization 12.2 Authorization ​ 12.2.2 Sample DB query call authorization ​",
    "tokens": 1161,
    "length": 2256
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/caching",
    "content": "Title: Caching  Caching. Content: Godspeed provides caching of the tasks using redis as cache. You can cache the result of any task in the workflows.",
    "title": "Caching  Caching",
    "tokens": 26,
    "length": 115
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/caching#91-specifications",
    "content": "Title: Caching  9.1 Specifications ​. Content:",
    "title": "Caching  9.1 Specifications ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/caching#911-datasource-spec-for-redis",
    "content": "Title: Caching 9.1 Specifications ​ 9.1.1 Datasource spec for redis ​. Content: Define a datasource with type 'redis' in   src/datasources  . Here, redis datasource is defined in  src/datasources/redis.yaml      type  :   redis        url  :   redis  [  s  ]  :  //  [  [  username  ]  [  :  password  ]  @  ]  [  host  ]  [  :  port  ]  [  /db  -  number  ]",
    "title": "Caching 9.1 Specifications ​ 9.1.1 Datasource spec for redis ​",
    "tokens": 123,
    "length": 278
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/caching#912-configuration",
    "content": "Title: Caching 9.1 Specifications ​ 9.1.2 Configuration ​. Content: Define default caching datasource in  static configuration      log_level  :   debug        lang  :   coffee        server_url  :   https  :  //api.example.com  :  8443/v1/api        caching  :   redis",
    "title": "Caching 9.1 Specifications ​ 9.1.2 Configuration ​",
    "tokens": 84,
    "length": 201
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/caching#913-workflow-spec",
    "content": "Title: Caching 9.1 Specifications ​ 9.1.3 Workflow spec ​. Content: Here is the caching spec to write in the workflow.     caching  :              key  :   <key name which is used to cache result in redis  >              invalidate  :   <used to invalidate the cache of some other task. Key name which we want to delete/remove from cache e.g. this field can be used in CRUD types task. While delete operation  ,   invalidate the cache of read or update task  >              cache_on_failure  :   <true  |  false  ,   whether you want to cache the failure result or not. By default  ,   it is false  >              expires  :   <timer in seconds  ,   until the cached result is valid  >              force  :   <true  |  false  ,   force flag to specify not to use cache  ,   always trigger task's function. Set it to true if you don't want to use cache  >                      Example Spec      summary  :   workflow to cache task results        id  :   cache_wf        tasks  :            -     id  :   cache_step1            caching  :                key  :   cache_step1              invalidate  :   cache_step2              cache_on_failure     :     false                expires  :     60                force  :     false              fn  :   com.gs.http            args  :                  datasource  :   httpbin                data  :                    name  :     'hello'                  config  :                    url     :   /anything                  method  :   post          -     id  :   cache_step2            caching  :                key  :   cache_step2              cache_on_failure     :     false                expires  :     60                force  :     false              fn  :   com.gs.http            args  :                  datasource  :   httpbin                data  :                    name  :     'cache'                  config  :                    url     :   /anything                  method  :   post                      When the workflow is triggered for the first time, then the result of the two tasks are cached in DB with keys  cache_step1  and  cache_step2  for 60 seconds.  If the next call to this workflow occurs within 60 seconds then the cached results will be used, else API call will be triggered.  In the  cache_step1 , invaldiate spec is defined, which is invalidating/deleting the cached result of the  cache_step2 . It means even if  cache_step2  is cached, if any calls occurs within 60 seconds then the  cache_step1  will delete the cached result of  cache_step2 . So, no cache will be used for  cache_step2 .",
    "title": "Caching 9.1 Specifications ​ 9.1.3 Workflow spec ​",
    "tokens": 1174,
    "length": 2508
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/custom-middleware",
    "content": "Title: Custom Middleware  Custom Middleware. Content:",
    "title": "Custom Middleware  Custom Middleware",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/custom-middleware#141-how-to-add-custom-middleware-in-godspeed",
    "content": "Title: Custom Middleware  14.1 How to add custom middleware in Godspeed ​. Content: Step 1: Create an index.js/index.ts file in  src/middlewares  dierctory in your project.     Project structure      .      ├── config      └── src          └── middlewares              └── index.ts                      Step 2: index.ts/index.js should be exporting array of middleware functions with signature (req, res, next)     index.ts      import     {   uuid   }     from     'uuidv4'  ;                function     addUuid  (  req  :     any  ,   res  :     any  ,   next  :     any  )     {              // Set data            req  .  body  .  uuid   =     uuid  (  )  ;                        // Go to next middleware              next  (  )  ;          }                function     addTitle  (  req  :     any  ,   res  :     any  ,   next  :     any  )     {              // Set data            req  .  body  .  title   =     \"Title from middleware/ts\"  ;                        // Go to next middleware              next  (  )  ;          }                export     default     [  addUuid  ,   addTitle  ]  ;                            caution   If the current middleware function does not end the request-response cycle, it must call next() to pass control to the next middleware function. Otherwise, the request will be left hanging.    Sample req object    \nHere, two properties  uuid  and  title  are added in the body of req object.     {            \"_events\"  :     {  }  ,            \"_eventsCount\"  :     1  ,            \"httpVersionMajor\"  :     1  ,            \"httpVersionMinor\"  :     1  ,            \"httpVersion\"  :     \"1.1\"  ,            \"complete\"  :     true  ,            \"rawHeaders\"  :     [              \"Content-Type\"  ,              \"application/json\"  ,              \"User-Agent\"  ,              \"PostmanRuntime/7.29.2\"  ,              \"Accept\"  ,              \"*/*\"  ,              \"Cache-Control\"  ,              \"no-cache\"  ,              \"Postman-Token\"  ,              \"7ce46b80-61e1-44c4-b91a-8a3c914797e8\"  ,              \"Host\"  ,              \"localhost:4901\"  ,              \"Accept-Encoding\"  ,              \"gzip, deflate, br\"  ,              \"Connection\"  ,              \"keep-alive\"  ,              \"Content-Length\"  ,              \"2\"            ]  ,            \"rawTrailers\"  :     [  ]  ,            \"aborted\"  :     false  ,            \"upgrade\"  :     false  ,            \"url\"  :     \"/test3\"  ,            \"method\"  :     \"POST\"  ,            \"statusCode\"  :     null  ,            \"statusMessage\"  :     null  ,            \"_consuming\"  :     true  ,            \"_dumped\"  :     false  ,            \"baseUrl\"  :     \"\"  ,            \"originalUrl\"  :     \"/test3\"  ,            \"params\"  :     {  }  ,            \"query\"  :     {  }  ,            \"body\"  :     {              \"uuid\"  :     \"cfc5fc7f-cfdf-4fe7-99ad-08993f90f570\"  ,              \"title\"  :     \"Title from middleware/ts\"            }  ,            \"_body\"  :     true  ,            \"id\"  :     2  ,            \"log\"  :     {  }  ,            \"route\"  :     {              \"path\"  :     \"/test3\"  ,              \"stack\"  :     [                {                  \"name\"  :     \"<anonymous>\"  ,                  \"keys\"  :     [  ]  ,                  \"regexp\"  :     {                    \"fast_star\"  :     false  ,                    \"fast_slash\"  :     false                  }  ,                  \"method\"  :     \"post\"                }  ,                {                  \"name\"  :     \"<anonymous>\"  ,                  \"keys\"  :     [  ]  ,                  \"regexp\"  :     {                    \"fast_star\"  :     false  ,                    \"fast_slash\"  :     false                  }  ,                  \"method\"  :     \"post\"                }              ]  ,              \"methods\"  :     {                \"post\"  :     true              }            }  ,            \"protocol\"  :     \"http\"  ,            \"secure\"  :     false  ,            \"ip\"  :     \"::ffff:192.168.224.1\"  ,            \"ips\"  :     [  ]  ,            \"subdomains\"  :     [  ]  ,            \"path\"  :     \"/test3\"  ,            \"hostname\"  :     \"localhost\"  ,            \"host\"  :     \"localhost\"  ,            \"fresh\"  :     false  ,            \"stale\"  :     true  ,            \"xhr\"  :     false  ,            \"files\"  :     [  ]          }",
    "title": "Custom Middleware  14.1 How to add custom middleware in Godspeed ​",
    "tokens": 2719,
    "length": 4251
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/api",
    "content": "Title: API datasource  API datasource. Content: The API datasource acts as a wrapper around third party APIs. It helps interact with third party APIs or own microservices. It takes OpenAPI schema as its setting, and the datasource can be used in  com.gs.http  calls out of the box. Following functionality is provided by the framework based on the schema of the datasource Authentication and authorization as per the spec  Validation of the input to the http method (must be compliant to the API spec)  Validation of the response from the API (must be compliant to the API spec)",
    "title": "API datasource  API datasource",
    "tokens": 114,
    "length": 530
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/api#821-api-datasource-schema-defined-externally",
    "content": "Title: API datasource  8.2.1 API datasource schema defined externally ​. Content: If the OpenAPI spec of the API to consume/connect with is available at a URL, then one can simply refer the url here itself.     idfc  :            schema  :   https  :  //raw.githubusercontent.com/Kong/swagger  -  ui  -  kong  -  theme/main/demo/public/specs/httpbin.yaml",
    "title": "API datasource  8.2.1 API datasource schema defined externally ​",
    "tokens": 100,
    "length": 272
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/api#822-api-datasource-schema-defined-within-the-yaml-file",
    "content": "Title: API datasource  8.2.2 API datasource schema defined within the yaml file ​. Content: If there is no OpenAPI spec available for an API, then developer needs to provide details of the API schema in the .yaml file for that datasource.     type  :   api        schema  :          base_url  :   <% config.httpbin.base_url %  >          security  :            -     ApiKey  :   sample  -  app          -     ApiToken  :   <% config.httpbin.api_token %  >                securitySchemes  :            ApiKey  :              type  :   apiKey            in  :   header            name  :   x  -  api  -  key                ApiToken  :              type  :   apiKey            in  :   header            name  :   Authorization",
    "title": "API datasource  8.2.2 API datasource schema defined within the yaml file ​",
    "tokens": 328,
    "length": 631
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/api#823-headers-defined-at-datasource-level",
    "content": "Title: API datasource  8.2.3 Headers defined at datasource level ​. Content: Headers defined at datasource level are applicable for all the workflows, which are using this datasource. For example, in below datasource, headers 'name' and 'title' are sent in each workflow which is using this datasource.     type: api      base_url: <% config.httpbin.base_url %>            headers:        name: godspeed        title: <% inputs.headers['title'] %>",
    "title": "API datasource  8.2.3 Headers defined at datasource level ​",
    "tokens": 121,
    "length": 370
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/api#824-headers-defined-at-task-level",
    "content": "Title: API datasource  8.2.4 Headers defined at task level ​. Content: Headers defined at task level are applicable for a single task only. You can find the  example usage here",
    "title": "API datasource  8.2.4 Headers defined at task level ​",
    "tokens": 22,
    "length": 105
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/api#825-example-usage",
    "content": "Title: API datasource  8.2.5 Example usage ​. Content: You can find the  example usage here",
    "title": "API datasource  8.2.5 Example usage ​",
    "tokens": 8,
    "length": 36
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/aws",
    "content": "Title: Introduction  Introduction. Content: The framework supports AWS as a datasource. It helps in interacting with AWS, to use various AWS services and methods.",
    "title": "Introduction  Introduction",
    "tokens": 24,
    "length": 118
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/aws#871-example-spec",
    "content": "Title: Introduction  8.7.1 Example spec ​. Content: The datasources for AWS are defined in  src/datasources . Here, AWS datasource is defined in  aws_s3.yaml .     .      ├── config      └── src          ├── datasources          │   └── httpbin.yaml          │   ├── aws_s3.yaml          ├── events          ├── functions          └── mappings                     Sample configuration in  aws_s3.yaml      type: aws      common:          credentials:              accessKeyId: 'AKIA4KQJJFGY2KPNNOEMmnbv'              secretAccessKey: '+pf5xyyPSUfBNn0V9ZIH0oPVzARBvxoehR+mpzigcdfg'          region: \"ap-south-1\"      services:          S3:              config: {}",
    "title": "Introduction  8.7.1 Example spec ​",
    "tokens": 341,
    "length": 610
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/aws#872-comgsaws-workflow",
    "content": "Title: Introduction  8.7.2 com.gs.aws workflow ​. Content: Refer here  for com.gs.aws workflow.",
    "title": "Introduction  8.7.2 com.gs.aws workflow ​",
    "tokens": 11,
    "length": 36
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore",
    "content": "Title: Introduction  Introduction. Content: The framework takes the approach of schema driven development.\nIt supports multiple kinds of SQL and NoSQL datastores. The developer only needs to specify or generate the schema for a datastore, with authorization policies. The CRUD events and workflows are automatically generated from the schema itself. Shall the developer need to use these within other workflows, they can do that as well. Currently supported datastores   Postgres (via Prisma)  Mysql (via Prisma)  Mongodb (via Prisma)  Elasticsearch (via Elasticgraph, our inhouse implementation providing bunch of exciting features over Elasticsearch, including relationship management and joins.)  The integration supports  Model declaration (For both relational and non-relational stores)  Schema generation from existing database  Universal, autogenerated CRUD API.  Validation of the CRUD requests  Authorization mechanism at the entity, column, row and ownership levels  Automatic caching based on configuration.",
    "title": "Introduction  Introduction",
    "tokens": 201,
    "length": 974
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#831-schema-specification",
    "content": "Title: Introduction  8.3.1 Schema specification ​. Content: The framework extends  Prisma specification  for specifying the schema of any datastore. This can be generated from an  existing database  or manually created by the developer. The schema is present as  {datastore_name}.prisma  file in the  src/datasources  folder.    Sample Schema       generator client {        provider = \"prisma-client-js\"        output   = \"./generated-clients/mongo\"        previewFeatures = [\"metrics\"]      }            datasource db {        provider = \"mongodb\"        url      = env(\"MONGO_TEST_URL\")      }            model User1 {        id        String      @id @default(auto()) @map(\"_id\") @db.ObjectId        createdAt DateTime @default(now())        email     String   @unique        name      String?      }",
    "title": "Introduction  8.3.1 Schema specification ​",
    "tokens": 303,
    "length": 744
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#832-cli-commands",
    "content": "Title: Introduction  8.3.2 CLI Commands ​. Content: Any  Prisma CLI command  can be executed from godspeed CLI using  godspeed prisma <command> . For example,     $ godspeed prisma db pull --schema=./src/datasources/mongo_pull.prisma                             _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Prisma schema loaded from src/datasources/mongo_pull.prisma      Environment variables loaded from .env      Datasource \"db\"            ✔ Introspected 6 models and wrote them into src/datasources/mongo_pull.prisma in 81ms                  *** WARNING ***            Could not determine the types for the following fields.      - Model \"Post\", field: \"slug\"      - Model \"Profile\", field: \"userId\"      - Model \"User\", field: \"email\"            Run prisma generate to generate Prisma Client.                            note   Please make sure that  godspeed prisma <command>  is executed inside from devcontainer/project root directory.",
    "title": "Introduction  8.3.2 CLI Commands ​",
    "tokens": 594,
    "length": 1219
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#833-prisma-datastore-setup",
    "content": "Title: Introduction  8.3.3 Prisma Datastore Setup ​. Content: The framework has  inbuilt feature  of setting up datastore automatically whenever a new  {datastore_name}.prisma  file is created in the  src/datasources  folder. In case, you are getting any error in the datastore setup, then you can refer to below section for manual setup:  During the project setup, if you have not specified the type of datastore you just added, then you will have to execute  godspeed update  in project root directory, outside the dev container. This will deploy the container for this datastore in the dev container environment.",
    "title": "Introduction  8.3.3 Prisma Datastore Setup ​",
    "tokens": 127,
    "length": 553
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#model-setup",
    "content": "Title: Introduction 8.3.3 Prisma Datastore Setup ​ Model setup ​. Content: Prisma model setup is done using prisma generate and db push commands.Step 1: godspeed prisma generate ​      $ godspeed prisma generate --schema=./src/datasources/mongo2.prisma                             _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Environment variables loaded from .env      Prisma schema loaded from src/datasources/mongo2.prisma            ✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo2 in 111ms      You can now start using Prisma Client in your code. Reference: https://pris.ly/d/client            import { PrismaClient } from './src/datasources/generated-clients/mongo2'      const prisma = new PrismaClient()                     Step 2: godspeed prisma db push ​      $ godspeed prisma db push --schema=./src/datasources/mongo.prisma                             _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Environment variables loaded from .env      Prisma schema loaded from src/datasources/mongo.prisma      Datasource \"db\"            The database is already in sync with the Prisma schema.            ✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo in 149ms",
    "title": "Introduction 8.3.3 Prisma Datastore Setup ​ Model setup ​",
    "tokens": 962,
    "length": 1831
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#834-auto-generating-crud-apis-from-data-store-models",
    "content": "Title: Introduction  8.3.4 Auto generating CRUD APIs from data store models ​. Content: Developer can generate CRUD APIs for all the models in a datastore.  Events  and  Workflows  will be auto generated for  Create ,  Read ,  Update  and  Delete  operations for each model in respective datastore. Auto-generated events and workflows will be stored in  /events/{datasourceName}/{modelName}  and  /functions/com/gs/{datasourceName}/{modelName}  folders respectively.     godspeed gen-crud-api",
    "title": "Introduction  8.3.4 Auto generating CRUD APIs from data store models ​",
    "tokens": 116,
    "length": 404
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#835-sample-datastore-crud-task",
    "content": "Title: Introduction  8.3.5 Sample datastore CRUD task ​. Content: Please find an  example here",
    "title": "Introduction  8.3.5 Sample datastore CRUD task ​",
    "tokens": 6,
    "length": 28
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#836-prisma-encryption-of-fields",
    "content": "Title: Introduction  8.3.6 Prisma encryption of fields ​. Content: You can apply encryption on  String  type fields in Prisma. Be default, the encryption algorithm used is AES-GCM with 256 bit keys.",
    "title": "Introduction  8.3.6 Prisma encryption of fields ​",
    "tokens": 31,
    "length": 131
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#8361-specification",
    "content": "Title: Introduction 8.3.6 Prisma encryption of fields ​ 8.3.6.1 Specification ​. Content: In your prisma schema, add  /// @encrypted  to the fields you want to encrypts.  \nFor example,  email  field in below schema:     generator client {        provider = \"prisma-client-js\"        output   = \"./generated-clients/mongo\"        previewFeatures = [\"metrics\"]      }            datasource db {        provider = \"mongodb\"        url      = env(\"MONGO_TEST_URL\")      }            model User1 {        id        String      @id @default(auto()) @map(\"_id\") @db.ObjectId        createdAt DateTime @default(now())        email     String   @unique /// @encrypted        name      String?      }",
    "title": "Introduction 8.3.6 Prisma encryption of fields ​ 8.3.6.1 Specification ​",
    "tokens": 270,
    "length": 600
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/datastore#8362-configuration",
    "content": "Title: Introduction 8.3.6 Prisma encryption of fields ​ 8.3.6.2 Configuration ​. Content: You can specify  prisma_secret  in  environment configuration   \nFor example, this is the sample configuration, set  PRISMA_SECRET  as env variable:     prisma_secret  :   PRISMA_SECRET   # secret used to generate hash of prisma fields",
    "title": "Introduction 8.3.6 Prisma encryption of fields ​ 8.3.6.2 Configuration ​",
    "tokens": 69,
    "length": 235
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph",
    "content": "Title: Introduction  Introduction. Content: The framework supports elasticgraph as a datasource. It supports elasticsearch as datastore. In addition, you can use various features of elasticgraph like deep graph search algorithms, joins, aggregations, multi-lingual support.",
    "title": "Introduction  Introduction",
    "tokens": 47,
    "length": 229
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#851-folder-structure",
    "content": "Title: Introduction  8.5.1 Folder Structure ​. Content: The datasources for elasticgraph are defined in  src/datasources . Here,  elasticgraph1.yaml  and  elasticgraph2.yaml  are defined in datasources.     .      ├── config      └── src          ├── datasources          │   └── httpbin.yaml          │   ├── elasticgraph1.yaml          │   ├── elasticgraph2.yaml          ├── events          ├── functions          └── mappings",
    "title": "Introduction  8.5.1 Folder Structure ​",
    "tokens": 165,
    "length": 373
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#852-datasource-dsl",
    "content": "Title: Introduction  8.5.2 Datasource DSL ​. Content: elasticgraph1.yaml      type  :   elasticgraph        schema_backend  :   /workspace/development/app/src/eg_config/eg1/   # schema path to config files          deep  :     false     # deep feature of elasticgraph to use graph algorithms          collect  :     true     # collect feature of elasticsearch                      elasticgraph2.yaml      type  :   elasticgraph        schema_backend  :   /workspace/development/app/src/eg_config/eg2/   # schema path to config files          deep  :     false     # deep feature of elasticgraph to use graph algorithms          collect  :     true     # collect feature of elasticsearch",
    "title": "Introduction  8.5.2 Datasource DSL ​",
    "tokens": 254,
    "length": 632
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#853-configuration-files-of-elasticgraph",
    "content": "Title: Introduction  8.5.3 Configuration files of elasticgraph ​. Content: All the configuration files of elasticgraph datasources should be defined in  src/datasources/eg_config/  directory.Sample strucutre of config files under  schema_backend  path.     .      ├── eg1      │   ├── collect.toml      │   ├── common.toml      │   ├── config.toml      │   ├── custom.toml      │   ├── elasticsearch.toml      │   ├── joins      │   │   └── search.txt      │   └── schema      │       ├── aggregation.toml      │       ├── dependencies.toml      │       ├── entities      │       │   ├── credit_card.toml      │       │   └── user.toml      │       ├── entitiesInfo.toml      │       ├── relationships.txt      │       ├── suggestions.toml      │       └── union.toml      └── eg2          ├── collect.toml          ├── common.toml          ├── config.toml          ├── custom.toml          ├── elasticsearch.toml          ├── joins          │   └── search.txt          └── schema              ├── aggregation.toml              ├── dependencies.toml              ├── entities              │   ├── credit_card.toml              │   └── user.toml              ├── entitiesInfo.toml              ├── relationships.txt              ├── suggestions.toml              └── union.toml",
    "title": "Introduction  8.5.3 Configuration files of elasticgraph ​",
    "tokens": 617,
    "length": 1201
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#854-elasticgraph-setup",
    "content": "Title: Introduction  8.5.4 Elasticgraph Setup ​. Content: The framework has  inbuilt feature  of setting up elasticgraph model automatically whenever a new configuration is added in  src/datasources/eg_config/  directory. In case, you are getting any error in the setup, then you can refer execute below step for manual setup:  During the project setup, if you have not selected elasticsearch, then you will have to execute  godspeed update  in project root directory, outside the dev container. This will add elasticsearch in the dev container environment. Step 1: godspeed eg-push ​      $ godspeed eg-push                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                      > eg_test@1.0.0 eg-push      > for f in src/datasources/eg_config/*; do echo ${f}; node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ${f} all; done            src/datasources/eg_config/eg1",
    "title": "Introduction  8.5.4 Elasticgraph Setup ​",
    "tokens": 518,
    "length": 1162
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#855-auto-generating-crud-apis-for-elasticgraph",
    "content": "Title: Introduction  8.5.5 Auto generating CRUD APIs for elasticgraph ​. Content: Developer can generate CRUD APIs for all the entities in  src/datasources/eg_config/  directory.  Events  and  Workflows  will be auto generated for  Create ,  Read ,  Update  and  Delete  operations for each entity in respective datastore. Auto-generated events and workflows will be stored in  /events/{datasourceName}/{entityName}  and  /functions/com/gs/eg/{datasourceName}/{entityName}  folders respectively.     $ godspeed gen-crud-api                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                      > eg_test@1.0.0 gen-crud-api      > npx godspeed-crud-api-generator            Select datasource / schema to generate CRUD APIs      Events and Workflows are generated for elasticgraph.yaml",
    "title": "Introduction  8.5.5 Auto generating CRUD APIs for elasticgraph ​",
    "tokens": 503,
    "length": 1038
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources",
    "content": "Title: Introduction  Introduction. Content: The framework provides feature to extend datasources where you can add new datasources with any customized type as per your business logic.",
    "title": "Introduction  Introduction",
    "tokens": 25,
    "length": 139
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#861-datasource-definition",
    "content": "Title: Introduction  8.6.1 Datasource definition ​. Content: You can define your datasource in yaml file inside  src/datasources  directory. For example, newDatasource.yaml is defined in the datasources.     .      ├── config      └── src          ├── datasources          │   └── httpbin.yaml          │   ├── kafka1.yaml          │   └── newDatasource.yaml          ├── events          ├── functions          └── mappings                      The three keys in yaml  type ,  loadFn  and  executeFn  are mandatory to define any new datasource which is not provided by the framework as core datasources. You can define other key/vaue pairs as per your need. Below is a sample of newDatasource.yaml     type: sample      loadFn: com.sample.loader      executeFn: com.sample.execute      client_url: https://sample.com      client_id: sample123",
    "title": "Introduction  8.6.1 Datasource definition ​",
    "tokens": 312,
    "length": 781
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#type",
    "content": "Title: Introduction 8.6.1 Datasource definition ​ type ​. Content: It defines the type of the datasource like api, soap, datastore, etc.",
    "title": "Introduction 8.6.1 Datasource definition ​ type ​",
    "tokens": 19,
    "length": 69
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#loadfn",
    "content": "Title: Introduction 8.6.1 Datasource definition ​ loadFn ​. Content: It defines the load function which loads the client for the datasource. The developer must define the load function in the workflows as mentioned in the below project structure. The loadFn can be a js/ts function which takes the datasource yaml as an input and return an object that contains client.     .      ├── config      └── src          ├── datasources          ├── events          ├── functions          │   └── com          │       └── sample          │           ├── loader.ts          │           └── execute.ts          └── mappings                     A sample of loader.ts     export default async function(args:{[key:string]:any;}) {          const ds = {              ...args,              client: new SampleClient(args)              };          return ds;          }",
    "title": "Introduction 8.6.1 Datasource definition ​ loadFn ​",
    "tokens": 347,
    "length": 783
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#executefn",
    "content": "Title: Introduction 8.6.1 Datasource definition ​ executeFn ​. Content: It defines the execute function which gets executed in the workflow. The developer must define the execute function in the workflows as mentioned in the above project structure. The executeFn can be a js/ts function which takes the  workflow args  as input and return status/output.     export default async function(args:{[key:string]:any;}) {          if(args.datasource) {              const client = args.datasource.client;              const data = args.data;                    if (!Array.isArray(args.data)) {                  data = [args.data];              }      . . . . . . . . . .              } else {              return { success: false, code: 500, data: 'datasource not found in the workflow' };          }      }",
    "title": "Introduction 8.6.1 Datasource definition ​ executeFn ​",
    "tokens": 291,
    "length": 730
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#862-example-spec-for-the-event",
    "content": "Title: Introduction  8.6.2 Example spec for the event ​. Content: /sample_helloworld.http.post  :            id  :   sample_event          fn  :   com.jfs.sample_helloworld          body  :               description  :   The body of the query            required  :     true              content  :                application/json  :     # For ex. application/json application/xml                  schema  :                     type  :   object                  properties  :                      name  :                         type  :   string                  required  :     [  name  ]",
    "title": "Introduction  8.6.2 Example spec for the event ​",
    "tokens": 309,
    "length": 523
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#863-example-spec-for-the-workflow",
    "content": "Title: Introduction  8.6.3 Example spec for the workflow ​. Content: summary  :   hello world        tasks  :            -     id  :   helloworld_step1            fn  :   com.sample.execute            args  :                datasource  :   newDatasource              data  :   <% inputs %  >                config  :                  method  :   sample",
    "title": "Introduction  8.6.3 Example spec for the workflow ​",
    "tokens": 169,
    "length": 283
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/intro",
    "content": "Title: Datasources  Datasources. Content: Any kind of entity which provides read and write mechanism for data is considered a datasource. For example, an API, a SQL or NoSQL datastore which includes RDBMS, key value stores, document stores etc. The settings for each datasource lies in  src/datasources  directory.",
    "title": "Datasources  Datasources",
    "tokens": 63,
    "length": 272
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/intro#811-datasource-types",
    "content": "Title: Datasources  8.1.1 Datasource types ​. Content: Currently supported types   API    Datastores  (SQL/NoSQL)  Postgres  Mysql  Mongodb     Kafka    Elasticsearch   Upcoming  S3  File system",
    "title": "Datasources  8.1.1 Datasource types ​",
    "tokens": 50,
    "length": 139
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/kafka",
    "content": "Title: Introduction  Introduction. Content: The framework supports kafka as a datasource. It helps in interacting with kafka, to send/receive events on a kafka message bus.",
    "title": "Introduction  Introduction",
    "tokens": 34,
    "length": 128
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/kafka#841-example-spec",
    "content": "Title: Introduction  8.4.1 Example spec ​. Content: The datasources for kafka are defined in  src/datasources . Here, two kafka clients  kafka1.yaml  and  kafka2.yaml  are defined in datasources.     .      ├── config      └── src          ├── datasources          │   └── httpbin.yaml          │   ├── kafka1.yaml          │   └── kafka2.yaml          ├── events          ├── functions          └── mappings                     Sample configuration in  kafka1.yaml      type: kafka      client_id: my_service      brokers: [ \"kafka:9092\" ]",
    "title": "Introduction  8.4.1 Example spec ​",
    "tokens": 247,
    "length": 488
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/redis",
    "content": "Title: Introduction  Introduction. Content: The framework supports Redis as a datasource. It helps to utilize redis in different ways.",
    "title": "Introduction  Introduction",
    "tokens": 20,
    "length": 90
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/datasources/redis#881-example-spec",
    "content": "Title: Introduction  8.8.1 Example spec ​. Content: The datasources for Redis are defined in  src/datasources . Here, Redis datasource is defined in  redis.yaml .     .      ├── config      └── src          ├── datasources          │   └── httpbin.yaml          │   ├── redis.yaml          ├── events          ├── functions          └── mappings                     Sample configuration in  redis.yaml      type: redis      url: redis[s]://[[username][:password]@][host][:port][/db-number]                     For full redis configuration, Refer  redis node client documentation .",
    "title": "Introduction  8.8.1 Example spec ​",
    "tokens": 239,
    "length": 528
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/developer-manual/intro",
    "content": "Title: introWork of the developer  intro. Content:",
    "title": "introWork of the developer  intro",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/developer-manual/intro",
    "content": "Title: introWork of the developer  Work of the developer. Content:",
    "title": "introWork of the developer  Work of the developer",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/developer-manual/intro#creating-data-services-or-module-services-like-document-or-notification-service-",
    "content": "Title: introWork of the developer  Creating Data services or module services like Document or Notification service   ​. Content: The developer will use scaffolding provided by the platform to setup a new microservice project. In the configuration template, (s)he will configure the microservice for the required functionality, data model & performance tunings. Once done, (s)he can migrate the DBs and run the microservice, using the CLI during the local development, and using the GitOps process for staging/production deployment. Simple settings will provide out of the box functionalities like JWT token based authorization, APIs for multi db CRUD, analytics, search, suggest, document, notifications, event publishing/subscription, observability. This can be used to run standalone domain agnostic functional services like notification service! Or to run a separate microservice which does only the job of data federation and nothing else (Such a service is called backend for frontend aka BFF)",
    "title": "introWork of the developer  Creating Data services or module services like Document or Notification service   ​",
    "tokens": 173,
    "length": 869
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/developer-manual/intro#creating-domain-gateway-orchestrators--servicese-",
    "content": "Title: introWork of the developer  Creating domain gateway, orchestrators & servicese   ​. Content: If for a domain microservice like Lead Origination System, there is any custom validations, business logic, event consumers, REST routes, orchestration flows etc that need to be written, the developer needs to add those within the microservice project, using the respective interface and scaffolding structure provided by the framework. This way a developer can get a custom microservice on top of the fundamental microservice framework capabilities. They can mix and match capabilities provided out of the box with custom capabilities added on top by them.",
    "title": "introWork of the developer  Creating domain gateway, orchestrators & servicese   ​",
    "tokens": 103,
    "length": 557
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events",
    "content": "Title: Events  Events. Content: A microservice can be configured to consume events from variety of  event sources , like HTTP, gRpc, GraphQl, S3 etc. The event schema, for each event source, closely follows the OpenAPI specification. It includes The name/topic/URL of the event  The event source and other information for the source (for ex. group_id in case of Kafka events)  The event handler workflow  Validation (input and output)  Examples of input and output The response of the event is flexible for the developer to change as per the requirement.",
    "title": "Events  Events",
    "tokens": 117,
    "length": 522
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events#61-event-types",
    "content": "Title: Events  6.1 Event types ​. Content: Currently supported  http.{method_type} For example, post or get  Kafka  salesforce  cron  Planned  Webhook  S3  gRPC  GraphQL  Websocket",
    "title": "Events  6.1 Event types ​",
    "tokens": 42,
    "length": 137
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events#62-event-schema--examples-for-supported-sources",
    "content": "Title: Events  6.2 Event schema & examples for supported sources ​. Content: All event declarations are stored in the src/events folder, in YAML files.",
    "title": "Events  6.2 Event schema & examples for supported sources ​",
    "tokens": 18,
    "length": 74
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events#621-json-schema-validation",
    "content": "Title: Events 6.2 Event schema & examples for supported sources ​ 6.2.1 JSON schema validation ​. Content: The framework provides request and response schema validation out of the box.Request schema validation ​ Sample spec for request schema.     body:        content:          application/json:            schema:              type: 'object'              required: []              properties:                dob:                  type: 'string'                  format : 'date'                  pattern : \"[0-9]{4}-[0-9]{2}-[0-9]{2}\"                     If request schema validation fails, then status code 400 is returned.Response schema validation ​ Sample spec for response schema.     responses: #Output data defined as per the OpenAPI spec        200:          description:          content:            application/json: # For ex. application/json application/xml              schema:                type: object                properties:                  application_id:                    type: string                additionalProperties: false                required: [application_id]              examples: # <string, ExampleObject>                example1:                  summary:                  description:                  value:                    application_id: PRM20478956N                  external_value:                     If response schema validation fails, then status code 500 is returned.",
    "title": "Events 6.2 Event schema & examples for supported sources ​ 6.2.1 JSON schema validation ​",
    "tokens": 648,
    "length": 1315
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events#622-http-event",
    "content": "Title: Events 6.2 Event schema & examples for supported sources ​ 6.2.2 HTTP event ​. Content: For an HTTP event, the headers, query, params and body data are captured in a standard format, and made available in the  inputs  object  for use in the workflows . The inputs (event) object has following properties:     - query: `<%inputs.query.var_name%>` # present in case of http events      - params: `<%inputs.params.path_param%>` # present in case of http events      - headers: `<%inputs.headers.some_header_key%>` # present in case of http events      - body: `<%inputs.body.key%>` # Present for all events except for http events which don't have a body. For ex. http.get      - files: `<%input.files%>` # Any files uploaded via HTTP event. Not present in other kind of events                     Example spec for HTTP event ​         /v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post  :     #Adding .http.post after            #the endpoint exposes the endpoint as REST via the POST method (in this example)            fn  :   com.biz.kyc.ckyc.ckyc_initiate   #The event handler written in ckyc_initiate.yml, and            # kept in src/workflows/com/biz/kyc/ckyc folder (in this example)            on_validation_error  :   com.jfs.handle_validation_error   # The validation error handler if event's json schema validation gets failed and            # kept in src/workflows/com/jfs/ folder (in this example)            body  :              required  :     true              content  :                application/json  :                  schema  :                    type  :     'object'                    required  :     [  ]                    properties  :                      dob  :      {     type     :     'string'  ,     format     :     'date'  ,     pattern     :     \"[0-9]{4}-[0-9]{2}-[0-9]{2}\"     }                      meta  :                        type  :     'object'                  params  :            -     name  :   lender_loan_application_id            in  :   params   # same as open api spec: one of cookie, path, query, header              required  :     true              allow_empty_value  :     false              schema  :                type  :   string          responses  :     #Output data defined as per the OpenAPI spec              200  :                description  :                required  :     # default value is false                content  :                  application/json  :     # For ex. application/json application/xml                    schema  :                      type  :   object                    properties  :                        application_id  :                          type  :   string                    additionalProperties  :     false                      required  :     [  application_id  ]                    examples  :     # <string, ExampleObject>                      example1  :                        summary  :                        description  :                        value  :                          application_id  :   PRM20478956N                      external_value  :                    encoding  :              400  :                description  :                required  :     # default value is false                content  :                  application/json  :     # For ex. application/json application/xml                    schema  :                      type  :   object                    properties  :                        lender_response_code  :                          type  :   string                  examples  :     # <string, ExampleObject>                      example1  :                        summary  :                        description  :                        value  :                          lender_response_code  :   E001                      external_value  :                  encoding  :                     Example workflow consuming an HTTP event ​          summary  :   Simply returning query & body data of an http.post event          id  :   some_unique_id          tasks  :              -     id  :   step1              fn  :   com.gs.return              args  :   <%inputs.body%  >     # Evaluation of dynamic values happens via <% %>. The type of scripting can be coffee/js.                # Here we are returning the body of the HTTP post event.                     Example workflow (on_validation_error handler) handling json schema validation error ​          summary  :   Handle json scehma validation error          id  :   error_handler          tasks  :              -     id  :   erorr_step1              fn  :   com.gs.kafka              args  :                  datasource  :   kafka1                data  :     # publish the event and validation error to kafka on a topic                    value  :                      event  :   <% inputs.event %  >                      validation_error  :   <% inputs.validation_error %  >                  config  :                    topic  :   kafka_error_handle                  method  :   publish",
    "title": "Events 6.2 Event schema & examples for supported sources ​ 6.2.2 HTTP event ​",
    "tokens": 2613,
    "length": 4931
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events#623-kafka-event",
    "content": "Title: Events 6.2 Event schema & examples for supported sources ​ 6.2.3 Kafka event ​. Content: A kafka event is specified as  {topic_name}.{datasourceName}.{group_id}  in  the kafka event specification . The  group_id  represents identifier for all the consumers of the group. Only one consumer of the group will consume a message. This is useful for microservices, when a single services runs in multiple K8s pods. Each pod is part of the same group. This ensures the message is eventually consumed by any one of the pods.The message body of a kafka event is captured and represented as  inputs.body  for  consumption in the handler workflow .Datasource for kafka ​ The datasources for kafka are defined in  src/datasources .  Refer Kafka as datasource  for more information.Example spec for kafka event ​      kafka-consumer1.kafka1.kafka_proj  :     # This event will be triggered whenever            # a new message arrives on the topic_name            id  :   /kafkaWebhook          fn  :   com.jfs.publish_kafka   #The event handler written in publish_kafka.yml, and            # kept in src/workflows/com/jfs folder (in this example)            on_validation_error  :   com.jfs.handle_validation_error   # The validation error handler if event's json schema validation gets failed and            # kept in src/workflows/com/jfs folder (in this example)            body  :              description  :   The body of the query            content  :                application/json  :     # For ex. application/json application/xml                  schema  :                    type  :   object                  properties  :                      name  :                        type  :   string                  required  :     [  name  ]                     Example workflow consuming a kafka event ​          summary  :   Handle kafka event          id  :   some_unique_id          tasks  :              -     id  :   step1              summary  :   Publish an event with this data              fn  :   com.gs.kafka              args  :     # similar to Axios format                  datasource  :   kafka1                config  :                    method  :   publish                  topic  :   publish  -  producer1                data  :                    value  :   <% inputs %  >                # Here we are publishing an event data to another topic                     Refer  com.gs.kafka  native function to publish an event on kafka.",
    "title": "Events 6.2 Event schema & examples for supported sources ​ 6.2.3 Kafka event ​",
    "tokens": 1028,
    "length": 2356
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events#624-salesforce-event",
    "content": "Title: Events 6.2 Event schema & examples for supported sources ​ 6.2.4 Salesforce event ​. Content: A salesforce event is specified as  {topic_name}.salesforce.{datasource_name}   topic_name is salaesforce event topic\n datasource_name  is name of the  salesforce datasource filenamePrerequisite: For using  salesforce , You need to enable  redis  datasource. You can enable  redis while creating a new  godspeed  project or run  godspeed update  on an existing project.  in  config/default.yaml add a property as  caching: redis . Where  redis  is datasource name. If your  redis  type datasource name is  redis1.yaml , then  caching: redis1  will be the correct configuration. Example of  salesforce datasource, eg:  src/datasources/salesforce.yaml      type  :   salesforce        connection  :              # Please Check  https:#jsforce.github.io/document/                    #1. Username and Password Login              # you can change loginUrl to connect to sandbox or prerelease env.              # loginUrl : 'https:#test.salesforce.com'                    #2. Username and Password Login (OAuth2 Resource Owner Password Credential)              oauth2  :                  # you can change loginUrl to connect to sandbox or prerelease env.                  # loginUrl : 'https:#test.salesforce.com',                  clientId     :     '<your Salesforce OAuth2 client ID is here>'                  clientSecret     :     '<your Salesforce OAuth2 client secret is here>'                  redirectUri     :     '<callback URI is here>'                    #3. Session ID              serverUrl     :     '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'              sessionId     :     '<your Salesforce session ID is here>'                    #4. Access Token              instanceUrl     :     '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'              accessToken     :     '<your Salesforrce OAuth2 access token is here>'                    #5. Access Token with Refresh Token              oauth2  :                  clientId     :     '<your Salesforce OAuth2 client ID is here>'                  clientSecret     :     '<your Salesforce OAuth2 client secret is here>'                  redirectUri     :     '<your Salesforce OAuth2 redirect URI is here>'              instanceUrl     :     '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'              accessToken     :     '<your Salesforrce OAuth2 access token is here>'              refreshToken     :     '<your Salesforce OAuth2 refresh token is here>'                username  :   <% config.salesforce_username %  >          password  :   <% config.salesforce_password %  >                     Example of  salesforce  event:     {  topic_name  }  .salesforce.  {  datasourceName  }          id  :   /salesforcetopic        fn  :   com.jfs.handle_title_events        on_validation_error  :   com.jfs.handle_validation_error        body  :            description  :   The body of the query          content  :              application/json  :                schema  :                  type  :   object                properties  :                    name  :                      type  :   string                required  :     [  name  ]",
    "title": "Events 6.2 Event schema & examples for supported sources ​ 6.2.4 Salesforce event ​",
    "tokens": 1461,
    "length": 3175
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/events#625-cron-event",
    "content": "Title: Events 6.2 Event schema & examples for supported sources ​ 6.2.5 CRON event ​. Content: A CRON event will allow you to run events at scheduled time / interval. A CRON event is specified as  {schedule_expression.cron.timezone}     schedule_expression  You can refer  crontab  to generate schedule.     timezone  Refer  this wikipedia  to get the timezone format.  Here is an example of a CRON event which run every minute.   every_minute_cron.yaml      \"* * * * *.cron.Asia/Kolkata\"  :           fn  :   com.every_minute                       and corresponding function is   com/every_minute.yaml         summary  :   this workflow will be running every minute         tasks  :             -     id  :   print             description  :   print every             fn  :   com.gs.log             args  :                 level  :   info               data  :   HELLO from CRON",
    "title": "Events 6.2 Event schema & examples for supported sources ​ 6.2.5 CRON event ​",
    "tokens": 336,
    "length": 784
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/intro",
    "content": "Title: Introduction  Introduction. Content: Every microservice in the Godspeed framework has three fundamental abstractions, and the developer needs to work with just these three.  Events : Events trigger workflows. Events are generated by event sources like REST endpoints, gRPC, message bus, webhooks, websockets, S3, and more...   Workflows : Workflows are triggered by events. They not only perform business logic but also provide orchestration over datasources and microservices, and data/API federation. They will use datasources to store or retrieve data, join across various datasources, transform data, emit events and send responses. The framework provides a YAML dsl with some  inbuilt workflows . If YAML does not suffice for any particular case, developers can currently put JS/TS workflows alongside YAML workflows and use them.  Coming in future : Support for other languages.   Datasources : Datasources are locations where data can be stored or read from. For example API datasource (another microservice or third party), datastores (RDBMS, document, key-value), file system, S3 storage, etc. A microservice can use multiple datasources. The framework provides abstractions for Authn/Authz making it easy for the developer to express the same in a low code manner.  These abstractions allow the developer to focus purely on their business logic. 99.9% - 100% of typical functionality needed by the developer is covered by the framework's YAML-based DSL. Devs can forget about the low-level stuff they typically need to do - which accounts for 90% of the work in typical app dev scenario. The framework aims to handle all the low level functionality and saves developer's effort to do the same. For example creating controllers for endpoints, endpoint authentication/authorization, input validation, auto-telemetry with distributed context, setting up DB client and authorizing DB access, authentication of third party API, key management, creating Swagger docs or Postman collection, creating basic test suite based on documentation, etc.There is a standard  project structure  which will give the developer a kickstart to their project and also reference code/declarations, for the kind of stuff they can do using the framework.",
    "title": "Introduction  Introduction",
    "tokens": 469,
    "length": 2202
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/intro#21-developers-work",
    "content": "Title: Introduction  2.1 Developer's work ​. Content: The developer will use the CLI provided by the framework to setup a new microservice project and start developing. (S)he will configure the events, datasources, and workflows for the required functionality, along with mappings, environment variables, and common configurations, like for telemetry. To configure the datasources,  For datastores: they will either define the db schema or autogenerate it from the existing database using the CLI.   For APIs: they will need to define the APIs OpenAPI schema or provide the url for the same.",
    "title": "Introduction  2.1 Developer's work ​",
    "tokens": 114,
    "length": 537
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/intro#salient-features",
    "content": "Title: Introduction 2.1 Developer's work ​ Salient Features ​. Content: Note   Some of the features mentioned here are in the product roadmap and planned for upcoming releases.   Schema driven development The developer has to specify the API and data schema to start the development. YAML based DSL and configurations We have YAML based DSL which makes it much easier and succinct to express policies, business logic, and configurations. Code is shorter and easier to comprehend than programming, even for new learners. This DSL can be further customized by developers to add custom requirements.  Multi datastore support The same model configuration & unified CRUD API (including full-text search and autosuggest) will provide interfaces with multiple kinds of datastores (SQL or NoSQL). The API is aimed to provide validation, relationship management, transactions, denormalization, and multilingual support. Each integration will support the possible functionality as per the nature of the store.   Data validation The framework provides validation of third party API requests & responses, datastore queries, and its own API endpoints request and response. The developer only needs to specify the schema of third party API, own microservice API, and datastore model. Rest is taken care of by the framework. In case of more complex validation scenarios, where customer journeys may require conditional validation of incoming requests based on some attributes (in the database or the query {i.e. subject, object, environment, payload}), the developer can add such rules to the application logic as part of the workflows. Authentication The microservice framework authenticates every incoming request and extracts the user role and other info, for further processing, based on a valid JWT token. An IAM provider like ORY Kratos can be integrated into the platform for providing identity service. It will generate a JWT token which will include user id, information, and roles. This token is consumed by the microservices for user validation. Authorization   (  Planned  ) Each microservice will do the job of authorization for any request. Developers will write authorization rules for every microservice in simple configuration files. This will cover not only API endpoint access but also fine grained data access from datastores. This will integrate with third party Authz services in a pluggable way, with abstractions.  Distributed transactions   (  Planned  ) Each domain’s orchestrator is able to use the Saga  pattern  to ensure distributed transactions across multiple microservices. Autogenerated documentation The framework provides autogenerated documentation using CLI. Autogenerated CRUD API    (  Planned  ) The framework provides autogenereated CRUD APIs from database model. Generated API's can be extended by the developers as per their needs. Autogenerated test suite  The framework provides autogenerated test suite for APIs using CLI.  Multiple languages support In case YAML is not enough for a corner case, developers can write custom business logic in any language. If written in JS/TS, they can place the code within the same microservice project. Other language support will also work in the same way, and is planned for the future. Observability The framework provides automatic  observability  support with correlation, for modern distributed systems, via the OpenTelemetry spec. For the same, it will work in conjunction with the microservice mesh used. The developer can extend that to include customized observability. This can integrate with any tools that support OpenTelemetry.LoggingThe inbuilt logging mechanism will log both sync request/response cycle or async events, for both success and failure scenarios. MonitoringThe framework allows the developer to monitor custom business metrics, along with application level metrics like latency, success, and failures. TracingEvery incoming sync & async request will carry trace information in its headers. The same is propagated further through the microservice framework when it makes a sync or async hit to another service.",
    "title": "Introduction 2.1 Developer's work ​ Salient Features ​",
    "tokens": 795,
    "length": 4036
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli",
    "content": "Title: Godspeed CLI  Godspeed CLI. Content: The CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.",
    "title": "Godspeed CLI  Godspeed CLI",
    "tokens": 33,
    "length": 176
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#41-functionality",
    "content": "Title: Godspeed CLI  4.1 Functionality ​. Content:",
    "title": "Godspeed CLI  4.1 Functionality ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#outside-the-dev-container",
    "content": "Title: Godspeed CLI 4.1 Functionality ​ Outside the dev container ​. Content: Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.  Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.  List the versions of gs_service.  Change the version of gs_service.",
    "title": "Godspeed CLI 4.1 Functionality ​ Outside the dev container ​",
    "tokens": 73,
    "length": 335
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#inside-the-dev-container",
    "content": "Title: Godspeed CLI 4.1 Functionality ​ Inside the dev container ​. Content: All Prisma commands including DB push, pull or migration.  OAS 3 documentation file generation.  Test suite/Postman collection generation.  Running test suite.",
    "title": "Godspeed CLI 4.1 Functionality ​ Inside the dev container ​",
    "tokens": 34,
    "length": 159
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#42-installation",
    "content": "Title: Godspeed CLI  4.2 Installation ​. Content: npm install -g @mindgrep/godspeed                     Once Godspeed CLI is installed, the  godspeed  command can be called from command line. When called without arguments, it displays its help and command usage.     $ godspeed                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Usage: godspeed [options] [command]            Options:        -v, --version                   output the version number        -h, --help                      display help for command            Commands:        create [options] <projectName>        versions                        List all the available versions of gs_service        prepare                         prepare the containers, before launch or after cleaning the containers        version <version>        help [command]                  display help for command",
    "title": "Godspeed CLI  4.2 Installation ​",
    "tokens": 618,
    "length": 1156
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#43-options",
    "content": "Title: Godspeed CLI  4.3 Options ​. Content:",
    "title": "Godspeed CLI  4.3 Options ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#--version--v",
    "content": "Title: Godspeed CLI 4.3 Options ​ --version (-v) ​. Content: The --version option outputs information about your current godspeed version.     $ godspeed -v                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                0.0.26",
    "title": "Godspeed CLI 4.3 Options ​ --version (-v) ​",
    "tokens": 324,
    "length": 503
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#--help--h",
    "content": "Title: Godspeed CLI 4.3 Options ​ --help (-h) ​. Content: The --help option displays help and command usage.     $ godspeed                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Usage: godspeed [options] [command]            Options:        -v, --version                   output the version number        -h, --help                      display help for command            Commands:        create [options] <projectName>        versions                        List all the available versions of gs_service        prepare                         prepare the containers, before launch or after cleaning the containers        version <version>        help [command]                  display help for command",
    "title": "Godspeed CLI 4.3 Options ​ --help (-h) ​",
    "tokens": 563,
    "length": 994
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#44-commands-outside-the-dev-container",
    "content": "Title: Godspeed CLI  4.4 Commands Outside the dev container ​. Content:",
    "title": "Godspeed CLI  4.4 Commands Outside the dev container ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#create",
    "content": "Title: Godspeed CLI 4.4 Commands Outside the dev container ​ create ​. Content: The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.     $ godspeed create my_service                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefined      project created      Do you need mongodb? [y/n] [default: n] n      Do you need postgresdb? [y/n] [default: n] y      Please enter name of the postgres database [default: test]       Do you need kafka? [y/n] [default: n] n      Do you need elastisearch? [y/n] [default: n] n      Please enter host port on which you want to run your service [default: 3000] 3100      Fetching release version information...      Please select release version of gs_service from the available list:      latest      1.0.0      1.0.1      1.0.10      1.0.11      1.0.12      1.0.13      1.0.2      1.0.3      1.0.4      1.0.5      1.0.6      1.0.7      1.0.8      1.0.9      base      dev      v1.0.13      Enter your version [default: latest] 1.0.13      Selected version 1.0.13      . . . . . . . .                      Options ​      $ godspeed help create                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Usage: godspeed create [options] <projectName>            Options:        -n, --noexamples                      create blank project without examples        -d, --directory <existing_project_directory>  existing project template dir        -h, --help                            display help for command",
    "title": "Godspeed CLI 4.4 Commands Outside the dev container ​ create ​",
    "tokens": 1202,
    "length": 2200
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#update",
    "content": "Title: Godspeed CLI 4.4 Commands Outside the dev container ​ update ​. Content: The update can be executed in the following cases: If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute  godspeed update  command before launching the project.  If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute  godspeed update  with the required settings.  If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute  godspeed update command. It fetches the new docker image itself.  Please note that the command should be executed from inside the project root directory.        note   Whenever you update your project using  godspeed update  and open the project in VScode dev container after update, then it is mandatory to do   godspeed build   inside dev container for the first time.       $ godspeed update                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Do you need postgresdb? [y/n] [default: n]       Do you need kafka? [y/n] [default: n]       Do you need elastisearch? [y/n] [default: n]       Please enter host port on which you want to run your service [default: 3000]       Fetching release version information...      Please select release version of gs_service from the available list:      latest      1.0.0      1.0.1      1.0.2      1.0.3      1.0.4      dev      stable      Enter your version [default: latest]       Selected version latest      Removing dev_test_devcontainer_node_1                ...       . . . . . . . . . .      Step 1/9 : FROM adminmindgrep/gs_service:latest      latest: Pulling from adminmindgrep/gs_service      824b15f81d65: Already exists      325d38bcb229: Already exists      d6d638bf61bf: Already exists      55daac95cedf: Already exists      4c701498752d: Already exists      a48b0ae49665: Pulling fs layer      4c393fb6deac: Pulling fs layer      4f4fb700ef54: Pulling fs layer      8992963a9530: Pulling fs layer      4f4fb700ef54: Verifying Checksum      4f4fb700ef54: Download complete      4c393fb6deac: Verifying Checksum      4c393fb6deac: Download complete      8992963a9530: Verifying Checksum      8992963a9530: Download complete      a48b0ae49665: Verifying Checksum      a48b0ae49665: Download complete      a48b0ae49665: Pull complete      4c393fb6deac: Pull complete      4f4fb700ef54: Pull complete      8992963a9530: Pull complete      Digest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278ee      Status: Downloaded newer image for adminmindgrep/gs_service:latest       ---> 988917710d1a      Step 2/9 : ARG USERNAME=node       ---> Running in c70404bb4f3e      Removing intermediate container c70404bb4f3e       ---> 47a7406b2473      Step 3/9 : ARG USER_UID=1000       ---> Running in 51e68336d8d8      Removing intermediate container 51e68336d8d8       ---> ce913f6898bb      Step 4/9 : ARG USER_GID=$USER_UID       ---> Running in 7cf1c1f2a3ec      Removing intermediate container 7cf1c1f2a3ec       ---> 91f045b32e0f      Step 5/9 : USER root       ---> Running in f338d755a032      Removing intermediate container f338d755a032       ---> fa9898eb4c23      Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development       ---> Running in eba3659fb919      Removing intermediate container eba3659fb919       ---> 414f34560b0d      Step 7/9 : USER node       ---> Running in 23818c5f4882      Removing intermediate container 23818c5f4882       ---> 1bd65323ae91      Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed       ---> Running in a66cb062390d      . . . . . . . . . .       godspeed update dev_test is done.",
    "title": "Godspeed CLI 4.4 Commands Outside the dev container ​ update ​",
    "tokens": 1773,
    "length": 4215
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#versions",
    "content": "Title: Godspeed CLI 4.4 Commands Outside the dev container ​ versions ​. Content: The versions command lists all the versions available of gs_service.     $ godspeed versions                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                latest      1.0.0      1.0.1      1.0.10      1.0.11      1.0.12      1.0.13      1.0.2      1.0.3      1.0.4      1.0.5      1.0.6      1.0.7      1.0.8      1.0.9      base      dev      v1.0.13",
    "title": "Godspeed CLI 4.4 Commands Outside the dev container ​ versions ​",
    "tokens": 483,
    "length": 690
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#version",
    "content": "Title: Godspeed CLI 4.4 Commands Outside the dev container ​ version ​. Content: The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.     $ godspeed version 1.0.13                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Generating prisma modules      Starting test1_devcontainer_postgres_1 ...       Starting test1_devcontainer_postgres_1 ... done      Creating test1_devcontainer_node_run   ...       Creating test1_devcontainer_node_run   ... done      Environment variables loaded from .env      . . . . . . . . . .",
    "title": "Godspeed CLI 4.4 Commands Outside the dev container ​ version ​",
    "tokens": 444,
    "length": 873
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#help",
    "content": "Title: Godspeed CLI 4.4 Commands Outside the dev container ​ help ​. Content: The help command displays help and usage for any command.     $ godspeed help create                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                Usage: godspeed create [options] <projectName>            Options:        -n, --noexamples                      create blank project without examples        -d, --directory <projectTemplateDir>  local project template dir        -h, --help                            display help for command",
    "title": "Godspeed CLI 4.4 Commands Outside the dev container ​ help ​",
    "tokens": 447,
    "length": 777
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#45-commands-inside-the-dev-container",
    "content": "Title: Godspeed CLI  4.5 Commands Inside the dev container ​. Content:",
    "title": "Godspeed CLI  4.5 Commands Inside the dev container ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#prisma",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ prisma ​. Content: You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection.  Read more here .      $ godspeed prisma <prisma command with args>",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ prisma ​",
    "tokens": 51,
    "length": 219
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#build",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ build ​. Content: You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer  Open in Dev container      godspeed build",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ build ​",
    "tokens": 46,
    "length": 205
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#dev",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ dev ​. Content: You can run your project using dev command.     godspeed dev",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ dev ​",
    "tokens": 16,
    "length": 60
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#gen-api-docs",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ gen-api-docs ​. Content: You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.     $ godspeed gen-api-docs                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                      > proj_upd@1.0.0 gen-api-docs      > node ../gs_service/dist/api-specs/api-spec.js | pino-pretty            [1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events      [1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml      [1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ gen-api-docs ​",
    "tokens": 731,
    "length": 1581
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#gen-test-suite",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ gen-test-suite ​. Content: You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly.      godspeed gen-test-suite                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                      > proj_upd@1.0.0 gen-test-suite      > npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false                  > proj_upd@1.0.0 gen-api-docs      > node ../gs_service/dist/api-specs/api-spec.js | pino-pretty            [1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events      [1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml      [1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!      Input file:  /workspace/development/app/docs/api-doc.yaml      Writing to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }      Conversion successful, collection written to file",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ gen-test-suite ​",
    "tokens": 932,
    "length": 2131
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#gen-crud-api",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ gen-crud-api ​. Content: You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.     $ godspeed gen-crud-api                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                      > eg_test@1.0.0 gen-crud-api      > npx godspeed-crud-api-generator            Select datasource / schema to generate CRUD APIs      (x) elasticgraph.yaml      ( ) For all      ( ) Cancel",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ gen-crud-api ​",
    "tokens": 432,
    "length": 794
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#test",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ test ​. Content: You can run the test suite generated in above command from the following two ways: Postman: Import the collection in postman and run the test suite.  CLI: You can use below command to run the test suite from CLI.  Please make sure your service is up and running before running the test suite.       godspeed test                            _                                   _          __ _    ___     __| |  ___   _ __     ___    ___    __| |        / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |       | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |        \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|        |___/                        |_|                                      > proj_upd@1.0.0 test      > newman run tests/test-suite.json            newman            Godspeed: Sample Microservice            → Call another (sub) workflow from main workflow        POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]      . . . . . . . .",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ test ​",
    "tokens": 507,
    "length": 1010
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/introduction-cli#help-1",
    "content": "Title: Godspeed CLI 4.5 Commands Inside the dev container ​ help ​. Content: The help command displays help and usage for any command.  Click here to know more",
    "title": "Godspeed CLI 4.5 Commands Inside the dev container ​ help ​",
    "tokens": 17,
    "length": 82
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/mappings",
    "content": "Title: Mappings  Mappings. Content: Mappings is a global object which will be available in your microservice. You can define anything in the mappings i.e. key/value pair map, array, etc. You can access these mappings inside your workflows at any time.",
    "title": "Mappings  Mappings",
    "tokens": 51,
    "length": 215
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/mappings#101-project-structure",
    "content": "Title: Mappings  10.1 Project structure ​. Content: Mappings are present in  src/mappings  directory. The default format is yaml and you can store mappings in the nested directories also. The nested directories are also accessible in the same  mappings  object.     .      ├── config      └── src          └── mappings              └── index.yaml              └── generate.yaml",
    "title": "Mappings  10.1 Project structure ​",
    "tokens": 121,
    "length": 325
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/mappings#102-sample-mappings",
    "content": "Title: Mappings  10.2 Sample mappings ​. Content: This is a sample mapping which is accessible in the workflows inside mappings object using  mappings.Gender  and  mappings.generate.genId     index.yaml      Gender  :            Male  :   M          Female  :   F          Others  :   O                      generate.yaml      genId  :     12345                            Note   If the file name is index.yaml then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the mappings object like  mappings.Gender .  \nHowever, for other file names you need to mention the file name while accessing the mappings object like  mappings.generate.genId   Smaple workflow accessing mappings object:       - id: httpbinCof_step1          description: Hit http bin with some dummy data. It will send back same as response          fn: com.gs.http          args:            datasource: httpbin            params:            data:              personal_email_id: 'ala.eforwich@email.com'              gender: <% mappings.Gender[inputs.body.Gender] %>              id:  <% mappings.generate.genId %>            config:              url : /anything              method: post",
    "title": "Mappings  10.2 Sample mappings ​",
    "tokens": 497,
    "length": 1168
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/mappings#103-use-mappings-constants-in-other-mapping-files",
    "content": "Title: Mappings  10.3 Use mappings constants in other mapping files ​. Content: You can use mapping constants in other mapping files using coffee/js scripting.For example, you have mapping files  index.yaml ,  relations.json  and  reference.yaml . Use the mappings from first two files as reference in the third file as follows:    index.yaml      Gender  :            Male  :   M          Female  :   F          Others  :   O                      relations.json      {              \"id\"  :     1  ,              \"title\"  :     \"Hello World\"  ,              \"completed\"  :     false          }                      reference.yaml      NewGender  :   <% mappings.Gender.Others %  >          title  :    <% mappings.relations.title %  >",
    "title": "Mappings  10.3 Use mappings constants in other mapping files ​",
    "tokens": 309,
    "length": 654
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/plugins",
    "content": "Title: Plugins  Plugins. Content: Plugins are small js/ts functions to enhance the workflows capabilities. You can write any piece of code in the plugin and can access it inside your workflows at any time.",
    "title": "Plugins  Plugins",
    "tokens": 37,
    "length": 171
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/plugins#111-project-structure",
    "content": "Title: Plugins  11.1 Project structure ​. Content: Plugins are present in  src/plugins  directory. The default format is js/ts and you can store plugins in the nested directories also.     .      ├── config      └── src          └── plugins              └── index.ts              └── time                  └── epoch.ts              └── epoch                  └── convertEpoch.ts",
    "title": "Plugins  11.1 Project structure ​",
    "tokens": 165,
    "length": 327
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/plugins#112-sample-plugins",
    "content": "Title: Plugins  11.2 Sample plugins ​. Content: These are the sample plugins file which export plugin functions named  randomInt  and  convertEpochToDate . plugins/index.ts      export     function     randomInt  (  min  :     number  ,   max  :     number  )     {              return   Math  .  floor  (  Math  .  random  (  )     *     (  max   -   min   +     1  )  )     +   min  ;          }                      plugins/time/epoch.ts      import   format   from     'date-fns/format'  ;                export     function     convertEpochToDate  (  inputTimestamp  :     string  )  {              const   newDateTime   =     new     Date  (  inputTimestamp  )  ;              return     format  (  newDateTime  ,     'yyyy-MM-dd HH:mm:ss'  )  ;          }                      plugins/epoch/convertEpoch.ts      import   format   from     'date-fns/format'  ;                export     default     function     convertEpoch  (  inputTimestamp  :     string  )  {              const   newDateTime   =     new     Date  (  inputTimestamp  )  ;              return     format  (  newDateTime  ,     'yyyy-MM-dd HH:mm:ss'  )  ;          }                            Note    If the file name is index.ts then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the plugin e.g.  randomInt .      For other file names you need to mention the file name using underscore notation while accessing the plugins function inside your workflow e.g.  time_epoch_convertEpochToDate   If it's a default import then you don't need to mention the plugin function name e.g.  epoch_convertEpoch",
    "title": "Plugins  11.2 Sample plugins ​",
    "tokens": 713,
    "length": 1591
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/plugins#113-sample-workflow-using-plugins",
    "content": "Title: Plugins  11.3 Sample workflow using plugins ​. Content: You can use these plugins in your workflows as given below:       - id: httpbinCof_step1          description: Hit http bin with some dummy data. It will send back same as response          fn: com.gs.http          args:            datasource: httpbin            params:            data:              personal_email_id: 'ala.eforwich@email.com'              id: <% 'UID-' + randomInt(1,9) %>              date: <% time_epoch_convertEpochToDate(inputs.body.datetimestamp) %>              default_date: <% epoch_convertEpoch(inputs.body.datetimestamp) %>            config:              url : /anything              method: post",
    "title": "Plugins  11.3 Sample workflow using plugins ​",
    "tokens": 309,
    "length": 626
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/scaffolding",
    "content": "Title: Scaffolding  Scaffolding. Content:",
    "title": "Scaffolding  Scaffolding",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/auto-watch",
    "content": "Title: Auto watch and build  Auto watch and build. Content: The framework provides auto watch/build feature to detect the changes in you project files. This feature is only applicable when you are working inside dev container.          note   Please make sure VS code 'Run On Save' plugin is installed in your dev container environment.  Here is the list of files which are being watched inside the dev container.     src/**/*.yaml|yml|js|json      src/**/*.ts      src/**/*.prisma      src/**/*.toml                       *.prisma files \nThese files are being watched for  Datastore as datasources  During any datastore setup via Prisma in the dev container, you don't need to setup anything explicitily, the watch feature automatically takes care of setting up the datastores. Refer  Prisma Datastore Setup  for more information.   *.toml files \nThese files are being watched for configuration files of  Elasticgraph as datasource . If there is any change in *.toml file then auto watch reindexes all the elasticgraph datasources configuration inside  src/datasources/eg_config/  directory.",
    "title": "Auto watch and build  Auto watch and build",
    "tokens": 281,
    "length": 1032
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/configuration/env-vars",
    "content": "Title: Environment variables  Environment variables. Content: The environment variables are defined in yaml files under  config/custom-environment-variables.yaml  file. The default directory structure is given as below:     ├── config      │   ├── custom-environment-variables.yaml                            note   Any configuration which includes secrets or passwords is recommended to be defined using environment variables only.",
    "title": "Environment variables  Environment variables",
    "tokens": 104,
    "length": 370
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/configuration/env-vars#custom-environment-variablesyaml",
    "content": "Title: Environment variables  custom-environment-variables.yaml ​. Content: This is a sample for custom environment variables where these variables gets values from environment variables set in the environment.      my_datasource:        base_url: MY_DATASOURCE_BASE_URL        api_key: MY_DATASOURCE_API_KEY        api_token: MY_DATASOURCE_API_TOKEN            kafka:        brokers:          __name: KAFKA_BROKERS          __format: json        client_id: KAFKA_CLIENT_ID            jwt:        issuer: JWT_ISS        audience: JWT_AUD        secretOrKey: JWT_SECRET            prisma_secret: PRISMA_SECRET                     For example,  MY_DATASOURCE_BASE_URL  is defined as an environment variable. To specify its value, you need to export this variable in the environment as given below:     $ export MY_DATASOURCE_BASE_URL=https://httpbin.org/                     After exporting the environment variable, you can access this variable in your project by using scripting  <% config.my_datasource.base_url %>",
    "title": "Environment variables  custom-environment-variables.yaml ​",
    "tokens": 389,
    "length": 939
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/configuration/intro",
    "content": "Title: 3.3.1 Introduction  3.3.1 Introduction. Content:",
    "title": "3.3.1 Introduction  3.3.1 Introduction",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/configuration/intro#file-naming-and-load-order",
    "content": "Title: 3.3.1 Introduction  File Naming and Load Order ​. Content: The configuration files under  config/  directory can have specific naming conventions and load order. Please refer  File Name and Load Order  for more information.",
    "title": "3.3.1 Introduction  File Naming and Load Order ​",
    "tokens": 31,
    "length": 164
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/configuration/static-vars",
    "content": "Title: Static variables  Static variables. Content: The static variables as well as their values are defined in yaml files under  config/  directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:     ├── config      │   ├── default.yaml                            note   Any configuration which includes secrets or passwords is recommended to be defined using environment variables only. Avoid using static variables for secrets and passwords.",
    "title": "Static variables  Static variables",
    "tokens": 116,
    "length": 459
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/configuration/static-vars#defaultyaml",
    "content": "Title: Static variables  default.yaml ​. Content: This file contains some predefined variables. Below is a sample file which defines the static variables used in Godspeed.     log_level  :   debug        lang  :   coffee        redact  :     [  ]     # fields to hide. Sample: ['ns', 'req.headers']          server_url  :   https  :  //api.example.com  :  8443/v1/api        httpbin  :     # sample api datasource url            base_url  :   https  :  //httpbin.org                      log_level  is the minimum log level to log. Log messages with a lower limit will not get logged. The default value is 'info'.  \nThe available levels are 'fatal', 'error', 'warn', 'info', 'debug', 'trace' or 'silent'.  \n lang  is the language used for scripting in the workflows. The default value is 'coffee'.  \nThe available values are 'coffee' or 'js'. Refer  Coffee/JS scripting  for more information.  \n redact  is the list of fields, the values for which, you want to hide from the logs. The default value is blank. Refer  Logs field masking  for more information.  \n server_url  is the custom server url which you want to use as  Servers  in swagger specs/auto generated documentation. Refer  Custom Server URL",
    "title": "Static variables  default.yaml ​",
    "tokens": 380,
    "length": 1154
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/getting-started",
    "content": "Title: Getting started  Getting started. Content: Hereby is a step by step guide on running your first project. The setup is independent of the OS you are running it on.       info   You can also refer to tutorial on  Getting Started with Godspeed .",
    "title": "Getting started  Getting started",
    "tokens": 50,
    "length": 199
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/getting-started#311-glossary",
    "content": "Title: Getting started  3.1.1 Glossary ​. Content: gs_service : The framework code version. During this setup, you will be asked to select the version of gs_service.  \n Remote containers/Dev containers : Refer  VSCode Remote containers  for more information.",
    "title": "Getting started  3.1.1 Glossary ​",
    "tokens": 48,
    "length": 207
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/getting-started#312-pre-requisites",
    "content": "Title: Getting started  3.1.2 Pre-requisites ​. Content: Please ensure you have the following in your machine NVM, with Node LTS installed (Currently 16+)  Visual Studio Code LTS, with the following plugins installed:   Remote Containers    Run on Save  Refer  Run On Save    Godspeed Extension Pack     Docker-desktop should be up and running.  On Linux systems, please ensure that docker compose plugin is installed. You can verify it by executing  docker compose version  command. Refer  Install Compose plugin  for more information.    Git   Hardware recommendations    \nRAM: 8GB  \nHard Disk: SSD       tip    Depending your setup, you may need to run the above command using administrator privileges  On Windows machines, sometimes Docker-desktop doesn't start. Make sure you have WSL installed with Ubuntu 18.04, for Docker to work fine.",
    "title": "Getting started  3.1.2 Pre-requisites ​",
    "tokens": 190,
    "length": 786
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/getting-started#313-steps-to-get-started",
    "content": "Title: Getting started  3.1.3 Steps to get started ​. Content: Step1: Install the Godspeed CLI ​      npm install -g @mindgrep/godspeed                     Step 2: Setting up a project on your local machine ​        note    If you are creating a new project then follow  section 2.1   OR     If you are setting up a project from any existing git repository then follow  section 2.2    2.1 Create a new project ​      godspeed create my_test_project                     During the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.  By default,  latest  version is selected for gs_service. You should select either  latest  or any highest semantic version available in the list. 2.2 Setting up a project from an existing GIT repository ​ Clone the git repository on your local machine.      cd <your git repo>      godspeed update                     During the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.  By default,  latest  version is selected for gs_service. You should select either  latest  or any highest semantic version available in the list. Step3: cd to your project ​      cd <your project directory>                           Step4: Start Visual Studio from the project directory ​      code .                           Step 5: Open in Dev container ​  Again click on the dev container tray icon. If this is your first time, click on  Open folder in Dev Container  . Else for every other time, click on  Re-open in Dev Container   Step 6: Building the project ​        godspeed build                     Step 7: Start the service for local development in watch mode ​        godspeed dev                            tip   With the dev container running, we have auto watch and auto build enabled when you make changes to your project files. You don't need to run build manually everytime you make changes.",
    "title": "Getting started  3.1.3 Steps to get started ​",
    "tokens": 610,
    "length": 1915
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/getting-started#314-time-to-start-the-development",
    "content": "Title: Getting started  3.1.4 Time to start the development ​. Content: If you have successfully reached here, then it is time to start the development of your project!",
    "title": "Getting started  3.1.4 Time to start the development ​",
    "tokens": 19,
    "length": 96
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/scaffolding",
    "content": "Title: Introduction  Introduction. Content: The project root folder gets created in current folder under the  projectName  which is used in  godspeed create  command using godspeed CLI. The project contains two folders:  src/  and  config/ . Click  here  for more information on  godspeed create  command.",
    "title": "Introduction  Introduction",
    "tokens": 60,
    "length": 261
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/scaffolding#321-scaffolding--project-structure",
    "content": "Title: Introduction  3.2.1 Scaffolding & Project structure ​. Content: Project Structure with no examples ​ The project contains blank structure with no examples/templates when it is created using  godspeed create -n  command option. Refer  command here  for more information.       .      ├── config      │   ├── custom-environment-variables.yaml      │   ├── default.yaml      │   ├── index.yaml      │   └── telemetry      ├── package.json      └── src          ├── datasources          ├── events          ├── functions          └── mappings                     Project Structure with examples ​ The project contains following heirarchy with examples when it is created without using  godspeed create -n  command option. Refer  command here  for more information.       .      ├── config      │   ├── custom-environment-variables.yaml      │   ├── default.yaml      │   ├── index.yaml      │   └── telemetry      │       └── index.yaml      ├── package.json      └── src          ├── datasources          │   └── httpbin.yaml          ├── events          │   ├── call_another_workflow.yaml          │   ├── document.yaml          │   ├── helloworld.yaml          │   ├── httpbin_anything.yaml          │   ├── run_tasks_in_parallel.yaml          │   ├── sum.yaml          │   └── switch_case.yaml          ├── functions          │   └── com          │       └── biz          │           ├── call_another_wf.yaml          │           ├── documents          │           │   └── upload_file.yaml          │           ├── helloworld.yaml          │           ├── httpbin_anything.yaml          │           ├── run_tasks_in_parallel.yaml          │           ├── sub_wf.yaml          │           ├── sum.js          │           ├── sum_workflow.yaml          │           └── switch_case.yaml          └── mappings              └── index.yaml",
    "title": "Introduction  3.2.1 Scaffolding & Project structure ​",
    "tokens": 861,
    "length": 1769
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/setup/tests",
    "content": "Title: Introduction  Introduction. Content: Godspeed provides a facility to auto-generate and run test suite using CLI.  Click on  auto-generate test suite  for more information on generating the test suite and  run test suite  for more information on running the test suite.",
    "title": "Introduction  Introduction",
    "tokens": 51,
    "length": 231
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/swagger-specs",
    "content": "Title: Introduction  Introduction. Content: You can access autogenerated Swagger API specifications at  <domain name>/api-docs  url.  \nFor example,      http://localhost:3000/api-docs                     Godspeed also provides a facility to auto-generate OAS 3 documentation using CLI.",
    "title": "Introduction  Introduction",
    "tokens": 82,
    "length": 241
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/swagger-specs#51-cli-command-to-generate-documentation",
    "content": "Title: Introduction  5.1 CLI command to generate documentation ​. Content: You can generate OAS3 documentation using   godspeed gen-api-docs   CLI command.",
    "title": "Introduction  5.1 CLI command to generate documentation ​",
    "tokens": 22,
    "length": 80
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/swagger-specs#52-custom-server-url",
    "content": "Title: Introduction  5.2 Custom Server URL ​. Content: You can add custom server URL for API documentation in  static configuration \nBy adding the custom server url, your autogenerated documentation or swagger specs will have this url set in the  Servers .     server_url: https://api.example.com:8443/v1/api                     For example,",
    "title": "Introduction  5.2 Custom Server URL ​",
    "tokens": 89,
    "length": 286
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/technology-used/intro",
    "content": "Title: Technologies used (Default)  Technologies used (Default). Content: Nodejs    Express  (HTTP server)   Webassembly  (multiple language support in Nodejs)   Temporal  (microservice orchestration and distributed transactions)",
    "title": "Technologies used (Default)  Technologies used (Default)",
    "tokens": 38,
    "length": 155
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows",
    "content": "Title: Workflows  Workflows. Content: Workflows is where the actual computation and flow orchestration happens. The framework supports a YAML based DSL to write workflows and tasks containing the business logic. These workflows can be attached to the events as their handlers, or called from within another workflow. The framework exposes  CoffeeScript /JS based expressions  for evaluation of dynamic variables or transformation  of data from  inputs  of event, or  outputs  of previous tasks.  Default language for transformations (coffee/js) can be configured in  configuration",
    "title": "Workflows  Workflows",
    "tokens": 106,
    "length": 542
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#71-the-structure-of-workflows",
    "content": "Title: Workflows  7.1 The structure of workflows ​. Content: A workflow has the following attributes  summary  - the title   description  - more details   id  - Recommended for better logging visibility   on_error  - Default error handling if any tasks fails.    tasks  - the tasks (workflows or sub-workflows) to be run in series (sequence, or one by one). The tasks invoke other workflows written in YAML or JS/TS. Other languages support is planned.      summary  :   Hello world        description  :   Hello world example which invokes the com.gs.return workflow        id  :   hello_world   # needed for better logging visibility          on_error  :            continue  :     false            response  :              success  :     false              code  :     500              data  :     \"Default error\"          tasks  :     # tasks to be run in sequence (default is sequence)            -     id  :   step1   ## id of this task. Its output will be accessible            # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.              fn  :   com.gs.return            args  :     'Hello World!'     # com.gs.return takes its return value as `args`. Hence the args key.",
    "title": "Workflows  7.1 The structure of workflows ​",
    "tokens": 434,
    "length": 1149
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#72-the-tasks-within-workflows",
    "content": "Title: Workflows  7.2 The tasks within workflows ​. Content: A workflow has one or more tasks associated with it.\nA task has the following attributes   id  - Needed for better logging visibility.  It is compulsory for a task.  Importantly, this is also used to access the output of this task in subsequent tasks in the  outputs.{task_id}  path, as shown in  example below .     summary  - the title     description  - more details     fn  - The handler to be run in this task. It can be one of the  framework functions ,  control functions  (like parallel, sequential, switch),  developer written functions , or another workflow.   You can also use scripting in dynamic evaluation of a function name as given in below example. Refer  Coffee/JS scripting  for more information.       summary  :   Call an API and transform the        tasks  :              -     id  :   transform_fn_step1              description  :   find fn name              fn  :   com.gs.transform              args  :     |                <js%                if (inputs.body.fn == 'sum') {                  return 'com.jfs.sum_workflow'                } else {                  return 'com.jfs.helloworld'                }              %>              -     id  :   call_fn_step2              description  :   call fn returned in transform_fn_step1              fn  :   <% outputs.transform_fn_step1.data %  >                args  :                  name  :   <% inputs.body.name %  >                           args  - Every handler  fn  has its own argument structure, which is kept in the  args  key. For example,           id  :   httpbin_step1          fn  :   com.gs.http          args  :              datasource  :   httpbin            config  :                url     :   /v1/loan  -  application/<% inputs.params.lender_loan_application_id %  >  /agreement/esign/initiate              method  :   post              headers  :   <% inputs.headers %  >                          on_error  - What to do if this task fails?           on_error  :     #You can find sample usage of this in the examples below. Just search on_error in this page.              continue  :     false     # Whether the next task should be executed, in case this task fails. by default continue is true.              response  :   <%Coffee/JS expression%  >     |   String   # If specified, the output of `response` is returned as the output of this task. If not specified, the error output is the default output of the failed task.              tasks  :     # If specified, the tasks are executed in series/sequence. The output of the last task in these tasks is the default output of the failed task.                -     id  :   transform_error                fn  :   com.gs.transform                args  :   <% outputs.httpbin_step1 %  >                      -     id  :   publish_error                fn  :   com.gs.kafka                args  :                    datasource  :   kafka1                  data  :                      value  :   <% outputs.transform_error.message %  >                    config  :                      topic  :   publish  -  producer1                       The only exception to this is  control functions  like series, parallel, switch, which don't take the  args , for the sake of more readability.     retry  - Retry logic helps to handle transient failures, internal server errors, and network errors with support for constant, exponential and random types. Currently applied only for  com.gs.http  workflow.           retry  :              max_attempts  :     5              type  :   constant            interval  :   PT15m                                retry  :              max_attempts  :     5              type  :   exponential            interval  :   PT15s                                retry  :              max_attempts  :     5              type  :   random            min_interval  :   PT5s            max_interval  :   PT10s",
    "title": "Workflows  7.2 The tasks within workflows ​",
    "tokens": 1787,
    "length": 3872
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#the-output-of-task--external-function",
    "content": "Title: Workflows  The output of task & external function ​. Content: The output of every task and function can be expected in the following format within other task  success : true/false. Default value is  true    code :  standard HTTP response codes[1xx, 2xx, 3xx, 4xx, 5xx] Default value is 200   message : any string explaining the response. Optional   data : the actual data returned from the task/function. Optional Note If a task or external JS function returns a value which is not in this JSON structure then framework assumes the output is the data itself & wraps it in this JSON structure with default values.  The output of any previously executed task is accesible in following manner  outputs.step1.code  Example of multiple task with arguments ​      summary  :   Workflow with switch  -  case and transform task        id  :   example_switch_functionality_id        description  :     |          Run two tasks in series. Both take different arguments. First one is switch case task.        Second is transform task which consumes the output of step1 and shapes the final output of this workflow.          tasks  :     # tasks to be run in sequence (default is sequence)            -     id  :   step1_switch   ## id of this switch task. Its output will be accessible              # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.              fn  :   com.gs.switch   # Switch workflow takes `value` and `cases` as arguments. The cases object specifies another task for every case.              value  :   <%inputs.body.condition%  >     # Evaluation of dynamic values happens via <% %>              cases  :                FIRST  :                  id  :   1st                fn  :   com.gs.return                args  :     \"'case - 1'\"                SECOND  :                  id  :   2nd                fn  :   com.gs.return                args  :     \"'case - 2'\"                THIRD  :                  id  :   3rd                fn  :   com.gs.return                args  :     \"'case - 3'\"              defaults  :                id  :   default              fn  :   com.gs.return              args  :   <%inputs.body.default_return_val%  >     #coffee/js script for dyanmic evaluation. Wrapped in <% %>. Same as that used elsewhere in workflows for dynamic calculations and variable substitutions. For ex. as used in com.gs.transform and com.gs.return            -     id  :   step2            fn  :   com.gs.transform            args  :     |     #coffee for dyanmic evaluation. Wrapped in <% %>                <coffee%   {                    code  :     200  ,                        data  :   outputs  [  '1st'  ]                  }   %  >",
    "title": "Workflows  The output of task & external function ​",
    "tokens": 1102,
    "length": 2627
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#73-location-and-fully-qualified-name-id-of-workflows-and-functions",
    "content": "Title: Workflows  7.3 Location and fully qualified name (id) of workflows and functions ​. Content: All the workflows and functions are to be kept in the  src/functions  folder. Their directory tree path, followed by the file name becomes the workflow's fully qualified name or id, by which it can be referenced in the events or within other workflows. The JS function shown below will be available in workflows under the F.Q.N.  com.biz.custom_function . Similarly,  com.biz.create_hdfc_account ,  com.biz.create_parallel  etc. are accessible as handlers from within other  workflow tasks  or events.",
    "title": "Workflows  7.3 Location and fully qualified name (id) of workflows and functions ​",
    "tokens": 124,
    "length": 501
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#74-referencing-a-workflow-within-an-event-or-another-workflow",
    "content": "Title: Workflows  7.4 Referencing a workflow within an event or another workflow ​. Content: A workflow task references and invokes other workflows written in either YAML or JS/TS, via the  fn  key. In future, other languages will also be supported.\nAn  event definition  references the handler yaml workflows by their fully qualified name, via the same  fn  key.",
    "title": "Workflows  7.4 Referencing a workflow within an event or another workflow ​",
    "tokens": 65,
    "length": 270
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#75-use-of-coffeejs-for-scripting",
    "content": "Title: Workflows  7.5 Use of Coffee/JS for scripting ​. Content: The framework provides coffee/js for Transformations in   com.gs.transform   and   com.gs.return    Dynamic evaluation or workflow or task variables, event variables, datasource variables. You will find its code in <% %> within various examples in this page below.Define language at global level ​ Default language for transformations (coffee/js) is configured in  static configuration Define language at workflow level ​ Global configuration for language is overridden by defining specific language inside <coffee/js% %>. For example,         - id: httpbinCof_step2            fn: com.gs.transform            args: |                <coffee% if outputs.httpbinCof_step1.data.json.code == 200 then {                    code: 200,                    success: true,                    data: outputs.httpbinCof_step1.data.json,                    headers: outputs.httpbinCof_step1.data.headers                } else {                    code: 500,                    success: false,                    message: 'error in httpbinCof_step1'                } %>                              - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key            description: upload documents            fn: com.gs.http            args:              datasource: httpbin              params:              data: |                <js% {                  [inputs.body.entity_type + 'id']: inputs.body.entity_id,                  _.omit(inputs.body, ['entity_type', 'entity_id'])}                %>                     Built-in Javascript modules ​ You can use build-in javascript modules in inline scripting. Only synchronous methods of build-in modules are allowed in inline scripting. For example,     summary  :   upload s3        tasks  :            -     id  :   step1            description  :   upload s3            fn  :   com.gs.aws            args  :                datasource  :   aws_s3              params  :      # fs is used directly in scripting in Body                  -     Bucket  :     'godspeedbucket'                    Key  :     'file4.yml'                    Body  :   <% fs.createReadStream(inputs.files  [  0  ]  .tempFilePath) %  >                config  :                  service  :   S3                method  :   putObject",
    "title": "Workflows  7.5 Use of Coffee/JS for scripting ​",
    "tokens": 1091,
    "length": 2289
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#76-inbuilt-functions",
    "content": "Title: Workflows  7.6 Inbuilt functions ​. Content: The framework provides the following inbuilt functions7.6.1 com.gs.http ​ Send HTTP events to other APIs in Axios compatible format. Example 1          summary  :   agreement esign          id  :   agreement_esign          tasks  :              -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key                description  :   agreement esign              fn  :   com.gs.http              params  :     # query params to be sent in the request                  id  :     123                args  :                  datasource  :   httpbin                config  :                    url     :   /v1/loan  -  application/<% inputs.params.lender_loan_application_id %  >  /agreement/esign/initiate                  method  :   post                    retry  :                  max_attempts  :     5                  type  :   constant                interval  :   PT15M                    on_error  :                  continue  :     true                    -     id  :   step2              fn  :   com.gs.transform              args  :     |                  <%if outputs.step1.data.success then outputs.step1.data else {                    code: outputs.step1.code,                    success : false,                    data: {                      error_data: outputs.step1.data['error'],                      uuid: outputs.step1.data.uuid,                      status_code_error: outputs.step1.data.status_code_error,                      event: outputs.step1.data.event                    }                }%>                      Example 2          summary  :   upload documents          id  :   upload_documents          tasks  :              -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key                description  :   upload documents              fn  :   com.gs.http              args  :                  datasource  :   httpbin                params  :                  data  :     |                  <js% {                  [inputs.body.entity_type + 'id']: inputs.body.entity_id,                  _.omit(inputs.body, ['entity_type', 'entity_id'])}                %>                  file_key  :   files                files  :   <% inputs.files %  >                  config  :                    url     :   /v1/documents                  method  :   post                    retry  :                  max_attempts  :     5                  type  :   constant                interval  :   PT15M                    on_error  :                  continue  :     false                  response  :   <%'Some error happened in saving' + inputs.body.entity_type%  >                    -     id  :   step2              fn  :   com.gs.transform              args  :   <% delete outputs.step1.headers; outputs.step1 %  >                             7.6.2 com.gs.kafka ​ Publish events on Kafka.         summary  :   Publishing incoming event data to a Kafka topic          id  :   push_to_kafka          tasks  :              -     id  :   step1              summary  :   Publish an event with input event's data  ,   adding to_process = true              fn  :   com.gs.kafka              args  :     # similar to Axios format                  datasource  :   kafka1                config  :                    method  :   publish                  topic  :   kyc_initiate_recieved                  group_id  :   kyc_domain                data  :     # Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.                    value  :   <% inputs %  >     # Your message content. Evaluation of dynamic values happens via <% %>. The type of scripting is coffee.                    key  :     # Optional - Used for partitioning.                    partition  :     # Optional - Which partition to send the message to.                    timestamp  :     # Optional - The timestamp of when the message was created.                    headers  :     # Optional - Metadata to associate with your message.                      Refer  https://kafka.js.org/docs/producing#message-structure  for information on data attributes. 7.6.3 com.gs.datastore ​ The datastore function allows CRUD access to any supported  datastore  in a format extending  Prisma API .     summary  :   Create and read data        tasks  :            -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key              description  :   Create entity from REST input data (POST request)            fn  :   com.gs.datastore            args  :                datasource  :   mongo   # Which ds to use.                data  :   <% inputs.body +   {  extra_field  :   its_value  }   %  >                config  :                  method  :   <% inputs.params.entity_type %  >  .create          -     id  :   step2   # the response of this will be accessible within the parent step key, under the step1 sub key              description  :   test again            fn  :   com.gs.datastore            args  :                datasource  :   mongo   # Adding this knows which ds/model we are talking about here.                config  :     # Similar approach as Axios                  method  :   <% inputs.params.entity_type %  >  .findMany                           7.6.4 com.gs.elasticgraph ​ The elasticgraph function allows CRUD access to elasticsearch  datastore .     summary  :   eg        tasks  :            -     id  :   create_entity1            description  :   create_entity1            fn  :   com.gs.elasticgraph            args  :                datasource  :   elasticgraph1              data  :                  index  :   <% inputs.params.entity_type + 's' %  >                  type  :     '_doc'                  body  :   <% inputs.body %  >                config  :                  method  :   index            on_error  :                continue  :     false                     7.6.5 com.gs.transform ​ This function allows to transform data from one format to another using coffee/js scripting.         summary  :   Parallel Multiplexing create loan for hdfc api calls          tasks  :              -     id  :   parallel              fn  :   com.gs.parallel              tasks  :                  -     id  :   1st                  fn  :   com.gs.return                  args  :     |                    'parallel task1'                        -     id  :   2nd                  fn  :   com.gs.return                  args  :     |                    'parallel task2'              -     id  :   step2              fn  :   com.gs.transform              args  :                  code  :     200                  data  :   <% outputs.step1_switch.data %  >                     7.6.6 com.gs.series ​        control flow function   Executes the tasks in series.  By default every top level workflow executes its task in series. But when invoking subworkflows if you need, you can explicitly use series workflow. Its syntax is same as parallel.         summary  :   Parallel Multiplexing create loan for hdfc api calls          tasks  :              -     id  :   parallel              fn  :   com.gs.series              tasks  :                  -     id  :   1st                  fn  :   com.gs.return                  args  :     |                    'parallel task1'                        -     id  :   2nd                  fn  :   com.gs.return                  args  :     |                    'parallel task2'              -     id  :   step2              fn  :   com.gs.transform              args  :     |                <coffee% {                code: 200,                data: outputs['1st']              } %>                     7.6.7 com.gs.parallel ​        control flow function   Executes the child tasks in parallel.  Syntax is same as  com.gs.series          summary  :   Parallel Multiplexing create loan for hdfc api calls          tasks  :              -     id  :   parallel              fn  :   com.gs.parallel              tasks  :                  -     id  :   1st                  fn  :   com.gs.return                  args  :     |                    'parallel task1'                        -     id  :   2nd                  fn  :   com.gs.return                  args  :     |                    'parallel task2'                        -     id  :   3rd                  fn  :   com.gs.return                  args  :     |                    'parallel task3'                    -     id  :   step2              fn  :   com.gs.transform              args  :     |                <coffee% {              code: 200,              data: outputs['1st']              } %>                     7.6.8 com.gs.switch ​        control flow function   The classic switch-case flow execution  The args of switch-flow are  value  and  cases .  value  takes a coffee/js expression to be evaluated during runtime. Every case has a task associated with it. The task can invoke another function or a workflow.         summary  :   create loan application for lender          tasks  :                -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key                  description  :   create account in the bank                fn  :   com.gs.switch                value  :   <%inputs.headers  [  'lender'  ]  %  >                  cases  :                    httpbin  :                      -     id  :   1st                      fn  :   com.biz.loan_application.httpbin_create_loan_application                      args  :   <%inputs%  >                             7.6.9 com.gs.each_sequential ​        control flow function   The classic for-each flow execution  The args is list of values in  value  field along with associated tasks. For each value in  value  tasks are executed sequentially. The final output each_sequential is the array of status of the last executed task of each iteration.         summary  :   For each sample          description  :   Here we transform the response of for loop          tasks  :              -     id  :   each_sequential_step1              description  :   for each              fn  :   com.gs.each_sequential              value  :     [  1  ,     2  ,     3  ,     4  ]                tasks  :                  -     id  :   each_task1                  fn  :   com.gs.transform                  args  :   <% 'each_task1 ' + task_value %  >              -     id  :   each_sequential_step2              description  :   return the response              fn  :   com.gs.transform              args  :   <% outputs.each_sequential_step1 %  >                      on_error handling \nYou can add on_error at task level as well as at each_sequential loop level.See the below example, If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the loop else it continues the next tasks.  If all the tasks are failed in loop then the control goes to on_error defined at loop level.        note   on_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.           summary  :   For each sample          description  :   Here we transform the response of for loop          tasks  :              -     id  :   each_sequential_step1              description  :   for each              fn  :   com.gs.each_sequential              value  :     [  1  ,     2  ,     3  ,     4  ]                tasks  :                  -     id  :   each_task1                  fn  :   com.gs.transform                  args  :   <% 'each_task1 ' + task_value %  >                    on_error  :     # on_error at task level                      continue  :     false                      response  :   <%Coffee/JS expression%  >     |   String              on_error  :     # on_error at loop level                  continue  :     true                  response  :   <%Coffee/JS expression%  >     |   String            -     id  :   each_sequential_step2              description  :   return the response              fn  :   com.gs.transform              args  :   <% outputs.each_sequential_step1 %  >                     7.6.10 com.gs.each_parallel ​ The args is list of values in  value  field along with associated tasks. For each value in  value  tasks are executed in parallel. The final output each_parallel is the array of status of the last executed task of each iteration.         summary  :   For each sample          description  :   Here we transform the response of for loop          tasks  :              -     id  :   each_parallel_step1              description  :   for each              fn  :   com.gs.each_parallel              value  :     [  1  ,     2  ,     3  ,     4  ]                tasks  :                  -     id  :   each_task1                  fn  :   com.gs.transform                  args  :   <% 'each_task1 ' + task_value %  >              -     id  :   each_parallel_step2              description  :   return the response              fn  :   com.gs.transform              args  :   <% outputs.each_parallel_step1 %  >                      on_error handling \nYou can add on_error at task level as well as at each_parallel loop level.See the below example, If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the execution for the next tasks in  tasks  for current  task_value  in  value  list. For example, in the below workflow, if  each_task1  step of task_value 1 gets failed then  each_task2  will not get executed on continue false.  If all the tasks are failed in loop then the control goes to on_error defined at loop level.        note   on_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.           summary  :   For each sample          description  :   Here we transform the response of for loop          tasks  :              -     id  :   each_parallel_step1              description  :   for each              fn  :   com.gs.each_parallel              value  :     [  1  ,     2  ,     3  ,     4  ]                tasks  :                  -     id  :   each_task1                  fn  :   com.gs.transform                  args  :   <% 'each_task1 ' + task_value %  >                    on_error  :     # on_error at task level                      continue  :     false                      response  :   <%Coffee/JS expression%  >     |   String                -     id  :   each_task2                  fn  :   com.gs.transform                  args  :   <% 'each_task2 ' + task_value %  >                on_error  :     # on_error at loop level                  continue  :     true                  response  :   <%Coffee/JS expression%  >     |   String            -     id  :   each_parallel_step2              description  :   return the response              fn  :   com.gs.transform              args  :   <% outputs.each_parallel_step1 %  >                     7.6.11 com.gs.return ​        return statement   The classic return statement  It returns from the current function to the function caller. The function stops executing when the return statement is called.         summary  :   Multiplexing create loan for hdfc api calls          id  :   helloworld          tasks  :              -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key                description  :   create account in the bank              fn  :   com.gs.return              args  :     |                <coffee% 'Hello ' + inputs.query.name %>                     7.6.12 com.gs.log ​ It logs the intermediate inputs/outputs during the workflow execution in pino logging format. The args are  level  and  data .  level  takes any value from the  Pino log levels  and  data  takes a coffee/js expression to be evaluated during runtime or anything (like string, number, etc.) which you want to get logged during the workflow execution.         summary  :   Summing x + y          description  :   Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params  !            tasks  :              -     id  :   sum_step1              description  :   add two numbers              fn  :   com.jfs.sum              args  :                  x  :     1                  y  :     2              -     id  :   sum_step2              description  :   log the output in logs              fn  :   com.gs.log              args  :                  level  :   info   # log levels: info, debug, error, warn, fatal, silent, trace                  data  :   <% outputs.sum_step1 %  >              -     id  :   sum_step3              description  :   return the response              fn  :   com.gs.transform              args  :   <% outputs.sum_step1 %  >                     7.6.13 com.gs.dynamic_fn ​ It executes the workflow whose name is dynamically returned as the output of its task list. The tasks of this function should return a string output which will be the name of the workflow to be executed.  Event DSL       '/sum.http.get'  :            fn  :   com.jfs.sum_dynamic          summary  :   A workflow to sum x and y          description  :   This workflow sums two integers          params  :              -     name  :   x              in  :   query              required  :     true                allow_empty_value  :     false                schema  :                  type  :   string                  -     name  :   y              in  :   query              required  :     true                allow_empty_value  :     false                schema  :                  type  :   string                       com.jfs.sum_dynamic.yaml       summary  :   Dynamic function to call com.jfs.sum_workflow.yaml        description  :   This function dynamically is taking workflow name and executing it at the runtime.        tasks  :            -     id  :   sum_dynamic_step1            description  :   add two numbers            fn  :   com.gs.dynamic_fn            tasks  :     # the tasks should return a string value which will the name of the workflow to be executed.              # For example, in below task list, final workflow name will be `com.jfs.sum_workflow`                -     id  :   get_wf_name_step1                fn  :   com.gs.transform                args  :   com.jfs.sum_workflow              -     id  :   get_wf_name_step2   # this task is returning a workflow name dynamically                  fn  :   com.gs.transform                args  :   <% outputs.get_wf_name_step1.data %  >                       com.jfs.sum_workflow.yaml       summary  :   Summing x + y        description  :   Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params  !          tasks  :            -     id  :   sum_step1            description  :   add two numbers            fn  :   com.gs.return            args  :     |             <%             +inputs.query.x + +inputs.query.y           %>                     7.6.14 com.gs.aws ​ Interacts with AWS to use its various services and methods.  params  is the list of params to the AWS service methods. We are using AWS v3 style services. Please refer  AWS S3  for AWS S3 methods.      summary  :   upload s3        tasks  :            -     id  :   step1            description  :   upload s3            fn  :   com.gs.aws            args  :                datasource  :   aws_s3              params  :                  -     Bucket  :     'godspeedbucket'                    Key  :     'file4.yml'                    Body  :   <% fs.createReadStream(inputs.files  [  0  ]  .tempFilePath) %  >                config  :                  service  :   S3                method  :   putObject                     7.6.15 com.gs.redis ​ Developer can read / write to redis datasource using standard redis client functions.     summary  :   demonstration of redis functions        id  :   accessing_redis        tasks  :            -     id  :   store_value_to_key            description  :   Writing user info in redis with key user            fn  :   com.gs.redis            args  :                config  :                  method  :   set              data  :                  key  :   user                value  :   Adam          -     id  :   retrieve_user_set_in_previous_task            description  :   Retriving user from redis            fn  :   com.gs.redis            args  :                config  :                  method  :   get              data  :                  key  :   user                     7.6.16 com.gs.if, com.gs.elif, com.gs.else ​        control flow function   The classic if-else flow execution  The args are  condition  and  tasks .  condition  takes a coffee/js expression to be evaluated during runtime. The  tasks  can invoke another function or a workflow.     summary  :   Returning hello world        tasks  :            -     id  :   if            fn  :   com.gs.if            condition  :   <% inputs.query.status == 'Hello' %  >              tasks  :                -     id  :   step1                description  :   Return hello world                fn  :   com.gs.return                args  :     'Hello!'                  -     id  :   elif1            description  :   Return hello world            fn  :   com.gs.elif            condition  :   <% inputs.query.status == 'Hell' %  >              tasks  :                -     id  :   step2                description  :   Return hello world                fn  :   com.gs.return                args  :     'Hell!'                  -     id  :   elif2            description  :   Return hello world            fn  :   com.gs.elif            condition  :   <% inputs.query.status == 'Hel' %  >              tasks  :                -     id  :   step3                description  :   Return hello world                fn  :   com.gs.return                args  :     'Hel!'                  -     id  :   else            description  :   Return hello world            fn  :   com.gs.else            tasks  :                -     id  :   step4                description  :   Return hello world                fn  :   com.gs.return                args  :     'Hi!'",
    "title": "Workflows  7.6 Inbuilt functions ​",
    "tokens": 11647,
    "length": 22399
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#77-developer-written-functions",
    "content": "Title: Workflows  7.7 Developer written functions ​. Content: Developer can write functions in JS/TS and  kept in src/functions folder  at a path, which becomes its fully qualified name. Other languages support is planned. Once it is written, the function can be invoked from within any workflow or sub-workflow, with its fully qualified name and argument structure.           summary  :   Custom workflow invocation          id  :   custom_function          tasks  :              -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key                description  :   custom_fn              fn  :   com.biz.custom_function   # Can be JS/TS workflow in src/com/xyz directory with filename being custom.{js|ts}                args  :                  arg1  :     'hello world'                  arg2  :     'hello again'",
    "title": "Workflows  7.7 Developer written functions ​",
    "tokens": 309,
    "length": 816
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#78-headers-defined-at-workflow-level",
    "content": "Title: Workflows  7.8 Headers defined at workflow level ​. Content: Headers defined at workflow level are applicable for a single workflow only. You can find the  example usage here",
    "title": "Workflows  7.8 Headers defined at workflow level ​",
    "tokens": 22,
    "length": 113
  },
  {
    "url": "https://docs.godspeed.systems/docs/microservices/workflows#79-file-upload-feature",
    "content": "Title: Workflows  7.9 File Upload feature ​. Content: The framework provides file upload feature to upload files. Here is the sample event and workflow spec to upload any file. Event Spec      /document.http.post  :            fn  :   com.biz.documents.upload_file          id  :     '/sendDocuments'            summary  :   upload document          description  :   upload document on httpbin          data  :              schema  :                body  :                  required  :     false                  content  :                    multipart/form-data  :                      schema  :                        type  :   object                      properties  :                          fileName  :                            type  :   string                          format  :   binary                     7.9.1 Workflow spec to upload files with same file key ​          summary  :   upload file          id  :   upload_file          tasks  :              -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key                description  :   upload docfileuments              fn  :   com.gs.http              args  :                  datasource  :   httpbin                params  :                  file_key  :   files                files  :   <% inputs.files %  >                  config  :                    url     :   /v1/documents                  method  :   post                    retry  :                  max_attempts  :     5                  type  :   constant                interval  :   PT15M                            Note   If file_key is same for all the files then you can use above workflow DSL. In case you have different file_keys for multiple files then you can directly use  <% inputs.file_obj %>  as given in the below section 6.9.2  7.9.2 Workflow spec to upload multiple files with different file keys ​      summary  :   upload multiple documents        tasks  :              -     id  :   upload_multiple_files_step1              description  :   upload multiple documents              fn  :   com.gs.http              args  :                  datasource  :   httpbin                data  :   <% inputs.body %  >                  files  :   <% inputs.file_obj %  >                  config  :                    url     :   /anything                  method  :   post                     7.9.3 Workflow spec to upload file directly from URL ​      summary  :   upload document from url        tasks  :            -     id  :   upload_url_step1            description  :   upload document from url            fn  :   com.gs.http            args  :                datasource  :   httpbin              data  :   <% inputs.body %  >                files  :                  sample  :                    url  :   https  :  //s3.ap  -  south  -  1.amazonaws.com/sample.pdf                  method  :   get              config  :                  url     :   /anything                method  :   post                headers  :                     Content-Type  :     'multipart/form-data'",
    "title": "Workflows  7.9 File Upload feature ​",
    "tokens": 1666,
    "length": 3033
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api",
    "content": "Title: Notification API  Notification API. Content:",
    "title": "Notification API  Notification API",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#notification-service-can-be-run-as-independent-microservices-and-as-a-module-within-other-microservices",
    "content": "Title: Notification API  Notification service can be run as independent microservices and as a module within other microservices. ​. Content:",
    "title": "Notification API  Notification service can be run as independent microservices and as a module within other microservices. ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#1-sendemail",
    "content": "Title: Notification API  1. SendEmail ​. Content:",
    "title": "Notification API  1. SendEmail ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#request-url",
    "content": "Title: Notification API 1. SendEmail ​ Request URL ​. Content: Content Type: application/json ; charset= utf- 8         Method: POST         URL: /api/notification/v1/publish/sendEmail",
    "title": "Notification API 1. SendEmail ​ Request URL ​",
    "tokens": 49,
    "length": 121
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json",
    "content": "Title: Notification API 1. SendEmail ​ Parameters for the request Json ​. Content: recipientsTo      STRING           message           STRING           from              STRING           Subject           STRING",
    "title": "Notification API 1. SendEmail ​ Parameters for the request Json ​",
    "tokens": 83,
    "length": 129
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json",
    "content": "Title: Notification API 1. SendEmail ​ Parameters for the response JSON ​. Content: Status_Code: INTEGER",
    "title": "Notification API 1. SendEmail ​ Parameters for the response JSON ​",
    "tokens": 7,
    "length": 20
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#here-recipientsto-and-from-must-be-validated-as-valid-email-format",
    "content": "Title: Notification API  Here recipientsTo and from must be validated as valid email format. ​. Content:",
    "title": "Notification API  Here recipientsTo and from must be validated as valid email format. ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#2-sendbulkemail",
    "content": "Title: Notification API  2. sendBulkEmail ​. Content:",
    "title": "Notification API  2. sendBulkEmail ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#request-url-1",
    "content": "Title: Notification API 2. sendBulkEmail ​ Request URL ​. Content: Content Type: application/json ; charset= utf- 8         Method: POST         URL: URL: /api/notification/v1/publish/sendBulkEmail",
    "title": "Notification API 2. sendBulkEmail ​ Request URL ​",
    "tokens": 53,
    "length": 130
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-1",
    "content": "Title: Notification API 2. sendBulkEmail ​ Parameters for the request Json ​. Content: recipientsToList      [STRING, STRING...]         message                STRING         from                   STRING         Subject                STRING",
    "title": "Notification API 2. sendBulkEmail ​ Parameters for the request Json ​",
    "tokens": 98,
    "length": 155
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-1",
    "content": "Title: Notification API 2. sendBulkEmail ​ Parameters for the response JSON ​. Content: Status_Code: INTEGER",
    "title": "Notification API 2. sendBulkEmail ​ Parameters for the response JSON ​",
    "tokens": 7,
    "length": 20
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#3-sendbulktemplateemail",
    "content": "Title: Notification API  3. sendBulkTemplateEmail ​. Content:",
    "title": "Notification API  3. sendBulkTemplateEmail ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#request-url-2",
    "content": "Title: Notification API 3. sendBulkTemplateEmail ​ Request URL ​. Content: Content Type: application/json ; charset= utf- 8         Method: POST         URL: URL: /api/notification/v1/publish/sendBulkTemplateEmail",
    "title": "Notification API 3. sendBulkTemplateEmail ​ Request URL ​",
    "tokens": 54,
    "length": 138
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-2",
    "content": "Title: Notification API 3. sendBulkTemplateEmail ​ Parameters for the request Json ​. Content: recipientsToList      [STRING, STRING...]         templateId             INTEGER         templateParam          [{“placeholder1” : “value1”}, {“placeholder2” : “value2”} ]         from                   STRING         Subject                STRING",
    "title": "Notification API 3. sendBulkTemplateEmail ​ Parameters for the request Json ​",
    "tokens": 150,
    "length": 247
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-2",
    "content": "Title: Notification API 3. sendBulkTemplateEmail ​ Parameters for the response JSON ​. Content: Status_Code: INTEGER",
    "title": "Notification API 3. sendBulkTemplateEmail ​ Parameters for the response JSON ​",
    "tokens": 7,
    "length": 20
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#4-sendsms",
    "content": "Title: Notification API  4. SendSMS ​. Content:",
    "title": "Notification API  4. SendSMS ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#request-url-3",
    "content": "Title: Notification API 4. SendSMS ​ Request URL ​. Content: Content Type: application/json ; charset= utf- 8         Method: POST         URL: URL: /api/notification/v1/publish/sendSMS",
    "title": "Notification API 4. SendSMS ​ Request URL ​",
    "tokens": 52,
    "length": 124
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-3",
    "content": "Title: Notification API 4. SendSMS ​ Parameters for the request Json ​. Content: recipientsTo           INTEGER         message                STRING         from                   INTEGER",
    "title": "Notification API 4. SendSMS ​ Parameters for the request Json ​",
    "tokens": 73,
    "length": 107
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-3",
    "content": "Title: Notification API 4. SendSMS ​ Parameters for the response JSON ​. Content: Status_Code: INTEGER                     Here recipientsTo and from must be valid mobile numbers. Message conent and length should meet the criteria of SMS.",
    "title": "Notification API 4. SendSMS ​ Parameters for the response JSON ​",
    "tokens": 50,
    "length": 156
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#5-sendbulksms",
    "content": "Title: Notification API  5. SendBulkSMS ​. Content:",
    "title": "Notification API  5. SendBulkSMS ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#request-url-4",
    "content": "Title: Notification API 5. SendBulkSMS ​ Request URL ​. Content: Content Type: application/json ; charset= utf- 8         Method: POST         URL: URL: /api/notification/v1/publish/sendBulkSMS",
    "title": "Notification API 5. SendBulkSMS ​ Request URL ​",
    "tokens": 54,
    "length": 128
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-4",
    "content": "Title: Notification API 5. SendBulkSMS ​ Parameters for the request Json ​. Content: recipientsToList       [INTEGER, INTEGER]         message                STRING         from                   INTEGER",
    "title": "Notification API 5. SendBulkSMS ​ Parameters for the request Json ​",
    "tokens": 76,
    "length": 118
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-4",
    "content": "Title: Notification API 5. SendBulkSMS ​ Parameters for the response JSON ​. Content: Status_Code: INTEGER                     Here recipientsTo and from must be valid mobile numbers. Message content & length should meet the criteria of SMS.",
    "title": "Notification API 5. SendBulkSMS ​ Parameters for the response JSON ​",
    "tokens": 49,
    "length": 155
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#6-sendwhatsapptext",
    "content": "Title: Notification API  6. SendWhatsAppText ​. Content:",
    "title": "Notification API  6. SendWhatsAppText ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#request-url-5",
    "content": "Title: Notification API 6. SendWhatsAppText ​ Request URL ​. Content: Content Type: application/json ; charset= utf- 8         Method: POST         URL: URL: /api/notification/v1/publish/sendWhatsappText",
    "title": "Notification API 6. SendWhatsAppText ​ Request URL ​",
    "tokens": 54,
    "length": 133
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-5",
    "content": "Title: Notification API 6. SendWhatsAppText ​ Parameters for the request Json ​. Content: recipientsTo           INTEGER         message                STRING         message_type           \"TEXT\"         Channel                “whatsapp”         from                   INTEGER",
    "title": "Notification API 6. SendWhatsAppText ​ Parameters for the request Json ​",
    "tokens": 128,
    "length": 187
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-5",
    "content": "Title: Notification API 6. SendWhatsAppText ​ Parameters for the response JSON ​. Content: Status_Code: INTEGER                     Here recipientsTo and from must be valid mobile numbers. Message should meet the criteria prescribed by Whatsapp.",
    "title": "Notification API 6. SendWhatsAppText ​ Parameters for the response JSON ​",
    "tokens": 48,
    "length": 154
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#7-glossary",
    "content": "Title: Notification API  7. Glossary ​. Content:",
    "title": "Notification API  7. Glossary ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#conventions",
    "content": "Title: Notification API 7. Glossary ​ Conventions ​. Content: Status - HTTP status code of response.                  All response is in JSON format.                  All request parameters are mandatory unless explicitly marked as [optional]",
    "title": "Notification API 7. Glossary ​ Conventions ​",
    "tokens": 61,
    "length": 180
  },
  {
    "url": "https://docs.godspeed.systems/docs/notification-api#status-codes",
    "content": "Title: Notification API 7. Glossary ​ Status Codes ​. Content: All status codes are standard HTTP status codes. The below ones are used in this API. ​           2XX - Success of some kind                 4XX - Error occurred in client’s part                 5XX - Error occurred in server’s part                           following are the status codes ​            Status Code    Description                  200             OK                  201             Created                  202             Accepted (Request accepted, and queued for execution)                  400             Bad request                  401             Authentication failure                  403             Forbidden                  404             Resource not found                  405             Method Not Allowed                  412             Precondition Failed                  413             Request Entity Too Large                  500             Internal Server Error                  501             Not Implemented                  503             Service Unavailable                  504             Invalid data",
    "title": "Notification API 7. Glossary ​ Status Codes ​",
    "tokens": 604,
    "length": 1055
  },
  {
    "url": "https://docs.godspeed.systems/docs/out-of-box/auto-export",
    "content": "Title: Auto Export  Auto Export. Content:",
    "title": "Auto Export  Auto Export",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/out-of-box/auto-export#why-modular-design",
    "content": "Title: Auto Export  Why modular design? ​. Content: To Be Done",
    "title": "Auto Export  Why modular design? ​",
    "tokens": 3,
    "length": 10
  },
  {
    "url": "https://docs.godspeed.systems/docs/out-of-box/auto-export#what-happens-on-importing-a-module",
    "content": "Title: Auto Export  What happens on importing a module? ​. Content: To Be Done",
    "title": "Auto Export  What happens on importing a module? ​",
    "tokens": 3,
    "length": 10
  },
  {
    "url": "https://docs.godspeed.systems/docs/out-of-box/auto-export#how-are-modules-imported-in-a-microservice",
    "content": "Title: Auto Export  How are modules imported in a microservice? ​. Content: `name      namespace      git          repoUrl          version      includedFunctions          users              registration                  auths                      JWT                          enabled: false                  validations                      - <fnName>                      - <fn2Name>                  preHooks                      - <fnName>                  onError                      - <fnName>                  postHooks                      - <fnName>          crud              create                  otel: false",
    "title": "Auto Export  How are modules imported in a microservice? ​",
    "tokens": 392,
    "length": 546
  },
  {
    "url": "https://docs.godspeed.systems/docs/out-of-box/auto-instrumentation",
    "content": "Title: To Be Done  To Be Done. Content:",
    "title": "To Be Done  To Be Done",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/out-of-box/dual-write",
    "content": "Title: To Be Done  To Be Done. Content:",
    "title": "To Be Done  To Be Done",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface",
    "content": "Title: GodSpeed – A Microservice framework  GodSpeed – A Microservice framework. Content: This document is intended for stakeholders, tech leaders, architects & developers. It will provide high level goals, tenets, design principles, components & features of the platform for the intended audience.",
    "title": "GodSpeed – A Microservice framework  GodSpeed – A Microservice framework",
    "tokens": 37,
    "length": 208
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#11-introduction",
    "content": "Title: GodSpeed – A Microservice framework  1.1 Introduction ​. Content: Godspeed is aimed at empowering teams to develop, maintain and observe microservices based backends, with high velocity, scalability, quality and performance.\n  We want development (and hence also QA) teams to bypass all the repeatable and reusable work involved in building modern distributed backends with domain driven design, multi-tenancy, microservices and serverless functions. We want the developers to be able to speedily develop microservices in days, instead of months.For the same, we are trying to provide everything that a team needs to create and operate modern microservices. It will be configuration/templating driven, plug & play, extensible by nature and cloud independent. There will be no vendor lock-in, either with Godspeed or any vendor used. It will give developers choice and control over the kind of tools, DBs and cloud providers they wish to use, while following standards and unified interfaces.This framework is being systematically developed by Mindgrep over the last years, across various projects by extracting abstractions and reusable components. It is actively being customized/expanded/improved with new adaptations.",
    "title": "GodSpeed – A Microservice framework  1.1 Introduction ​",
    "tokens": 229,
    "length": 1154
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#12-goals",
    "content": "Title: GodSpeed – A Microservice framework  1.2 Goals ​. Content: THE GOALS OF THE FRAMEWORK ARE AIMED TO MAKE BUSINESS AGILE BY EMPOWERING THE PRODUCT & DEVELOPMENT TEAMS TO DELIVER EXCELLENT SOLUTIONS VERY FAST.",
    "title": "GodSpeed – A Microservice framework  1.2 Goals ​",
    "tokens": 46,
    "length": 147
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#developer-friendly",
    "content": "Title: GodSpeed – A Microservice framework 1.2 Goals ​ Developer friendly ​. Content: Godspeed provides low code implementation, YAML based DSL, prebuilt feature set and easy project setup, making like of developers easy. Thus empowering them to focus and accomplish their core work with the least amount of effort, time & cost.",
    "title": "GodSpeed – A Microservice framework 1.2 Goals ​ Developer friendly ​",
    "tokens": 49,
    "length": 242
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#enhancing-developer-productivity",
    "content": "Title: GodSpeed – A Microservice framework 1.2 Goals ​ Enhancing developer productivity ​. Content: The framework provides fundamental functionalities of “a modern microservice” out of the box so that developer only needs to focus on business logic (80% reduction in work).",
    "title": "GodSpeed – A Microservice framework 1.2 Goals ​ Enhancing developer productivity ​",
    "tokens": 36,
    "length": 173
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#smaller-micro-teams-and-lesser-learning-curve",
    "content": "Title: GodSpeed – A Microservice framework 1.2 Goals ​ Smaller, micro teams and lesser learning curve ​. Content: Module owners can start shipping microservices within a week's ramp-up time. If at all, only a couple of members in the ogranization need to know the nitty gritty. Rest can just train to use the framework, and deliver with their help,or ours.",
    "title": "GodSpeed – A Microservice framework 1.2 Goals ​ Smaller, micro teams and lesser learning curve ​",
    "tokens": 56,
    "length": 242
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#security",
    "content": "Title: GodSpeed – A Microservice framework 1.2 Goals ​ Security ​. Content: The framework can read the environmental variables from a secure source like K8s Vault. For data in transit and data at rest, we use encryption mechanisms. Also, the framework supports JWT Authentication. Further, all hits to other APIs are secured via security schemas specified in their Open API Specification (OAS 3). Fine grained authorization at API and datasources level is in the roadmap.  Read more",
    "title": "GodSpeed – A Microservice framework 1.2 Goals ​ Security ​",
    "tokens": 83,
    "length": 406
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#easy-and-fast-migrations",
    "content": "Title: GodSpeed – A Microservice framework 1.2 Goals ​ Easy and fast migrations ​. Content: Migrate existing data models to Godspeed via database introspection. Autogenerate CRUD APIs based on the data models. Migrate existing API based on its introspection, to create Godspeed compliant events - planned. Now, all that remains for developers, is simply to migrate the business logic.",
    "title": "GodSpeed – A Microservice framework 1.2 Goals ​ Easy and fast migrations ​",
    "tokens": 61,
    "length": 292
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#13-features",
    "content": "Title: GodSpeed – A Microservice framework  1.3 Features ​. Content:",
    "title": "GodSpeed – A Microservice framework  1.3 Features ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#14-tenets",
    "content": "Title: GodSpeed – A Microservice framework  1.4 Tenets ​. Content:",
    "title": "GodSpeed – A Microservice framework  1.4 Tenets ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#dont-repeat-yourself",
    "content": "Title: GodSpeed – A Microservice framework 1.4 Tenets ​ Don't repeat yourself ​. Content: Developer does not need to do anything at the levels lower than the schema (events, datasources) and business logic. All that, including project setup with required docker containers, is handled by the framework. The developers need not to repeat any work from api to api or project to project.",
    "title": "GodSpeed – A Microservice framework 1.4 Tenets ​ Don't repeat yourself ​",
    "tokens": 58,
    "length": 294
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#easy-to-extend--customize",
    "content": "Title: GodSpeed – A Microservice framework 1.4 Tenets ​ Easy to extend & customize ​. Content: Pluggable interfaces allow new integrations without changing code. For example, replacing datastores, APM/BPM tools, analytics engines, cache, email provider, file storage, CRM etc. should ideally require no change in the application code.",
    "title": "GodSpeed – A Microservice framework 1.4 Tenets ​ Easy to extend & customize ​",
    "tokens": 52,
    "length": 239
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#standards-driven",
    "content": "Title: GodSpeed – A Microservice framework 1.4 Tenets ​ Standards driven ​. Content: Use standards in designing the system. For example, events using CouldEvents. Observability using OpenTelemetry.",
    "title": "GodSpeed – A Microservice framework 1.4 Tenets ​ Standards driven ​",
    "tokens": 22,
    "length": 112
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#15-design-principals",
    "content": "Title: GodSpeed – A Microservice framework  1.5 Design principals ​. Content:",
    "title": "GodSpeed – A Microservice framework  1.5 Design principals ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#three-fundamental-abstractions",
    "content": "Title: GodSpeed – A Microservice framework 1.5 Design principals ​ Three fundamental abstractions ​. Content: The three fundamental abstractions in the Godspeed are events (sync/async), workflows (business logic) and datasources (APIs/datastores).  Read more",
    "title": "GodSpeed – A Microservice framework 1.5 Design principals ​ Three fundamental abstractions ​",
    "tokens": 37,
    "length": 148
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#unified-observability-for-apm-and-bpm",
    "content": "Title: GodSpeed – A Microservice framework 1.5 Design principals ​ Unified Observability For APM and BPM ​. Content: We will follow  OpenTelemetry  (OTEL) SDKs to collect and observe telemetry data, including application performance monitoring. This will be integrable with a plethora of open source or commercial tools of choice that integrate with the standard OTEL protocol.  Read more",
    "title": "GodSpeed – A Microservice framework 1.5 Design principals ​ Unified Observability For APM and BPM ​",
    "tokens": 56,
    "length": 271
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#16-framework-architecture",
    "content": "Title: GodSpeed – A Microservice framework  1.6 Framework architecture ​. Content: The three main dimensions of Godspeed framework: events, workflows and datasources.",
    "title": "GodSpeed – A Microservice framework  1.6 Framework architecture ​",
    "tokens": 17,
    "length": 83
  },
  {
    "url": "https://docs.godspeed.systems/docs/preface#17-scenarios-and-use-cases",
    "content": "Title: GodSpeed – A Microservice framework  1.7 Scenarios and use cases ​. Content: Use cases include any kind of microservice, CRUD microservice, wrapper service, search and suggest service, backend for frontend service, orchestration service, domain gateway service, etc.",
    "title": "GodSpeed – A Microservice framework  1.7 Scenarios and use cases ​",
    "tokens": 38,
    "length": 189
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap",
    "content": "Title: Roadmap  Roadmap. Content:",
    "title": "Roadmap  Roadmap",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap#godspeed-framework-roadmap-q1-and-q2---2023",
    "content": "Title: Roadmap  Godspeed Framework Roadmap Q1 and Q2 - 2023 ​. Content:",
    "title": "Roadmap  Godspeed Framework Roadmap Q1 and Q2 - 2023 ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap#features-core-framework",
    "content": "Title: Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Features [Core Framework] ​. Content: Generative AI based microservice code generation [In progress - Q1]  Generative AI based app generation [Q-2]  Support to define and handle custom event sources [Done - Q1]    Adding capability for defining reusable modules and use them in projects [Q-2]  Support for Java, Golang, Python{on prioritisation by partners} [Q-2]  Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]",
    "title": "Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Features [Core Framework] ​",
    "tokens": 123,
    "length": 534
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap#language-features--debugging-vscode-extension",
    "content": "Title: Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Language Features & Debugging VSCode Extension ​. Content: AI based FAQ & troubleshooting [Q-1]  VS code Debugger  for step through debuggability[Q-2]  Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]",
    "title": "Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Language Features & Debugging VSCode Extension ​",
    "tokens": 48,
    "length": 170
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap#platform",
    "content": "Title: Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Platform ​. Content: Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]  K8s based Grafana observability stack - [Done- Q1]  Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]  K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]",
    "title": "Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Platform ​",
    "tokens": 106,
    "length": 374
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap#other-minor-stories--core-framework-platform--language-features",
    "content": "Title: Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Other Minor Stories- Core Framework, Platform & Language features ​. Content: Support for Authentication for dynamic JWT tokens [Q1]  Support to call YAML workflows from JS workflows [Q1]  Support for using mapping file constants in other mapping file [Q1]",
    "title": "Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Other Minor Stories- Core Framework, Platform & Language features ​",
    "tokens": 44,
    "length": 178
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap#enhancements-in-language",
    "content": "Title: Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Enhancements in Language ​. Content: Support for validating / formatting inline js/coffee in yaml files [Q-1]  Support to show proper error hints in events, workflows and datasources yaml files [Q-1]  Help / Tooltip for different kind godspeed functions [Q-1]  Support for JS/TS syntax check in workflows/datasources [Q-1]  Better navigate between events and workflows and definitions through [Q-1]",
    "title": "Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ Enhancements in Language ​",
    "tokens": 95,
    "length": 361
  },
  {
    "url": "https://docs.godspeed.systems/docs/roadmap#may-pick-up",
    "content": "Title: Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ May pick up ​. Content: Unified dashboard with SSO for CD and observability.  Java flavour of microservice framework (on customer demand)",
    "title": "Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​ May pick up ​",
    "tokens": 24,
    "length": 113
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/config-loading",
    "content": "Title: Config Loading  Config Loading. Content:",
    "title": "Config Loading  Config Loading",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/config-loading#introduction",
    "content": "Title: Config Loading  Introduction ​. Content: In Godspeed landscape, a configuration can be expressed in two ways.",
    "title": "Config Loading  Introduction ​",
    "tokens": 14,
    "length": 68
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/config-loading#way-1-for-simple-and-small-configuration",
    "content": "Title: Config Loading Introduction ​ Way 1 For simple and small configuration ​. Content: When the config is simple and small, it is perhaps better to put all of it in a single yaml/json/toml file sample_project_module.yaml        user          name: 'Ayush'            address:              city: 'Dharamsala'              locality:                pincode: 176052                landmark: 'Hill ventures adventure park'",
    "title": "Config Loading Introduction ​ Way 1 For simple and small configuration ​",
    "tokens": 153,
    "length": 330
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/config-loading#way-2-for-large-and-complex-configuration",
    "content": "Title: Config Loading Introduction ​ Way 2 For large and complex configuration ​. Content: But when a configuration is growing large and has many nested components, it is perhaps better to break them in separate folder/file structure, for better readability and maintenance.\nWithin any folder, If there is an index.yaml/toml/json, its keys will be loaded at the root path ending at that folder's name.  Any other files' data is loaded under the key of that filename  Nested folders' data is loaded recursively using the same approach, under the key of the nested folders  The config loader in GS will load collated JSON from nested configurations stored in folder structure and give the same output as if it was stored within a single file.  sample_project_module      ./sample_project_module        index.yaml          name: 'Ayush'                     //Contents of index.yaml file        address          index.yaml            city: 'Dharamsala'              //Content of address/index.yaml file          locality.yaml            pincode: 176052            landmark: 'Hill ventures adventure park'",
    "title": "Config Loading Introduction ​ Way 2 For large and complex configuration ​",
    "tokens": 323,
    "length": 1009
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/config-loading#conclusion",
    "content": "Title: Config Loading Introduction ​ Conclusion ​. Content: Both these settings will ead to the same output as shown in Way 1.",
    "title": "Config Loading Introduction ​ Conclusion ​",
    "tokens": 16,
    "length": 66
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/intro",
    "content": "Title: Project structure  Project structure. Content:",
    "title": "Project structure  Project structure",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/intro#introduction",
    "content": "Title: Project structure  Introduction ​. Content: There are two kinds of projects : Microservice  Serverless Any project can Have its own code (./src)  Include other libraries/modules (package.json)  Add middleware to functions (imported or in /src)  Export functions (own or imported) via HTTP, message bus or socket  A CLI is planned to create the scaffolding structure. For now template git repository will be made available.",
    "title": "Project structure  Introduction ​",
    "tokens": 85,
    "length": 378
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/intro#project-scaffolding-structure",
    "content": "Title: Project structure Introduction ​ Project Scaffolding Structure ​. Content: Configuration of any kind can be written in a single yaml/toml/json file, or can be broken down into nested folders. Any single file when getting too big, can be broken down into folders.  Read more here   Middleware: Functions authored in /src or imported from other modules, when loaded at service start time, can be wrapped as GSInstruction, with zero or more pre and post hooks including validations and auth,  based on middleware settings  of the project and overriden settings per function      ./                                              // Project root directory        src/                                          // It includes your authored functions which you wish to expose via the microservice interfaces as API. The FQN of any exported from any function, is the folder path to that function relative to /src        test/                                         // Test cases for the project        ui/                                           // Any UI related code including static files            static //html, images, css            src //React, react-native, Ionic,        config/                                       // All the configuration for this project, including that of imported modules and also own exported functions.          src/                                        // Any config required by the code in src folder          imported_modules            auth/                                     // Auth related config            telemetry/                                // Telemetry related config            data/                                     // Data related config, including model, databases used, batch settings, internationalization/localization etc.          middleware/                                 // Inserting pre and post function hooks to functions ;            common/                                   // Applicable to all functions, be it imported functions or functions defined in src            function_overrides/                       // Middleware related config          exported_functions/                         // Configuration for function/modules to be exported over REST, message bus or socket (whether from /src or imported modules)          test/                                       // Any config required by the tests          microservice/                               // When exposed as microservice this is required. It contains any microservice level settings. For example, the microservice name, domain name, open API channels (like message bus, REST).            domainName: 'lending'            microserviceName: 'credit_card'            enabled_channels: ['REST', 'messageBus', 'socket']  //By default all exported functions will be exported via all enabled channels          serverless/                                 // When exposed as serverless function this is required. It contains any FAAS level settings.            domainName: 'lending'            FAASName: 'some_ETL'            trigger: 'messageBus' | 'gitOps' ...      //For full list of supported triggers, see the ArgoEvents for supported sources        package.json                                  // All package info including the imported modules and dependencies        ReadMe.md                      TODO: Add details for microservice/serverless config for different environments like dev/staging/production.",
    "title": "Project structure Introduction ​ Project Scaffolding Structure ​",
    "tokens": 1418,
    "length": 3374
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/intro#defining-api-schema-and-exporting",
    "content": "Title: Project structure Introduction ​ Defining API schema and exporting ​. Content: In Godspeed land, the API schema is collection of defined and exported functions with middleware hooks like param validation & authorization.  Refer the core runtime  for the same.\nIn Godspeed land, you need to write only the business logic & configurations, and not write any code for setting up the server, defining routes, listening to different sync/async channels, sending responses etc.\nThis way the business logic of a function is decoupled from the way this function is exported and consumed, saving development and testing work, and also saving code repetition.\nAll you need to export a function is to define its config in /config/exported_functions.     ./config        exported_functions/          com            abc              functionA                               // The Fullly qualified name (FQN) of the exported function to external consumer will be `${domainName}.${microserviceName}.com.abc.functionA`                                                      // On event interfaces, the microservie or serverless will be registered to listen on the FQN of this function. For REST, the FQN will itself become the URL for that endpoint.                enabled_channels:                     // If channels are not specified for this function, it is exportd via all the channels exposed by this service. In case of HTTP, default export will be POST.                  REST:                    methodType: 'GET' | 'POST'...     // The params of GET request and payload of POST request become the arguments of the underlying function, to be called with its middleware                  messageBus: true | false            // Default value: true. By default every function is exported on all the exported channels of this microservice (see microservice config detailed in above section)                  socket: true | false                // If a channel is not set at the microservice config level, yet a function can be exported on that channel by this local override",
    "title": "Project structure Introduction ​ Defining API schema and exporting ​",
    "tokens": 637,
    "length": 1979
  },
  {
    "url": "https://docs.godspeed.systems/docs/scaffolding/intro#common-middleware",
    "content": "Title: Project structure Introduction ​ Common middleware ​. Content: Like discussed already, any function exported an be given middleware hooks to be run before and after the function execution. These are useful for param validation, authorization and any other use cases as need be.\nThe developer gets default middleware functions defined in  /config/middleware/common . He can further tweak the middleware for any function used in the project. Local changes will override the global settings.\nThese settings will be same in case of FAAS or microservice project.     ./config          middleware/            common/                                                       // all functions will have common middleware defined here              preAuths                com.mg.gs.telemetry.createSpan                dot.separated.fqn.fn2              auths //GSAssert                f.q.n2.cachedAclsBasedAuth                f.q.n2.ownershipBasedAuth              validations //GSAssert                f.q.n3.applyValidationA                f.q.n4.applyValidationB              onError              finally                com.mg.gs.telemetry.closeSpan                com.mg.gs.telemetry.EFKLog                com.mg.gs.telemetry.trace                com.mg.gs.telemetry.sendLatencyMetric                  function_overrides                                             //function specific overrides values here              com                godspeed                  lending                    createLoanAccount                      middleware                        preAuths                          push // | prepend | set                          //One can add middleware before or after the common middleware. Or replace (set) the common middleware with override.                            - f.q.n.fn1                            - dot.separated.fqn.afterAll                          prepend                            - f.q.n.beforeAll                        auths //GSAssert                          set // | prepend | set                            - f.q.n2.cachedAclsBasedAuth                            - f.q.n2.ownershipBasedAuth                        validations                          prepend                            - f.q.n3.applyValidationA                            - f.q.n4.applyValidationB                        finally",
    "title": "Project structure Introduction ​ Common middleware ​",
    "tokens": 1258,
    "length": 2272
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/Auth/intro",
    "content": "Title: Auth Spec  Auth Spec. Content:",
    "title": "Auth Spec  Auth Spec",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro",
    "content": "Title: Introduction  Introduction. Content: The introduction of code level security is as follows:",
    "title": "Introduction  Introduction",
    "tokens": 10,
    "length": 54
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#security",
    "content": "Title: Introduction  Security ​. Content:",
    "title": "Introduction  Security ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#1-code-level-security",
    "content": "Title: Introduction  1. Code Level Security ​. Content: Methodologies for code scanning, vulnerability prevention, and security are listed below:  GitHub secret scanning to avoid committing private keys and secrets into the codebase across all git branches.    Use of CodeQL to scan and analyze code for security vulnerabilities and code related problems. This will be integrated in the CI using GitHub Actions.    Dependabot alerts will be configured on the github repos for the early detection of vulnerabilities in the third-party libraries and packages.    Integrate  Snyk  container security to the Kubernetes cluster to identify and fix the vulnerabilities across all image layers. This will be hooked up in the CI process.    Web Application security testing will be done using Zed Attack Proxy (ZAP) to identify risks of malicious attacks.",
    "title": "Introduction  1. Code Level Security ​",
    "tokens": 161,
    "length": 791
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#2-network",
    "content": "Title: Introduction  2. Network ​. Content: The entire platform will be hosted inside a restricted private network similar to Amazon Virtual Private Cloud (VPC). All communication between the internet and this network will be encrypted with HTTPS.",
    "title": "Introduction  2. Network ​",
    "tokens": 35,
    "length": 203
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#3-data-at-rest--transit",
    "content": "Title: Introduction  3. Data at rest & transit ​. Content: All personally identifiable and sensitive information will be encrypted when stored in the database. This will be achieved using client side field encryption within the microservices/CRUD APIs. The encryption of the fields will be configurable at the time of defining the schema. For example, a MongoDB client will encrypt the fields using Authenticated encryption with associated data (AEAD) with HMAC-SHA-512 MAC before sending the data to the MongoDB server. This is supported out of the box using  mongodb-client-encryption  library.During transit, the communication between microservices will follow a mutual TLS approach to ensure that the parties at each end of the network are who they claim to be. Additionally the data in transit will be encrypted as long as it was configured in the schema.",
    "title": "Introduction  3. Data at rest & transit ​",
    "tokens": 161,
    "length": 801
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#4-logging",
    "content": "Title: Introduction  4. Logging ​. Content: No Personally identifiable information (PII) to be present in logs. This will have to be ensured by the developers through model configuration. Once configured, the specific information will be redacted from the logs by the framework. Additionally, the use of pre-commit git hooks such as  Husky  will prevent committing console logs using  ESlint  rules.",
    "title": "Introduction  4. Logging ​",
    "tokens": 72,
    "length": 355
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#5-cache",
    "content": "Title: Introduction  5. Cache ​. Content: Cache to support encryption at rest and in-transit. Caching services such as Redis Enterprise have built in encryption support data in transit and at rest. Additionally, Amazon ElastiCache for Redis, an in-memory distributed caching mechanism, provides in-transit and at rest encryption to protect the data.",
    "title": "Introduction  5. Cache ​",
    "tokens": 65,
    "length": 307
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#6-documents",
    "content": "Title: Introduction  6. Documents ​. Content: Documents to be stored as Blobs and will be encrypted at rest. Storage services such as Amazon S3 allow configuring the default encryption on a bucket. Doing so will encrypt all the newly added objects using server side encryption.",
    "title": "Introduction  6. Documents ​",
    "tokens": 45,
    "length": 231
  },
  {
    "url": "https://docs.godspeed.systems/docs/security/intro#7-vaults",
    "content": "Title: Introduction  7. Vaults ​. Content: Secret Management -- Using Hashicorp Vault or AWS Secret Manager or Azure Key Vault. Hashicorp Vault is cloud agnostic",
    "title": "Introduction  7. Vaults ​",
    "tokens": 25,
    "length": 118
  },
  {
    "url": "https://docs.godspeed.systems/docs/serverless%20workflows/intro",
    "content": "Title: Essential 3 (Serverless) Workflow engine  Essential 3 (Serverless) Workflow engine. Content: In Godspeed land, one can trigger any kind of serverless workflows (akin to Lambda functions) from a diversity of sources. This is programming language, framework and cloud agnostic. Technologies used   ArgoEvents    ArgoWorkflow  Salient Feature ​  MULTIPLE TRIGGER SOURCES. MULTIPLE TRIGGERED DESTINATIONS \nArgo Events is a CloudEvents compliant, event-driven workflow automation framework for Kubernetes. It integrates with more than 20 trigger sources and can trigger multiple kinds of workflows. Manages everything from simple, linear, real-time to complex, multi-source events. It can trigger K8s objects, Argo Workflows, OpenFAAS functions, AWS Lamdba and other Serverless workloads, etc. on events from a variety of sources like git, webhooks, S3, schedules, messaging queues, gcp pubsub, sns, sqs, etc.",
    "title": "Essential 3 (Serverless) Workflow engine  Essential 3 (Serverless) Workflow engine",
    "tokens": 207,
    "length": 811
  },
  {
    "url": "https://docs.godspeed.systems/docs/serverless%20workflows/technology-used/intro",
    "content": "Title: Technologies used (Default)  Technologies used (Default). Content: ArgoEvents    ArgoWorkflow",
    "title": "Technologies used (Default)  Technologies used (Default)",
    "tokens": 10,
    "length": 26
  },
  {
    "url": "https://docs.godspeed.systems/docs/springboot-integration/intro",
    "content": "Title: Godspeed Integration with SpringBoot  Godspeed Integration with SpringBoot. Content:",
    "title": "Godspeed Integration with SpringBoot  Godspeed Integration with SpringBoot",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/springboot-integration/intro#options-for-the-springboot-world",
    "content": "Title: Godspeed Integration with SpringBoot  Options for the Springboot world ​. Content: Godspeed can be useful for teams working in any framework or language. They can integrate to Godspeed modules through SDKs in those languages.",
    "title": "Godspeed Integration with SpringBoot  Options for the Springboot world ​",
    "tokens": 28,
    "length": 142
  },
  {
    "url": "https://docs.godspeed.systems/docs/springboot-integration/intro#sdk-features",
    "content": "Title: Godspeed Integration with SpringBoot Options for the Springboot world ​ SDK features ​. Content: Telemetry  Out of box telemetry data collection for distrubuted logging, tracing, monitoring  Integrating legacy systems\ncan easily be integrated with log4j etc.  Custom telemetry for BPM(Business Process Monitoring)  Pluggable telemtery sinks/backends(OTEL compliant)  Godspeed will provide out of box preconfigured open source telemetry backeneds as an option      Integration with Godspeed common services: - DB CRUD - Search, suggest & scoring - Data federation (Backend For Frontend) - Notification - Document",
    "title": "Godspeed Integration with SpringBoot Options for the Springboot world ​ SDK features ​",
    "tokens": 120,
    "length": 514
  },
  {
    "url": "https://docs.godspeed.systems/docs/springboot-integration/intro#domain-gatway",
    "content": "Title: Godspeed Integration with SpringBoot Options for the Springboot world ​ Domain gatway ​. Content: The  Godspeed domain gateway ) provides Authorization  Orchestration  Distributed transaction",
    "title": "Godspeed Integration with SpringBoot Options for the Springboot world ​ Domain gatway ​",
    "tokens": 16,
    "length": 93
  },
  {
    "url": "https://docs.godspeed.systems/docs/table-of-contents",
    "content": "Title: Table of Contents  Table of Contents. Content: 1.  Preface    \n 1.1 Introduction   \n 1.2 Goals   \n 1.3 Features   \n 1.4 Tenets   \n 1.5 Design principals   \n 1.6 Framework architecture   \n 1.7 Scenarios and use cases        2.  Introduction    \n 2.1 Developer's work     3.  Setup    \n 3.1 Getting started   \n 3.1.1 Glossary   \n 3.1.2 Pre-requisites   \n 3.1.3 Steps to get started   \n 3.1.4 Time to start the development     3.2 Project structure   \n 3.2.1 Scaffolding & Project structure     3.3 Configuration   \n 3.3.1 Introduction   \n 3.3.2 Environment variables   \n 3.3.3 Static variables     3.4 Tests   \n 3.5 Auto watch and build     4.  CLI    \n 4.1 Functionality   \n 4.2 Installation   \n 4.3 Options   \n 4.4 Commands: Outside the dev container   \n 4.5 Commands: Inside the dev container     5.  Swagger Specs    \n 5.1 CLI command to generate documentation   \n 5.2 Custom Server URL     6.  Events    \n 6.1 Event types   \n 6.2 Event schema & examples for supported sources   \n 6.2.1 JSON schema validation   \n 6.2.2 HTTP event   \n 6.2.3 Kafka event     7.  Workflows    \n 7.1 The structure of workflows   \n 7.2 The tasks within workflows   \n 7.3 Location and fully qualified name (id)    of workflows and functions   \n 7.4 Referencing a workflow within an event or another workflow   \n 7.5 Use of Coffee/JS for scripting     7.6 Inbuilt functions   \n 7.6.1 com.gs.http   \n 7.6.2 com.gs.kafka   \n 7.6.3 com.gs.datastore   \n 7.6.4 com.gs.elasticgraph   \n 7.6.5 com.gs.transform   \n 7.6.6 com.gs.series   \n 7.6.7 com.gs.parallel   \n 7.6.8 com.gs.switch   \n 7.6.9 com.gs.each_sequential   \n 7.6.10 com.gs.each_parallel   \n 7.6.11 com.gs.return   \n 7.6.12 com.gs.log   \n 7.6.13 com.gs.dynamic_fn   \n 7.6.14 com.gs.aws   \n 7.6.15 com.gs.redis   \n 7.6.16 com.gs.if, com.gs.elif, com.gs.else       7.7 Developer written functions   \n 7.8 Headers defined at workflow level        7.9 File Upload feature   \n 7.9.1 Workflow spec to upload files with same file key   \n 7.9.2 Workflow spec to upload multiple files with different file keys   \n 7.9.3 Workflow spec to upload file directly from URL     8.  Datasources    \n 8.1 Introduction   \n 8.1.1 Datasource types     8.2 API datasource   \n 8.2.1 API datasource schema defined externally   \n 8.2.2 API datasource schema defined within the yaml file   \n 8.2.3 Headers defined at datasource level   \n 8.2.4 Headers defined at task level   \n 8.2.5 Example usage     8.3 Datastore as datasource   \n 8.3.1 Schema specification   \n 8.3.2 CLI Commands   \n 8.3.3 Prisma Datastore Setup   \n 8.3.4 Auto generating CRUD APIs from data store models   \n 8.3.5 Sample datastore CRUD task     8.4 Kafka as datasource   \n 8.4.1 Example spec     8.5 Elasticgraph as datasource   \n 8.5.1 Folder Structure   \n 8.5.2 Datasource DSL   \n 8.5.3 Configuration files for elasticgraph   \n 8.5.4 Elasticgraph Setup   \n 8.5.5 Auto generating CRUD APIs for elasticgraph     8.6 Extensible datasources   \n 8.6.1 Datasource definition   \n 8.6.2 Example spec for the event   \n 8.6.3 Example spec for the workflow     8.7 AWS as datasource   \n 8.7.1 Example spec   \n 8.7.2 com.gs.aws workflow     8.8 Redis as datasource   \n 8.8.1 Example spec     9.  Caching    \n 9.1 Specifications   \n 9.1.1 Datasource spec for redis   \n 9.1.2 Configuration   \n 9.1.3 Workflow spec     10.  Mappings    \n 10.1 Project structure   \n 10.2 Sample mappings   \n 10.3 Use mappings constants in other mapping files     11.  Plugins    \n 11.1 Project structure   \n 11.2 Sample plugins   \n 11.3 Sample workflow using plugins     12.  Authentication & Authorization    \n 12.1 Authentication   \n 12.1.1 JWT Configuration   \n 12.1.2 Event spec   \n 12.1.3 Generate JWT   \n 12.1.4 Datasource authentication     12.2 Authorization   \n 12.2.1 Workflow DSL   \n 12.2.2 Sample DB query call authorization     13.  Telemetry    \n 13.1 Introduction   \n 13.1.1 Architecture     13.2 Goals   \n 13.3 Configuration   \n 13.3.1 OTEL exporter endpoint   \n 13.3.2 OTEL service name     13.3.3 Logging   \n 13.3.3.1 Log level   \n 13.3.3.2 Log fields masking   \n 13.3.3.3 Log format   \n 13.3.3.4 Add custom identifiers in logs     13.4 Custom metrics, traces and logs (BPM)      \n 13.4.1 DSL spec for custom metrics   \n 13.4.2 DSL spec for custom trace   \n 13.4.3 DSL spec for custom logs     13.5 Observability Stack   \n 13.6 Recommended model for telemetry signals     14.  Custom Middleware    \n 14.1 How to add custom middleware in Godspeed     15.  Roadmap      16.  FAQ    \n 16.1 What is the learning curve of the microservice framework?   \n 16.2 What is the development process and quality metrics?   \n 16.3 How can we adopt new versions of used technology easily and fast? For example, the new Postgres release.   \n 16.4 How easy is it to add new technology in place of an existing one, or add something absolutely new and unique (not existing in the framework)   ?   \n 16.5 Which databases are currently supported? What is the roadmap for future support?   \n 16.6 Does the API handle DB transactions?   \n 16.7 How can apps be decoupled or loosely coupled with DBs?   \n 16.8 When using Godspeed service alongside SpringBoot, what will be the impact on performance with another hop, versus direct connection with DB from Spring Boot?   \n 16.9 What is the strategic advantage of making DB queries through Godspeed?   \n 16.10 How to achieve multi-tenancy in DBs, for a single application?   \n 16.11 How can we start adopting the Godspeed framework?   \n 16.12 How to move out of the Godspeed framework? Can we have a two door exit? I.e. Can we move out of technology and data both?   \n 16.13 How will we prevent unified CRUD API from limiting or choking us?   \n 16.14 What kind of API standards does the framework support?   \n 16.15 Why Rest first approach ? Why not Graphql first approach?   \n 16.16 How are we doing testing given there is quite a bit of custom DSL in the framework. How do we ensure the correctness?   \n 16.17 How will the upgrades and migrations be done to the framework?   \n 16.18 How CRUD APIs will support the paid as well as the non paid features of databases such as MongoDB. For example: MongoDB free vs paid versions will support different features.   \n 16.19 How to ship new models easily?",
    "title": "Table of Contents  Table of Contents",
    "tokens": 2237,
    "length": 6141
  },
  {
    "url": "https://docs.godspeed.systems/docs/tech-stack",
    "content": "Title: Godspeed  Godspeed. Content: RECOMMENDED STACK, STANDARDS & PROCESSES  Preferred  Alternatives      Soon to be available on  official documentation site.         Containerisation  Docker      Developer setup  Docker with Godspeed repository (Docker images and templates)      Cloud provisioning  Gitops, Kubernetes, Crossplane      Software provisioning and configuring  Git ops, Argo events, ArgoWorkflows, Argo CD, Argo Rollout      IAM  ORY Kratos/Keycloak      Gateway authorisation  ORY OATHKEEPER      Ingress gateway  NGINX Proxy/Istio/Kong/Ambassdor/Trafeik      Service mesh  Linkerd      Microservice framework  SpringBoot + Open Telemetry SDK + Java SDK Godspeed: SDK with TS, JS, Webassembly (Java, Python, Go, .Net, C#, JS, TS..)      Serverless/ETL framework  \"Argo events, Argo Workflow, Godspeed SDK with webassembly. \"      Distributed transactions, microservice orchestration    Godspeed function-DAG interface with Temporal plugin.  SpringBoot with Temporal integration .        Document service  Document service. Godspeed document service or MinIO  MinIO has community and commercial editions for hosting a S3 comptabile document service.    Notification service  Godspeed based service with  universal API .  Adapters with providers.    Eventual consistency (polygot persistence)  Godspeed plus Debezium plus Kafka      Databases  Planned support for Mongodb, Elasticsearch        Later support for Postegres, Mysql      Testing Godspeed itself  Chai/Mocha      Test cases for business logic (in any language/framework)  Can be written in any langauge/framework and integrated in CI/CD      MessageBus/Queue  Kafka, ActiveMQ      Telemetry - origination  SDKs in each of Springboot and Godspeed service, compliant with OTEL      Observability     DataDog     Observability.logging  Elasticsearch, FluentBit, Kibana  CloudWatch    Observability.monitoring  Prometheus/Grafana  CloudWatch    Observability.tracing  Jaeger  X-RAY    Observability.alerting  Grafana      Version control  Git & GitHub      Standards- telemetry  OpenTelementry      Standards- events  CloudEvents      Search, Suggest, Analytics  Elasticsearch      Data-events  Debezium + Godspeed (fast to create and execute ETLs)      CI/CD  Argo Events,ARGO Workflow, ArgoCD      Security- Key secret management  Hashicorp Vault and Sealed Secrets (Kubernetes)      Security- Network  VPC      Security- Code  Github, Synk      Encryption",
    "title": "Godspeed  Godspeed",
    "tokens": 740,
    "length": 2396
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro",
    "content": "Title: Observability  Observability. Content:",
    "title": "Observability  Observability",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#131-introduction",
    "content": "Title: Observability  13.1 Introduction ​. Content: For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the  OpenTelemetry standard  and its supporting tech ecosystem.  Not even a single request must go untracked!",
    "title": "Observability  13.1 Introduction ​",
    "tokens": 77,
    "length": 390
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#1311-architecture",
    "content": "Title: Observability 13.1 Introduction ​ 13.1.1 Architecture ​. Content: Both  Traces  and  Metrics  are sent to OTEL Collector directly.  Tempo  is used as tracing backend for traces and  Prometheus  is used for metrics with  Mimir  as its backend.  For  Logs , a fluent bit daemonset is running on node, which collects logs from various applications on the node.  Loki  is used as logs aggregation solution.",
    "title": "Observability 13.1 Introduction ​ 13.1.1 Architecture ​",
    "tokens": 84,
    "length": 336
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#132-goals",
    "content": "Title: Observability  13.2 Goals ​. Content:",
    "title": "Observability  13.2 Goals ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#auto-application-performance-monitoring",
    "content": "Title: Observability 13.2 Goals ​ Auto application performance monitoring ​. Content: No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.",
    "title": "Observability 13.2 Goals ​ Auto application performance monitoring ​",
    "tokens": 26,
    "length": 114
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#backend-agnostic",
    "content": "Title: Observability 13.2 Goals ​ Backend agnostic ​. Content: Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.",
    "title": "Observability 13.2 Goals ​ Backend agnostic ​",
    "tokens": 30,
    "length": 148
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#complete-debuggability",
    "content": "Title: Observability 13.2 Goals ​ Complete debuggability ​. Content: Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.",
    "title": "Observability 13.2 Goals ​ Complete debuggability ​",
    "tokens": 50,
    "length": 232
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#133-configuration",
    "content": "Title: Observability  13.3 Configuration ​. Content:",
    "title": "Observability  13.3 Configuration ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#1331-otel-exporter-endpoint",
    "content": "Title: Observability 13.3 Configuration ​ 13.3.1 OTEL exporter endpoint ​. Content: Specify the IP address of your OTEL collector as env variable. Refer  OTEL Exporter  for more information.     $ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317                     For example,     export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:4317",
    "title": "Observability 13.3 Configuration ​ 13.3.1 OTEL exporter endpoint ​",
    "tokens": 110,
    "length": 270
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#1332-otel-service-name",
    "content": "Title: Observability 13.3 Configuration ​ 13.3.2 OTEL service name ​. Content: Specify the service name by which you want to setup observability and set it as env variable.      $ export OTEL_SERVICE_NAME=sample_proj1                     Let's assume you have setup SigNoz as the exporter then you will see something like this:\n  \n  \n   In case you have any questions, please reach out to us on our  Discord channel .",
    "title": "Observability 13.3 Configuration ​ 13.3.2 OTEL service name ​",
    "tokens": 108,
    "length": 338
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#1333-logging",
    "content": "Title: Observability 13.3 Configuration ​ 13.3.3 Logging ​. Content: 13.3.3.1 Log level ​ The minimum level set to log above this level. Please refer  Pino log levels  for more information. Set  log_level  in  Static variables 13.3.3.2 Log fields masking ​ If you want to hide sensitive information in logs then define the fields which need to be hidden in  redact  feature in  Static variables . Please refer  Pino redaction paths  for more information.13.3.3.3 Log format ​ By default, the logs are dumped in  OTEL Logging format  when you deploy your service anywhere (UAT, Prod, K8s, etc.) except inside the vscode remote containers/dev containers.      {\"Body\":\"adding body schema for /upload_doc.http.post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}      {\"Body\":\"adding body schema for /upload_multiple_docs.http.post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}      {\"Body\":\"adding body schema for /upload_s3.http.post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}      {\"Body\":\"registering http handler /another_workflow post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}      {\"Body\":\"registering http handler /create/:entity_type post\",\"Timestamp\":\"1676531763728000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}      . . . . . . . . . . .       {\"Body\":\"args.retry {\\\"max_attempts\\\":3,\\\"type\\\":\\\"constant\\\",\\\"interval\\\":5000}\",\"Timestamp\":\"1676531764656000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"a58ef2d7ff7725c39f1e058bf22fe724\",\"SpanId\":\"751bc314bb6286b4\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"}}      {\"Body\":\"Result of _executeFn test_step1 {\\\"success\\\":true,\\\"code\\\":200,\\\"data\\\":{\\\"args\\\":{},\\\"data\\\":\\\"{\\\\\\\"data\\\\\\\":{\\\\\\\"lan\\\\\\\":\\\\\\\"12345\\\\\\\"}}\\\",\\\"files\\\":{},\\\"form\\\":{},\\\"headers\\\":{\\\"Accept\\\":\\\"application/json, text/plain, */*\\\",\\\"Content-Length\\\":\\\"24\\\",\\\"Content-Type\\\":\\\"application/json\\\",\\\"Host\\\":\\\"httpbin.org\\\",\\\"Traceparent\\\":\\\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\\\",\\\"User-Agent\\\":\\\"axios/0.25.0\\\",\\\"X-Amzn-Trace-Id\\\":\\\"Root=1-63edd835-22cff8e60555fa522c8544cf\\\"},\\\"json\\\":{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}},\\\"method\\\":\\\"POST\\\",\\\"origin\\\":\\\"180.188.224.177\\\",\\\"url\\\":\\\"https://httpbin.org/anything\\\"},\\\"message\\\":\\\"OK\\\",\\\"headers\\\":{\\\"date\\\":\\\"Thu, 16 Feb 2023 07:16:05 GMT\\\",\\\"content-type\\\":\\\"application/json\\\",\\\"content-length\\\":\\\"598\\\",\\\"connection\\\":\\\"close\\\",\\\"server\\\":\\\"gunicorn/19.9.0\\\",\\\"access-control-allow-origin\\\":\\\"*\\\",\\\"access-control-allow-credentials\\\":\\\"true\\\"}}\",\"Timestamp\":\"1676531765810000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"a58ef2d7ff7725c39f1e058bf22fe724\",\"SpanId\":\"751bc314bb6286b4\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"}}      {\"Body\":\"Validate Response JSON Schema Success\",\"Timestamp\":\"1676531765811000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"a58ef2d7ff7725c39f1e058bf22fe724\",\"SpanId\":\"751bc314bb6286b4\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"\"}}                       Dev Format  \nThe  dev format  is basically a transformation of OTEL log format to increase readability for developers.  \nPlease note that the default logging format inside vscode dev container on your local machine is  dev format  as given below:     datetime [SeverityText] TraceId SpanId {Attributes} Body                     Sample Logs:     16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post      16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post      16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post      16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post      16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post      16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post      16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post      . . . . . . . . . .       16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"} args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}      16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"} Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd7e4-0b8b6ba319833492520e6b0c\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:14:44 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}      16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"\"} Validate Response JSON Schema Success                            note   If you want to change the OTEL format to  dev format , then set the environment variable  NODE_ENV  to  dev  in your environment as given below. The default value of  NODE_ENV  is  production .         export NODE_ENV=dev                     13.3.3.4 Add custom identifiers in logs ​ You can add any custom identifier in the logging whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   To enable this feature ,you need to specify two things:     log_attributes  variable as  environment variable / static variable  which contains custom identifiers. For example, this is the sample static configuration:     log_attributes:         mobileNumber: \"query?.mobileNumber\"        id: \"params?.id\"        lan: \"body?.data?.lan\"                      location of the identifier in the request payload. As specified in the above example,   if mobileNumber is present in query params then specify  query?.mobileNumber .  if id is present in path params then specify  params?.id .  if lan is present in data field inside body then specify  body?.data?.lan .          note   Please make sure to add ? in case any field is optional like  body?.data?.lan  so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added.    Sample Logs   Dev format      21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"} Processing event /test/:id.http.post      21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"} event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"835edd29-7c36-4e11-9b79-c661bbd911b0\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}      21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"} event body and eventSpec exist                      OTEL format      {\"Body\":\"Processing event /test/:id.http.post\",\"Timestamp\":\"1676960742403000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"3b66e6f8ec6624f6467af1226503a39e\",\"SpanId\":\"eb6e7d89ac381e9f\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"5252603e08be\",\"process.pid\":828},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"}}      {\"Body\":\"event inputs {\\\"baseUrl\\\":\\\"\\\",\\\"body\\\":{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}},\\\"fresh\\\":false,\\\"hostname\\\":\\\"localhost\\\",\\\"ip\\\":\\\"::ffff:172.22.0.1\\\",\\\"ips\\\":[],\\\"method\\\":\\\"POST\\\",\\\"originalUrl\\\":\\\"/test/12?mobileNumber=9878987898\\\",\\\"params\\\":{\\\"id\\\":\\\"12\\\"},\\\"path\\\":\\\"/test/12\\\",\\\"protocol\\\":\\\"http\\\",\\\"query\\\":{\\\"mobileNumber\\\":\\\"9878987898\\\"},\\\"route\\\":{\\\"path\\\":\\\"/test/:id\\\",\\\"stack\\\":[{\\\"name\\\":\\\"<anonymous>\\\",\\\"keys\\\":[],\\\"regexp\\\":{\\\"fast_star\\\":false,\\\"fast_slash\\\":false},\\\"method\\\":\\\"post\\\"},{\\\"name\\\":\\\"<anonymous>\\\",\\\"keys\\\":[],\\\"regexp\\\":{\\\"fast_star\\\":false,\\\"fast_slash\\\":false},\\\"method\\\":\\\"post\\\"}],\\\"methods\\\":{\\\"post\\\":true}},\\\"secure\\\":false,\\\"stale\\\":true,\\\"subdomains\\\":[],\\\"xhr\\\":false,\\\"headers\\\":{\\\"content-type\\\":\\\"application/json\\\",\\\"user-agent\\\":\\\"PostmanRuntime/7.29.2\\\",\\\"accept\\\":\\\"*/*\\\",\\\"postman-token\\\":\\\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\\\",\\\"host\\\":\\\"localhost:4000\\\",\\\"accept-encoding\\\":\\\"gzip, deflate, br\\\",\\\"connection\\\":\\\"keep-alive\\\",\\\"content-length\\\":\\\"46\\\"},\\\"files\\\":[]}\",\"Timestamp\":\"1676960742403000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"3b66e6f8ec6624f6467af1226503a39e\",\"SpanId\":\"eb6e7d89ac381e9f\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"5252603e08be\",\"process.pid\":828},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"}}      {\"Body\":\"event body and eventSpec exist\",\"Timestamp\":\"1676960742404000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"3b66e6f8ec6624f6467af1226503a39e\",\"SpanId\":\"eb6e7d89ac381e9f\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"5252603e08be\",\"process.pid\":828},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"}}",
    "title": "Observability 13.3 Configuration ​ 13.3.3 Logging ​",
    "tokens": 4248,
    "length": 11747
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#134-custom-metrics-traces-and-logs-bpm",
    "content": "Title: Observability  13.4 Custom metrics, traces and logs (BPM) ​. Content: Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.",
    "title": "Observability  13.4 Custom metrics, traces and logs (BPM) ​",
    "tokens": 31,
    "length": 143
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#1341-dsl-spec-for-custom-metrics",
    "content": "Title: Observability 13.4 Custom metrics, traces and logs (BPM) ​ 13.4.1 DSL spec for custom metrics ​. Content: # refer https://github.com/siimon/prom-client      metrics:      -   name: metric_name          type: counter|gauge|histogram|summary          labels:             label1: val1            label2: val2                            # followng functions depending on the metric type and all of them could be scripts, can use inputs/outputs          inc: 10          dec: 10          set: 100          observe: 2000          timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/task                     Example spec ​ In the following example, we are using two custom metrics:  httpbin_calls_total: counter type metric, counter is incremented by 1.  httpbin_calls_duration: histogram type metric, timer is set to true to record duration.      summary: Call an API and transform the       tasks:          - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key            name: http bin step            description: Hit http bin with some dummy data. It will send back same as response            fn: com.gs.http                     metrics:              - name: httpbin_calls_total                help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'                type: counter                labels:                  method: httpbin                  status_code: <% outputs.httpbin_step1.code %>                               inc: 1              - name: httpbin_calls_duration                help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'                type: histogram                labels:                  method: httpbin                  status_code: <% outputs.httpbin_step1.code %>                               timer: true                      args:              datasource: httpbin              params: <% inputs.query %>              data: <% inputs.body %>              config:                url : /anything                method: post",
    "title": "Observability 13.4 Custom metrics, traces and logs (BPM) ​ 13.4.1 DSL spec for custom metrics ​",
    "tokens": 963,
    "length": 2042
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#1342-dsl-spec-for-custom-trace",
    "content": "Title: Observability 13.4 Custom metrics, traces and logs (BPM) ​ 13.4.2 DSL spec for custom trace ​. Content: trace:          name: span_name          attributes:              attribute1: value1              attribute2: value2                     Example spec ​ In the following example, we are creating a new span named  httpbin_trace  with span attributes  request  and  param . This span gets created when the task starts and ended when the task completes its execution.     summary: Call an API and transform the       tasks:          - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key            name: http bin step            description: Hit http bin with some dummy data. It will send back same as response            fn: com.gs.http            trace:              name: httpbin_trace              attributes:                  request: <%inputs.body%>                  param: <%inputs.query%>            args:              datasource: httpbin              params: <% inputs.query %>              data: <% inputs.body %>              config:                url : /anything                method: post",
    "title": "Observability 13.4 Custom metrics, traces and logs (BPM) ​ 13.4.2 DSL spec for custom trace ​",
    "tokens": 478,
    "length": 1060
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#1343-dsl-spec-for-custom-logs",
    "content": "Title: Observability 13.4 Custom metrics, traces and logs (BPM) ​ 13.4.3 DSL spec for custom logs ​. Content: logs:          before:              level: fatal|error|warn|info|debug|trace # refer pino for levels              message: 'Sample log before'              params:                 param1: val1                param2: val2              attributes:                request:                  query: <%inputs.query%>          after:              level: info              message: 'Sample log after'              params:              attributes:                      The logs are dumped in OTEL format. Please refer to  OTEL Logging Data model  for understanding of fields dumped in the logs.  message  and  params  are part of  Body  field and  attributes  are part of  Attributes  field in the log. Example spec ​ In the following example, we are two additional logs before and after the task execution.      summary: Call an API and transform the       tasks:          - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key            name: http bin step            description: Hit http bin with some dummy data. It will send back same as response            fn: com.gs.http            logs:              before:                level: error                message: 'Hello'                params:                   - key1: v1                    key2: v2                  - v1                attributes:                   request: <%inputs.query%>              after:                level: error                message: 'World'                params:                   key1: v1                  key2: v2                attributes:                   customer_name: <% outputs.httpbin_step1.data.json.customer_name %>             args:              datasource: httpbin              params: <% inputs.query %>              data: <% inputs.body %>              config:                url : /anything                method: post                       Sample Logs         {\"Body\":\"Hello [{\\\"key1\\\":\\\"v1\\\",\\\"key2\\\":\\\"v2\\\"},\\\"v1\\\"]\",\"Timestamp\":\"1676011973016000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"afde0bf5bb3533d932c1c04c30d91172\",\"SpanId\":\"ad477b2cf81ca711\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9ce06d358ba7\",\"process.pid\":67228},\"Attributes\":{\"request\":{\"status\":\"Hello\"},\"task_id\":\"if\",\"workflow_name\":\"if_else\"}}      . . . . . . . . . . .      {\"Body\":\"World {\\\"key1\\\":\\\"v1\\\",\\\"key2\\\":\\\"v2\\\"}\",\"Timestamp\":\"1676011973019000000\",\"SeverityNumber\":17,\"SeverityText\":\"ERROR\",\"TraceId\":\"afde0bf5bb3533d932c1c04c30d91172\",\"SpanId\":\"ad477b2cf81ca711\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9ce06d358ba7\",\"process.pid\":67228},\"Attributes\":{\"customer_name\":\"Hell!\",\"task_id\":\"if\",\"workflow_name\":\"if_else\"}}",
    "title": "Observability 13.4 Custom metrics, traces and logs (BPM) ​ 13.4.3 DSL spec for custom logs ​",
    "tokens": 1331,
    "length": 2765
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#135-observability-stack",
    "content": "Title: Observability  13.5 Observability Stack ​. Content: The complete observability stack with K8s helm-charts will be made available soon.",
    "title": "Observability  13.5 Observability Stack ​",
    "tokens": 19,
    "length": 82
  },
  {
    "url": "https://docs.godspeed.systems/docs/telemetry/intro#136-recommended-model-for-telemetry-signals",
    "content": "Title: Observability  13.6 Recommended model for telemetry signals ​. Content: Please find the  draft documentation here . This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.",
    "title": "Observability  13.6 Recommended model for telemetry signals ​",
    "tokens": 45,
    "length": 216
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/events",
    "content": "Title: Introduction  Introduction. Content: Events are used to expose the functions of this microservice to the external world. Whether via HTTP, message bus, gRPC or socket.",
    "title": "Introduction  Introduction",
    "tokens": 29,
    "length": 130
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/events#http-events",
    "content": "Title: Introduction  HTTP events ​. Content: Two events needed to complete an HTTP call.",
    "title": "Introduction  HTTP events ​",
    "tokens": 9,
    "length": 43
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/events#http-request-event",
    "content": "Title: Introduction HTTP events ​ HTTP request event ​. Content: Whenever an event has  event.full.name._http.{method_name}  as part of its name,\nthen the framework will start listening on the URL\n ${app_base_url}/event/full/name  against the method ${method_name} which can be PUT, GET, POST etc.\nThe body, params, headers and query of the HTTP request are\nserialized by the framework into the event object and passed to the  __handler  (function handler for this event) which consumes this request and returns a reponse. Implicitly the framework will emit a response for every event which can again be an event or yaml execution. Convention is event_name.response, but if we want to emit any other event, we can invoke any other DAG, it could send event to message_bus or GRPC also. Sample input definition ​      do_KYC.__http.post:        # exposed by convention as REST URL: app_base_url/do_KYC on method POST        __handler: __src.com.abc.do_KYC        __data: # {body, params, query, headers} Bank API POST url is: /create_loan/${pan}/?user_id=${user_id} & body takes {user_name, address}           __example:              body:                user_name: Ayush                pan: AKJP****                address: India              # In case of HTTP event, query, headers and params will be also present              headers:              query:              params:          __schema: #Validation will happen after recieving and before sending out event. In case of HTTP channel, payload will have metadata.http.{headers, params, query}            # ${config.src.com.pinelabs.li.schemas.create_loan_api} #using template written elsewhere. For ex. compulsory pan, user_name, address            body:              type: object              properties:                user_name: string                pan: string                address: string                required: [user_name, pan, address]            headers:            query:            params:        #__response: someother.do_KYC.http.post.response # Can be implicit or explicit (in case of custom event names)                     Sample response event definition ​ The framework, upon recieving the  __response , emits another event whose name is  event.full.name._http.{method_name}.response , by convention. This event is in turn caught by the framework internally itself, and passed on to the  http_event_handler  which then sends over the  __response  data to the HTTP caller.Every event has a schema which determines the shape of its data.\nIn case of HTTP event, it will have body, params, query and headers in its data.\nFurther, note that the event emmitted by the framework will have CloudEvents specific format. This includes the events which returns the HTTP response. This means that the HTTP response will also have CloudEvents format.     do_KYC.__http.post.response: #this URI can be customized. By default eventName.response is the actual response event.        # __handler: __http.response_handler # provided by the framework. No need to specify here        __data: # Bank API POST url is: /create_loan/${pan}/?user_id=${user_id} & body takes {user_name, address}          __example:              body:                user_id: 1              headers:          __schema: #Validation will happen after recieving and before sending out event. In case of HTTP channel, payload will have metadata.http.{headers, params, query}          # Schema can be in any shape, which is supported by the event handler attached to this event              200: *200-json-schema              400: *400-json-schema              500: *500-json-schema",
    "title": "Introduction HTTP events ​ HTTP request event ​",
    "tokens": 1256,
    "length": 3546
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions",
    "content": "Title: Introduction  Introduction. Content: The DSL provided by Godspeed is an extension of the YAML spec. Note: Also every keyword will start with double underscores.",
    "title": "Introduction  Introduction",
    "tokens": 27,
    "length": 123
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#name",
    "content": "Title: Introduction  Name ​. Content: A name of the function. It will has response data as the value to its key.     __name: step1",
    "title": "Introduction  Name ​",
    "tokens": 27,
    "length": 92
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#summary",
    "content": "Title: Introduction  Summary ​. Content: A basic sumary of the function.     __summary: A sample summary of the function",
    "title": "Introduction  Summary ​",
    "tokens": 21,
    "length": 79
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#description",
    "content": "Title: Introduction  Description ​. Content: A basic description of the function.     __summary: A sample description of the function",
    "title": "Introduction  Description ​",
    "tokens": 20,
    "length": 88
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#args",
    "content": "Title: Introduction  Args ​. Content: The YAML function argument that is needed in the function dag, we specify here. The arg consists of 2 parts An example of the how the argument looks for the function using  __example       __example:        sample_arg_1: sample_value_1        sample_arg_2: sample_value_2",
    "title": "Introduction  Args ​",
    "tokens": 84,
    "length": 271
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#three-types-of-functions",
    "content": "Title: Introduction  Three types of functions ​. Content: The DSL allows one to define functions in YAML format. A function definition can invoke A single function using  __ref . This means, internally we would call this function.       __ref: __src.com.abc.anuj                      A series of functions using  __sequence . This means, that we want to run multiple function in our DAG in sequential manner.      __sequence:        - __ref: __modules.imported_module_1.some_function        - __ref: __modules.imported_module_2.some_function_2                      A parallel exeuction of list of functions using  __parallel . This means, that we want to run multiple function in our DAG in parallel manner.      __parallel:        - __ref: __modules.imported_module_1.some_function        - __ref: __modules.imported_module_2.some_function_2                      The functions wrapped around and invoked can be either JS, or TS or YAML functions. Also we would only choose of the options between  __ref ,  __sequential ,  _parallel .  The name contains the response data in nested manner. Say we want data from step1 of DAG, the way to access that would be      __args:        create_user_url: ${__config.los.urls.create_user}        user_id: ${__response.data.step1.data.user_id}        user_name: ${__request.params.user_name}",
    "title": "Introduction  Three types of functions ​",
    "tokens": 446,
    "length": 1271
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#hooks",
    "content": "Title: Introduction  Hooks ​. Content: Hooks are like decorators in Python world or annotations in Java world, where you define logic that must execute before or after a function call.\nThe framework has some common hooks for all functions in the project, like Telemetry hooks. But the developer has the flexibility to override or change commmon hooks through  function overriding  defined below.Here are the different kind of hook functions possible       __hooks:          __pre_validations: # This ref is executed for pre_validation          __validations: # This ref is executed for validation          __preauths: # This ref is executed for pre_auths          __auths: # This ref is executed for auths          __pre_ref: # This ref is executed before the function call itself          __post_ref: # This ref is executed after the function call itself          __on_error: # This ref is executed if the function raises an error          __finally: # This ref is executed when the execution of the function call is done                      An example on hooks for  __on_error       __hooks:        __on_error:          - __ref: __log            __args:              data:                key1:value1                key2:value2",
    "title": "Introduction  Hooks ​",
    "tokens": 415,
    "length": 1190
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#example-using-single-function",
    "content": "Title: Introduction  Example using single function ​. Content: ```      com:        xyz:          someFn:            __name: step1            __summary: Summary of this function            __description: long description            __args:              __example:              __schema:            __ref: com.abc.anuj # JS, TS, yaml  __src.com.a.b.c, __modules            __args:              arg1: 5              arg2: Hello World            __hooks:              __pre_validations:              __validations:              __preauths:              __auths:              __pre_ref:              __post_ref:              __on_error:              __finally:            ```",
    "title": "Introduction  Example using single function ​",
    "tokens": 389,
    "length": 608
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#sequence-or-parallel-execution-of-list-of-functions",
    "content": "Title: Introduction  Sequence or parallel execution of list of functions ​. Content: ```      __sequence:        - __ref: src.com.abc.a_function        - __parallel:          - __ref: src.com.abc.b_function          - __ref: src.com.abc.c_function      ```",
    "title": "Introduction  Sequence or parallel execution of list of functions ​",
    "tokens": 93,
    "length": 171
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#sequence-or-parallel-business-logic-over-an-array-of-items-or-an-object",
    "content": "Title: Introduction  Sequence or parallel business logic over an array of items or an object ​. Content: __sequence:      __args:        items: ${__request.body.items}        as: item_name        __sequence:          - __ref: __if_else # or __sequence or __parallel            __args:              when:                ${__vars.item_name}:                  in: ${__config.shop.inventory.unavailable_items}              then:                __ref: __continue # also there is __break          - __ref: com.ecommerce.add_to_invoice # or __sequence or __parallel            __args:              text: ${__vars.item_name}",
    "title": "Introduction  Sequence or parallel business logic over an array of items or an object ​",
    "tokens": 272,
    "length": 511
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#overriding-a-function",
    "content": "Title: Introduction  Overriding a function ​. Content: Written within the project's src folder (DSL, JS or TS functions)  Exported by the modules included in the project (via package.json)",
    "title": "Introduction  Overriding a function ​",
    "tokens": 32,
    "length": 133
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#context-variables",
    "content": "Title: Introduction  Context variables ​. Content: Purpose",
    "title": "Introduction  Context variables ​",
    "tokens": 2,
    "length": 7
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#__super-for-overriding",
    "content": "Title: Introduction Context variables ​ __super  (for overriding) ​. Content:",
    "title": "Introduction Context variables ​ __super  (for overriding) ​",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#__vars",
    "content": "Title: Introduction Context variables ​ __vars  ​. Content: All variables created using  __assign  are available under  __vars",
    "title": "Introduction Context variables ​ __vars  ​",
    "tokens": 16,
    "length": 66
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#__config",
    "content": "Title: Introduction Context variables ​ __config  ​. Content: All variables that are part of the project config are present in the  __config  variable",
    "title": "Introduction Context variables ​ __config  ​",
    "tokens": 18,
    "length": 88
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#__src",
    "content": "Title: Introduction Context variables ​ __src  ​. Content: The  __src  variables contains every function under source folder(js, ts, yaml). We can access all these functions using the above variable",
    "title": "Introduction Context variables ​ __src  ​",
    "tokens": 30,
    "length": 139
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#__env",
    "content": "Title: Introduction Context variables ​ __env  ​. Content: The  __env  variables contains all the environment variables",
    "title": "Introduction Context variables ​ __env  ​",
    "tokens": 11,
    "length": 60
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#__response",
    "content": "Title: Introduction Context variables ​ __response  ​. Content: The  __response  has object for the incoming data.How to define variables ​        __ref: __assign        __name: nested_step        __args:            create_user_url: ${__config.los.urls.create_user}            user_id: ${__response.data.step1.data.user_id}            user_name: ${__request.params.user_name}                     How to use variables ​        __summary: Create loan in LOS        __ref: __http_post        __args:          url: ${__vars.step1.code}/${__vars.user_id}/?user_name=${__vars.user_name}          body: # body is {user_name: string, address: string}            user_name:  ${__event.data.body.user_name}            address:  ${__request.body.address}            loan_id: ${__response.step1.data.loan_id}          query:            user_id: ${__vars.user_id}                     ,  config,  src,  modules,  env,  event.data,  response (starting from the first parent span), __args (of the running GS instruction)",
    "title": "Introduction Context variables ​ __response  ​",
    "tokens": 443,
    "length": 940
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions#examples",
    "content": "Title: Introduction  Examples ​. Content: com:          pinelabs:            create_account_hdfc:              __summary: Multiplexing create loan for hdfc api calls              __args:                    __parallel:                - __name: step1 # the response of this will be accessible within the parent step key, under the step1 sub key                  __description: create account in the bank                  __ref: __http_post                  __args:                    url: ${__config.banks.urls.hdfc.create_user}/${__args.pan}                    body: # body is {user_name: string, address: string}                      user_name:  ${__request.body.user_name}                      address:  ${__request.body.address}                    query:                      user_name: ${__request.query.user_name}                    headers:                      xyz: 2134234                  __hooks:                    __on_error:                      - __ref: __log                        __args:                          level:                          data:                            key1: val1                            key2: val2                - __description: create account in our LOS                  __name: step2                  __sequence:                    - __ref: __assign                      __name: nested_step                      __args:                          create_user_url: ${__config.los.urls.create_user}                          user_id: ${__response.data.step1.data.user_id}                          user_name: ${__request.params.user_name}                    - __summary: Create loan in LOS                      __ref: __http_post                      __args:                        url: ${__vars.step1.code}/${__vars.user_id}/?user_name=${__vars.user_name}                        body: # body is {user_name: string, address: string}                          user_name:  ${__event.data.body.user_name}                          address:  ${__request.body.address}                          loan_id: ${__response.step1.data.loan_id}                        query:                          user_id: ${__vars.user_id}                        headers:                          access_token: ${__env.hdfc_token}                      __hooks:                        __on_error:                          - ${__super.__on_error}                        __finally:                          - ${__super.preauths}                      __on_err:                          __args:                            acceptable: true                            retry:                              count: 3                              interval: 100 #milliseconds                              strategy: incremental_backoff                              onError:                                __ref: *alias_deadqueue_ref                            saga_compensation:                              __ref: __notification__email                                __args:                                  #args for compensation                              __on_err:                                __args:                                  ignore: true                - __description: send event to message bus of successful loan creation                  __name: item_name                  __ref: __send_message # For example send the request to MB to notify any consumers that this API has been called on this microservice                    __args:                      topic: com.abc.li.create_loan.success                      body:                        data: ${__request}                      headers:                        custom_header_1: custom_value                - __description: Save in the DB                  __ref: __data.insert                  __args:                    _type: user                    _id: ${user_id}                      body:                        user_name: ${__vars.user_name}              hooks:                validation:                auths:                  - role_permission              __on_error:                __return:",
    "title": "Introduction  Examples ​",
    "tokens": 2603,
    "length": 4033
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old",
    "content": "Title: Core Interfaces  Core Interfaces. Content:",
    "title": "Core Interfaces  Core Interfaces",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old#type-gsinstruction",
    "content": "Title: Core Interfaces  Type GSInstruction ​. Content: A GSInstruction is a wrapper around actual business logic aka  function or action  or even another GSInstruction. This is a core building block of the Godspeed SDK modules, function DAG composition, and the proposed way of doing things from a flexibility, seperation of concern and dynamism point of view.GSInstruction allows to wrap a set of checks and custom behavior before and after the actual action (an atomic action unit of the business logic). The actual function of a GSInstruction can be written in any language. Except for JS and TS, all other language functions are compiled to Webassembly and run on this framework. GSInstruction also has the finally clause to wrap up before returning from this instruction. Function DAG is also an Instruction comprising of set of Instructions recursively.This  layered design  has following benefits   Separation of concern  Business logic is decoupled from authorizations, validations, auto instrumentation, auto exposing REST/Event interface etc. This can be plugged into any kind of microservice framework, including Godspeed.     Flexibility  It gives developer flexibility to implement different business flows around a common action. This can be across products, A/B tests or tenants. This is achieved by reusing core actions while decorating them with different pre and post hooks. For example   Geo fencing  API monetization  Rate limiting  Tenant specific payload validation    Dynamism:  The pre and post hooks of an Instruction can be dynamically updated (added or removed) by the program,  without restarting the service .     Custom observability:  Add business metrices or any other signals.  GSInstruction Constructor ​          name: String,          preAuthHooks?: [GSInstruction] // Auto telemetry, custom business logic, pre-loading.          auths?: [GSAssert] //RBAC/ABAC/JWT          onAuthError?:[GSAction] // What to do on error in auths          validations?: [GSAssert | GSL] //GSL when parsed, its command should be implemented via a GSAssert interface          onValidationsError?:[GSAction] // What to do on error in validations          preFunctionHooks: [GSAction]          onPreFunctionHooksError?:[GSAction]  // What to do on error in  PreFunctionHooks          _function: [GSAction]          onFunctionError?:[GSAction] //What to do on error in _functions          postFunctionHooks?: [GSAction] //To act upon error, or success cases.          finally?: [GSAction]                     GSInstruction.execute() ​      // Arguments      ctx: GSContext,      params: JSON                     GSReturn ​          res: GSResponse //On successful execution          error: GSError //On Error          events: [GSEvent] //Any events that happened when the instruction was running, in order of occurence. Usefor for Business Process Monitoring.",
    "title": "Core Interfaces  Type GSInstruction ​",
    "tokens": 812,
    "length": 2818
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old#type-gserror",
    "content": "Title: Core Interfaces  Type GSError ​. Content: code: //An error code extending the standards          message: String          stack: [String]//Stack trace          errors: [GSError]",
    "title": "Core Interfaces  Type GSError ​",
    "tokens": 55,
    "length": 135
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old#type-gsresponse",
    "content": "Title: Core Interfaces  Type GSResponse ​. Content: code: //A GS error code extending the standards          message: String          data: Any object or data type",
    "title": "Core Interfaces  Type GSResponse ​",
    "tokens": 38,
    "length": 111
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old#type-gscontext",
    "content": "Title: Core Interfaces  Type GSContext ​. Content: The GSContext includes all the context specific information like tracing information, actor, environment, headers, payload, shared state (if this ctx is shared with other instruction threads, this part can be shared with them), immutable state (personal copy, personal view, for concurrency) A context has the following properties          data: Any object or data type //All memoized data with shared references. References can have promises or actual data. This is not concurrency safe.          immutable: Any object or data type //For storing and accessing references which are unique to this execution context (for concurrency safety, in the functional programming way).          actor: String //JWT and other user specific info          headers: Object //In case there were any headers with the payload in messagebus or in HTTP          payload: Object //The arguments to include in this function          otel: Any object or data type //OTEL compliant trace/span information",
    "title": "Core Interfaces  Type GSContext ​",
    "tokens": 236,
    "length": 981
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old#type-gsassert-extends-gsinstruction",
    "content": "Title: Core Interfaces  Type GSAssert extends GSInstruction ​. Content: This is typically a condition check that matches a condition against given data or data promise.     ctx: GSContext      data: JSON | GSDataFetch // Internally GSAssert invokes GSDataFetch.getData() and applies the pass/fail condition to it.      condition: [GSCondition] // to run on the data, evaluating to true or false.                     Returns ​ On successful assertion ​ A GSResponse instance with following data\npass: true | falseOn error ​ It return a GSError instance",
    "title": "Core Interfaces  Type GSAssert extends GSInstruction ​",
    "tokens": 142,
    "length": 479
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old#type-gsdatafetch-extends-gsinstruction",
    "content": "Title: Core Interfaces  Type GSDataFetch extends GSInstruction ​. Content: GSDataFetch.invoke() data or promise of it.GSDataFetch can be a DB/cache fetch instruction  a file fetch instruction  HTTP fetch instruction (Own or third party API)  Data federation instruction  Any kind of a function which returns some data",
    "title": "Core Interfaces  Type GSDataFetch extends GSInstruction ​",
    "tokens": 55,
    "length": 242
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/functions_old#type-gscondition",
    "content": "Title: Core Interfaces  Type GSCondition ​. Content: A GSCondition interface is a function which evaluates to true or false, when supplied with  context  and  data \nThis condition can be GSInstruction  A TS/JS function  JSON schema instruction",
    "title": "Core Interfaces  Type GSCondition ​",
    "tokens": 44,
    "length": 190
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/intro",
    "content": "Title: Business Logic  Business Logic. Content:",
    "title": "Business Logic  Business Logic",
    "tokens": 0,
    "length": 0
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/intro#introduction",
    "content": "Title: Business Logic  Introduction ​. Content: You can express and run your business logic with Godspeed microservice or servlerless, in the two basic ways Within the Godspeed framework's runtime  As YAML function DAG (Godspeed DSL)  As JS/TS    In a different runtime (Using any language or framework)  Via HTTP, gRpc or event interface    The two basic concepts to learn here are functions and events",
    "title": "Business Logic  Introduction ​",
    "tokens": 86,
    "length": 355
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/intro#with-godspeed-microservice-framework",
    "content": "Title: Business Logic Introduction ​ With Godspeed microservice framework ​. Content: The Godspeed framework's runtime has capability to execute a function DAG written in the Godspeed DSL, or in JS/TS. Both kinds of business logic expressions are executed by Godspeed, as  GSInstruction .The framework patches in and executes the business logic as GSInstructions which also provide middleware hooking mechanism. This decouples the function logic and middleware from the runtime environment. When patched into a microservice, the function gets automatically exposed through REST, event driven and socket interfaces, based on the api schema settings. There is a standard way to define and patch business logic and middleware into a Godspeed microservice or in serverless workflows, during both the process load time and run time.",
    "title": "Business Logic Introduction ​ With Godspeed microservice framework ​",
    "tokens": 147,
    "length": 741
  },
  {
    "url": "https://docs.godspeed.systems/docs/writing-business-logic/intro#steps",
    "content": "Title: Business Logic  Steps ​. Content: Use Godspeed CLI to generate the folder template (scaffolding) for a project. Import other modules in the project, as per the templating specifications.  Write your business logic in YAML DSL or JS/TS, in the scaffolded module directory.  Modify the microservice config including which namespace/functions of this project are to be exposed as REST/Event endpoints, with query validations.  Start the Godspeed service specifying the path to the project folder.",
    "title": "Business Logic  Steps ​",
    "tokens": 101,
    "length": 459
  },
  {
    "url": "https://docs.godspeed.systems/",
    "content": "Title: Godspeed Docs  Godspeed Docs. Content: Documentation for GodspeedGodspeed Tutorial - 5min ⏱️",
    "title": "Godspeed Docs  Godspeed Docs",
    "tokens": 15,
    "length": 53
  },
  {
    "url": "https://docs.godspeed.systems/",
    "content": "Title: Godspeed Docs  Easy to Use. Content: Docusaurus was designed from the ground up to be easily installed and used to get your website up and running quickly.",
    "title": "Godspeed Docs  Easy to Use",
    "tokens": 24,
    "length": 118
  },
  {
    "url": "https://docs.godspeed.systems/",
    "content": "Title: Godspeed Docs  Focus on What Matters. Content: Docusaurus lets you focus on your docs, and we'll do the chores. Go ahead and move your docs into the docs directory.",
    "title": "Godspeed Docs  Focus on What Matters",
    "tokens": 28,
    "length": 117
  },
  {
    "url": "https://docs.godspeed.systems/",
    "content": "Title: Godspeed Docs  Powered by React. Content: Extend or customize your website layout by reusing React. Docusaurus can be extended while reusing the same header and footer.",
    "title": "Godspeed Docs  Powered by React",
    "tokens": 28,
    "length": 126
  }
]
