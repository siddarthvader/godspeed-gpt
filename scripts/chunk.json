[{"pageContent":"You don't need React to write simple standalone pages.","metadata":{"source":"scripts/gs.json","line":1,"url":"https://docs.godspeed.systems/markdown-page","title":"Markdown page example  Markdown page example"}},{"pageContent":"March 26, 2023  · 3 min read","metadata":{"source":"scripts/gs.json","line":2,"url":"https://docs.godspeed.systems/tutorial/tutorial/learning-module/beginner-track","title":"Learning Module - Level 1 [Beginner Track]"}},{"pageContent":"March 27, 2023  · 3 min read","metadata":{"source":"scripts/gs.json","line":3,"url":"https://docs.godspeed.systems/tutorial/tutorial/learning-module/intermediate-track","title":"Learning Module - Level 2 [Intermediate Track]"}},{"pageContent":"March 28, 2023  · One min read","metadata":{"source":"scripts/gs.json","line":4,"url":"https://docs.godspeed.systems/tutorial/tutorial/learning-module/advanced-track","title":"Learning Module - Level 3 [Advanced Track]"}},{"pageContent":"Archive","metadata":{"source":"scripts/gs.json","line":5,"url":"https://docs.godspeed.systems/tutorial/archive","title":"Archive  Archive"}},{"pageContent":"LINK-> March 26, 2023 - Learning Module - Level 1 [Beginner Track] /tutorial/learning-module/beginner-track <-LINK    LINK-> March 27, 2023 - Learning Module - Level 2 [Intermediate Track] /tutorial/learning-module/intermediate-track <-LINK    LINK-> March 28, 2023 - Learning Module - Level 3 [Advanced Track] /tutorial/learning-module/advanced-track <-LINK","metadata":{"source":"scripts/gs.json","line":6,"url":"https://docs.godspeed.systems/tutorial/archive","title":"Archive  2023"}},{"pageContent":"March 28, 2023  · One min read","metadata":{"source":"scripts/gs.json","line":7,"url":"https://docs.godspeed.systems/tutorial/learning-module/advanced-track","title":"Learning Module - Level 3 [Advanced Track]  Learning Module - Level 3 [Advanced Track]"}},{"pageContent":"March 26, 2023  · 3 min read","metadata":{"source":"scripts/gs.json","line":8,"url":"https://docs.godspeed.systems/tutorial/learning-module/beginner-track","title":"Learning Module - Level 1 [Beginner Track]  Learning Module - Level 1 [Beginner Track]"}},{"pageContent":"March 27, 2023  · 3 min read","metadata":{"source":"scripts/gs.json","line":9,"url":"https://docs.godspeed.systems/tutorial/learning-module/intermediate-track","title":"Learning Module - Level 2 [Intermediate Track]  Learning Module - Level 2 [Intermediate Track]"}},{"pageContent":"External services will communicate with API gateway synchronously and will follow the request - response cycle.","metadata":{"source":"scripts/gs.json","line":10,"url":"https://docs.godspeed.systems/docs/","title":"Hello World!  Hello World!"}},{"pageContent":"Communication between microservices could either be synchronous or asynchronous. All synchronous communication will happen, either through HTTP or gRPC, via the service mesh (using proxy sidecar). Asynchronous communication will follow event-driven architecture (EDA) through messages/events. The event format will follow the CloudEvents specification (a standard open format.","metadata":{"source":"scripts/gs.json","line":11,"url":"https://docs.godspeed.systems/docs/communication/intro","title":"Introduction  Introduction"}},{"pageContent":"A workflow is a serverless function which could be triggered by an event or a schedule, being listened to by ArgoEvents. Examples include AI/ML computation, CI/CD workflows, ETLs.","metadata":{"source":"scripts/gs.json","line":12,"url":"https://docs.godspeed.systems/docs/communication/intro#external-to-api-gateway","title":"Introduction  External to API gateway  ​"}},{"pageContent":"LINK-> Linkerd https://linkerd.io/ <-LINK  (service mesh for sync communication)   LINK-> Kafka with CloudEvents format messages https://kafka.js.org/ <-LINK  (Message bus for async communication)   LINK-> Argo Events https://argoproj.github.io/argo-events/ <-LINK  (for listening to events from multiple sources and triggering workflows)","metadata":{"source":"scripts/gs.json","line":13,"url":"https://docs.godspeed.systems/docs/communication/intro#microservices-communication","title":"Introduction  Microservices communication  ​"}},{"pageContent":"Make sure that you have appropriate  LINK-> model specifications /docs/data-at-flow-and-at-rest/model-setup <-LINK  in your project. The CLI will guide the user for the project specific CRUD setup.Importing your project in a microservice LINK-> ​ #importing-your-project-in-a-microservice <-LINK When you start Godspeed microservice with your project, it will [autogenerate the REST, Socket and Message bus endpoints] for the functions exported by your project. You can customize your exports in  CODE ``` config/global-exports.yaml ``` CODE  file. --> It will export the CRUD functions  It will also export any other functions you have in your project structure.","metadata":{"source":"scripts/gs.json","line":14,"url":"https://docs.godspeed.systems/docs/communication/intro#triggered-workflows","title":"Introduction  Triggered workflows  ​"}},{"pageContent":"The query interface of these functions is generic, and vendor independent. Yet, there are ways to run SQL and native queries on every vendor.    CODE ```     //SQL query to Postgres      godspeed.find({        _sql_query: “select * from….”,        source: “postgres” //Can be any configured database which supports SQL      })        //Mongodb query      godspeed.findOrCreate({        _type: “article”, //Godspeed uses the terminology _type for entity type. It translates to collection/index/table names automatically in its pluralized form.        _native_query : { tags: [\"technology\", \"low-code\"] },        source: “mongodb”      })     ``` CODE              All of the functions below can be run in any combination as a function DAG.","metadata":{"source":"scripts/gs.json","line":15,"url":"https://docs.godspeed.systems/docs/communication/technology-used/intro","title":"Technologies used (Default)  Technologies used (Default)"}},{"pageContent":"Saves the entity in the target database.Params LINK-> ​ #params <-LINK    CODE ```     _type: String //One of the types from the model      _id: String | Number //Optional. If not given, a UUID is autogenerated.      body: Object //A body as per the defined fields of the entity. This will be validated against the respective model   ``` CODE              Example request    CODE ```   {      '_type': 'borrower_profile',      'body': {        'english': {          'name': 'Deepti'        },        'hindi': {          'name': 'दीप्ति'        },        pan: 'AKJPG810**',        pincode: 176057,        product: { //While creating an entity, it can also be linked to an existing entity, by their valid relationship          _id: 5 //Link to the product with id 5        }      }    }   ``` CODE             Response LINK-> ​ #response <-LINK On Success LINK-> ​ #on-success <-LINK    CODE ```     _id: id as specified in the request      _type: type of the entity as sent in the request      status: status code as per the standards      message: Explanatory message   ``` CODE             On failure LINK-> ​ #on-failure <-LINK    CODE ```     //A GSError object      status: status code, extending the standards      message: Error message      stack: Error stack      errors: [GSError]   ``` CODE","metadata":{"source":"scripts/gs.json","line":16,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API","title":"API specs  API specs"}},{"pageContent":"Params LINK-> ​ #params-1 <-LINK    CODE ```   _id: id of the entity field needs to be updated    _type: the type of the entity    update: the update instructions   ``` CODE              Update instructions follow the API specified  LINK-> here https://www.npmjs.com/package/js-object-updater <-LINK   Example update instructions    CODE ```   {      _id: 'AVeawbnNW2vhiwtp9F2D',      _type: 'event',      update: {        set: {          title: 'Finding Common Ground',          x: [1, 2],          yString: ['Music']        },        push: {          x: 567,          yString: ['for', 'life']        },        addToSet: {          x: [567],          yString: ['for']        },        unset: [          'y'        ]      }    }     ``` CODE             Response LINK-> ​ #response-1 <-LINK On Success LINK-> ​ #on-success-1 <-LINK    CODE ```     status: 201      message: Successfully updated      data:        _id: id as specified in the request        _type: type of the entity updated   ``` CODE             On failure LINK-> ​ #on-failure-1 <-LINK    CODE ```     //A GSError object      status: status code, extending the standards      stack: Error stack      message: Error message      errors: [GSError]   ``` CODE","metadata":{"source":"scripts/gs.json","line":17,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#getting-started","title":"API specs  Getting Started ​"}},{"pageContent":"Deletes are cascading. Deleting an entity also removes its references (and any denormalized data) in other entities to which the entity is liked.Params LINK-> ​ #params-2 <-LINK    CODE ```   _id: id of the entity field needs to be updated    _type: the type of the entity   ``` CODE             Response LINK-> ​ #response-2 <-LINK On Success LINK-> ​ #on-success-2 <-LINK    CODE ```     status: 204      message: Deleted successfully      data:         _id: id as specified in the request        _type: type of the entity as sent in the request   ``` CODE             On failure LINK-> ​ #on-failure-2 <-LINK    CODE ```     //A GSError object      status: status code, extending the standards      stack: Error stack      message: Error message      errors: [GSError]   ``` CODE","metadata":{"source":"scripts/gs.json","line":18,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#importing-crud-module-to-your-project","title":"API specs Getting Started ​  Importing CRUD module to your project ​"}},{"pageContent":"One can retrieve an entity of a given type by its _id.   CODE ```   // Fetch borrower profile with selected fields and also some fields(GMV) from its relationship      {      _type: 'borrower_profile',      _id: 'AVeuJeQ9jGz7t7QfUg_M',      langs: ['hindi']      returnData: {        name: 1, //multi lingual field in DB model spec        mid: 1,        linkedProduct: {          name: 1        }      }    }      // Returns    {        \"message\": \"Successfully read borrower_profile\",        \"status\": 200,        \"data\": {            \"_type\": \"borrower_profile\",            \"_id\": \"AVeuJeQ9jGz7t7QfUg_M\",            \"data\": {               'hindi': {                  'name': 'दीप्ति'                },                'mid': '87asdf87',                'linkedProduct': {                  '_id': 5,                  '_type': 'product'                  'data': {                    'name': \"Existence\"                  }                }            }        }    }   ``` CODE             Params LINK-> ​ #params-3 <-LINK    CODE ```   _type: type of the entity    _id: id of the entity    returnData: The data to return including the entity's own properties and those of its related entities.    langs: Optional. The retrieved data is to be brought only for these languages. Other language data will not be retrieved. By default, all language data is retrieved.   ``` CODE             Response LINK-> ​ #response-3 <-LINK On Success LINK-> ​ #on-success-3 <-LINK    CODE ```     status: 200      data: the data including the id, type and the requested returnData      message: Successfully retrieved   ``` CODE             On failure LINK-> ​ #on-failure-3 <-LINK    CODE ```     //A GSError object      status: status code, extending the standards      stack: Error stack      message: Error message      errors: [GSError]   ``` CODE","metadata":{"source":"scripts/gs.json","line":19,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#universal-crud-api","title":"API specs Getting Started ​  Universal CRUD API ​"}},{"pageContent":"Find entities matching specified criteria with pagination.   CODE ```   // Fetch borrower profile with selected fields and also some fields(GMV) from its relationship      {      _type: 'borrower_profile',      query: {        name: 'दीप्ति'      },      langs: ['hindi'],      returnData: {        name: 1, //multi lingual field in DB model spec        mid: 1,        linkedProduct: {          name: 1        }      }    }      // Returns    {        \"message\": \"Successfully read borrower_profile\",        \"status\": 200,        \"data\": {          \"count\" : 11,          \"data\": [              {                \"_type\": \"borrower_profile\",                \"_id\": \"AVeuJeQ9jGz7t7QfUg_M\",                \"data\": {                  'hindi': {                      'name': 'दीप्ति'                    },                    'mid': '87asdf87',                    'linkedProduct': {                      '_id': 5,                      '_type': 'product'                      'data': {                        'name': \"Existence\"                      }                    }                }            }          ]        },      }   ``` CODE             Params LINK-> ​ #params-4 <-LINK    CODE ```     _type: A single entity type or multiple types in an array      returnData: The data to return (same as get by id above)      query: The matching criteria in GS syntax      _sql_query: The matching criteria in SQL format      _native_query: The matching criteria in native DB format      size: The number of matching results wanted      offset: The offset for pagination      langs: The languages in which data is to be retrieved   ``` CODE              Note: among the query, _sql_query, _native_query clauses, only one of them must be present, else an error is raised Response LINK-> ​ #response-4 <-LINK On Success LINK-> ​ #on-success-4 <-LINK    CODE ```     status: 200      data: matched entities with their respective id, type and returnData      message: Successfully retrieved   ``` CODE             On failure LINK-> ​ #on-failure-4 <-LINK    CODE ```     //A GSError object      status: status code, extending the standards      message: Telling what happened      errors: List of GSError objects explaining errors in details   ``` CODE","metadata":{"source":"scripts/gs.json","line":20,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#crud-api-available-functions","title":"API specs  CRUD API available functions ​"}},{"pageContent":"It is an extension of 'find' with where clause including additional text search capabilities like match_phrase and autosuggest. Currently works with Elasticsearch backend.Request LINK-> ​ #request <-LINK    CODE ```     _type: A single entity type or multiple types in an array      returnData: The data to return (same as get by id)      query: The matching criteria in GS syntax      _native_query: Elasticsearch API      _sql_query: Elasticsearch supported SQL syntax      size: The number of matching results wanted      offset: The offset for pagination      langs: The languages in which data is to be retrieved     ``` CODE             Response LINK-> ​ #response-5 <-LINK On Success LINK-> ​ #on-success-5 <-LINK    CODE ```     _id: id as specified in the request      _type: type of the entity as sent in the request      status: status code as per the standards   ``` CODE             On failure LINK-> ​ #on-failure-5 <-LINK    CODE ```     //A GSError object      status: status code, extending the standards      message: Telling what happened      errors: List of GSError objects explaining errors in details   ``` CODE","metadata":{"source":"scripts/gs.json","line":21,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#create","title":"API specs CRUD API available functions ​  Create ​"}},{"pageContent":"Godspeed has in-built support for federating data from multiple sources like database, search engine, warehouse, third party API & another microservice in both sync and async manner. One can execute multiple queries to configured sources within a single query Read only, write only or mixed. i.e. a single instruction can contain a combination of multiple reads and writes.  Non transactional or as a distributed transaction.  Retry logic, circuit breaker.  Notes  In case there are multiple independent transactions in the call or queries of any nature, and one is ok for some to fail but some not, then one can specify  CODE ``` ignoreError:true ``` CODE  in those calls.   It is recommended that the developer defines all the API schema on server side when going to production. They should export native functions like federate(shown below) as API contract with caution.","metadata":{"source":"scripts/gs.json","line":22,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#update","title":"API specs CRUD API available functions ​  Update ​"}},{"pageContent":"Dedicated Backend For Frontend (BFF) service  As part of a custom Godspeed service.","metadata":{"source":"scripts/gs.json","line":23,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#delete","title":"API specs CRUD API available functions ​  Delete ​"}},{"pageContent":"CODE ```   POST /api/v1/${domain}/${microserviceName}/federate    {        'searchResponse': { //The response of the query will come under this key in response from the service            \"instruction\": “findAll”, //This instruction has been declared on the server side in the API schema            \"params”: {                query_gs: {                    “match_phrase”: {“borrower.city.name”: “patna”},                    “exists”: “pincode”,                    “anyOneOf”: [                        {range: {annualIncome”: {\"gte\": 1000000}}},                        {“match”: {“hasOwnHouse”: true}},                       ]                }            }        },          'saveBorrowerProfileResponse': {            “instruction”: “saveBorrowersProfile”,            “ignoreError”: true,            \"retry\": {                \"count\": 3,                \"timeout\": 200 //milliseconds            },            \"params”: {                “name”: 1,                “pan”: “asdfadsf”            }        }    }   ``` CODE","metadata":{"source":"scripts/gs.json","line":24,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#get-by-id","title":"API specs CRUD API available functions ​  Get by Id ​"}},{"pageContent":"In Godspeed, one can query multiple databases through single API layer.\nThis generic API decouples The application code from underlying DB.  Common params    CODE ```   request:            ds //datasource            {queryType} : // can be one of  query_sql, query_native, query_gsl                        { actual query}        response:            status_code            message            _score //total score            result [                  {_score://indivual score for each match                   data : { fields value corresponding to returnData }                  }                  ]       ``` CODE               A sample query  \nThis query will be sent to the underlying primary database, which is typically a transactional store.   CODE ```     /** The default datasource for executing queries is the       * primary datastore (as per the configuration) unless specifically mentioned in the       * query with the 'source' argument.       */        /api/v2/search      {        type: 'user',        where: {          name: \"ayush\" //Executes an exact match        }      }   ``` CODE             One may want to leverage Elasticsearch for text search or faster reads.\nIf setup as secondary datastore, it will be synced with the primary\nas per the data model configuration.\nThe following query is targetted specifically to Elasticsearch.\nBut any supported database can be set as secondary, not just Elasticsearch.   CODE ```     /api/v2/search      {        source: 'elasticsearch', //can be 'cache', 'mongodb' or an in memory object etc.        query: {          type: 'user',          where: {            age: {              gte: 'ayush'            },            'city.name': {              matchPhrase: 'delhi' //Executes a text search            }          }        }      }     ``` CODE","metadata":{"source":"scripts/gs.json","line":25,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#find","title":"API specs CRUD API available functions ​  Find ​"}},{"pageContent":"A developer is not limited to use only the generic interface. Infact Godspeed design allows developer to execute SQL queries and native queries both.\nIn case,source is cache or in-memory object store, then the native query or SQL query may or may not be available as the constraint imposed by underlying cache or in-memory object store.   CODE ```     /api/v2/search      {         source: “postgres” //Can be any configured database and supporting SQL        _sql_query: {                      'select * from user where age > 8 and name='Ayush'                    }        }        //OR to a secondary datastore      {        source: 'mongoDB',        _native_query : { tags: [\"technology\", \"low-code\"] },        }   ``` CODE","metadata":{"source":"scripts/gs.json","line":26,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/CRUD%20API#search","title":"API specs CRUD API available functions ​  Search ​"}},{"pageContent":"This API is relationship aware, even with NoSQL stores like Elasticsearch and MongoDB. Based on the relationship definitions,\nthe following is managed by this library out of the box. (No code) Bidirectional relationship maintenance. i.e. A single API call establishes relationships from A to B and B to A  It is also possible to configure storage of foreign keys only on one side, yet traverse from both sides. (Similar to Graph databases)    Denormalisation support is also provided out of the box, across all NoSQL stores support. i.e. MongoDB and Elasticsearch    CODE ```   //An example of many to many relationships. An Event has multiple speakers, and a speaker can speak in many events.    speakers <> events    [event] <> [speaker]    Don't store foreign key in speaker //Means only event will have the foreign key of speaker stored in it.      //For denormalization, the following rule in schema/denormalisation.txt stores the names of speakers in the event    [event]    speakers{name} //Whenever a speaker and event are linked, the speaker's name is automatically copied to the event along with the foreign key (speaker's id).                   //When unlinked, the name of the speaker is also removed along with the foreign key.                   //When the name of the speaker is changed, the new name reflects across all the events where that speaker is linked.   ``` CODE","metadata":{"source":"scripts/gs.json","line":27,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation","title":"Data Federation  Data Federation"}},{"pageContent":"In order to optimize the performance of databases and the microservices, the framework allows to  CODE ``` batch the CRUD queries, per database ``` CODE  (by query category, i.e. get, create, find, delete, update)\n.  All queries of one type and to one DB (irrespective of their arguments like entity type, where clause) are batched by default, unless specified otherwise.    Queries and their reponse are multiplexed and demultiplexed internally so that the client never knows what else went in a batch.    All queries including transactions are batched together internally in same sequence as arrival of the queries    Error in one query does not affect the result of the other queries. The callers of each get their respective success or failure response as if they had executed the query without any batching in the first place.     CODE ``` In config/collect.toml ``` CODE    CODE ```   //Project level setting for batching.    //Specify the batch size or timeout, for every query category      noBatch = false // Can be set to true, in which case batching will not happen by default.    [batchSizes]      find = 20      create = 20      get = 20      update = 20      delete = 20    [timeouts] //in milli seconds      find = 20      create = 20      get = 20      update = 20      delete = 20      When invoking through JS      gs.find.collect() //Executes with batching      //When exposing the function externally through a microservice, it is batched by default      gs.find({        query: {}      })   ``` CODE              And, batching is optional    CODE ```     //When invoking through JS, don't add .collect() to the CRUD function calls      gs.find()      //When exposing the function externally through a microservice, you can add noBatch: true      gs.find({        noBatch: true      }   ``` CODE              You can set default setting of the API to noBatch. In that case you will need to say  CODE ``` noBatch: false ``` CODE  exlicitly to batch a kind of query.","metadata":{"source":"scripts/gs.json","line":28,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation#introduction","title":"Data Federation  Introduction ​"}},{"pageContent":"When writing to a datasource which support transactions, all writes are always transactions.\nA single write allows to update multiple entities/rows.","metadata":{"source":"scripts/gs.json","line":29,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation#the-uses-of-data-federation-can-be","title":"Data Federation Introduction ​  The uses of data federation can be ​"}},{"pageContent":"Developer does not need to worry about dual writes\nfor data syncing across multiple types of databases used in the app.Main featues of the dual writes are following: Just configure the federated DB model, write only to your primary. Your secondary databases will get eventually synced, as per your model settings.  It is intended for future to also handle transactions spread across multiple databases via Saga pattern.","metadata":{"source":"scripts/gs.json","line":30,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/data-federation#sample-instruction","title":"Data Federation Introduction ​  Sample instruction ​"}},{"pageContent":"Based on scaffolding of microservice project,\nthere will be right place to put project configurations for each module and also common settings.\nThe model configuration discussed in this document is a part of the project configuration.The configurations for model/data setup cover not only the entity model with relationships\nbut also all the different databases the project will use, how the data syncs between them\nand the Single Source of Truth settings for all entities.","metadata":{"source":"scripts/gs.json","line":31,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro","title":"CRUD Module Introduction  CRUD Module Introduction"}},{"pageContent":"In the configuration/databases/{db.toml} files there will be settings for respective dbs that are included in this project.   CODE ```   //elasticsearch.toml    name = elasticsearch    maxConnections = 200    apiVersion = '7.4'    requestTimeout = 90000    node = 'http://localhost:9200'    sniffOnStart = true   ``` CODE","metadata":{"source":"scripts/gs.json","line":32,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#single-universal-api-for-multiple-database","title":"CRUD Module Introduction  Single Universal API for multiple database ​"}},{"pageContent":"We use the word entities (similar to rows in MySQL, or nodes in a Graph) for\nrefering to individual data points of a particular type.\nEach entity has an id, type, fields like text, date etc. and relationships (akin to foreign keys).\nThe configurations of a field are all declared in one file.Each entity is stored in a separate table/index/colelction depending on the database used.\nThe name of that will be pluralized and autogenerated as {entity._type + ‘s’}For example, for type video, the collection/index/table name will be videos The simple fields of an entity and their settings are defined in  configFolder/schema/entities/{entityType}.toml As per the definitions, the schema in the datastores (ES or PG) is generated from here. The migrations also make use of these definitions, to run.Here is a sample config for a sample entity type in TOML format   CODE ```   sstDB = postgres //The main DB for this entity as its SST.    All writes will happen here first, and later the other DBs    will get eventually (automatically) synced through CDC mechanism.      [name]    type = 'String'    enum = ['value1', 'value2']    multiLingual = true    [name.postgres]    sortable = true //Will create index for this to sort on, in PG    [name.elasticsearch] //Create appropriate indices in ES for    the queries we wish to do on this field    autoSuggestion = true    exactMatch = true    sortable = true   ``` CODE             Corresponding document of an Event, when returned from the\nAPI will look like shown below. It does not matter\nwhich underlying database the information is being fetched from.   CODE ```   {      \"_type\": \"person\",      \"_id\": \"294464\",      \"_version\": 4,      \"data\": {        \"tibetan\": {          \"name\": \"ཆེན་པོ་མཆོག་ནས་ནང་ཆོས་ངོ་སྤྲོད་སྩལ་།\",        },        \"english\": {          \"name\": \"His Holiness the Fourteenth Dalai Lama.\",        }      }    }   ``` CODE             The data model you set is used to generate the appropriate schema in respective databases.","metadata":{"source":"scripts/gs.json","line":33,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#support-for-native-and-sql-queries","title":"CRUD Module Introduction  Support for native and SQL queries ​"}},{"pageContent":"You must define the relationships of your data model in  configFolder/schema/relationships.txt  It is compulsory to maintain relationship name both ways, from Entity A to B, and B to A.  This is so that one can express Graph traversal from both sides.The format for specifying relationships in relationship file is   CODE ```   relationNameFromAToB <> relationNameFromBToA    entityTypeA <> entityTypeB //One to one      relationNameFromAToB <> relationNameFromBToA    [entityTypeA] <> entityTypeB //Many to one      relationNameFromAToBs <> relationNameFromBToA    entityTypeA <> [entityTypeB] //One to many      relationNameFromAsToBs <> relationNameFromBsToAs    [entityTypeA] <> [entityTypeB] //many to many   ``` CODE              As you can see, when an entity type is surrounded by square brackets [], it means cardinality of many Some examples   CODE ```   speakers <> events    [event] <> [speaker]    sessions <> event    event <> [session]     ``` CODE             Example link call   CODE ```   es.deep.link({        e1: {            _type: ‘event’,            _id: ‘674’        },        e2: {            _type: session,            _id: 4        },        e1ToE2Relation: ‘sessions’    })    .then(console.log)   ``` CODE","metadata":{"source":"scripts/gs.json","line":34,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#relationship-awareness","title":"CRUD Module Introduction  Relationship awareness ​"}},{"pageContent":"We use denormalisation to make it fast  Settings configFolder/schema/denormalisation.txt Imagine you have a database composed of events, speakers and persons.And, you wish to do the following two queries. Search events by speakers.person.name  Show countwise breakup of search results on events, based on speakers.person.name (like on ecommerce sites)  If your tables have only the foreign keys, you will have to do multiple hits to implement such cross table queries. And they will be slow. Depending on your data size, this may take a long long time before the final query result is returned. Also, your database will most probably get under heavy load.  With Godspeed you can denormalize based on simple rule setting and achieve the same result with a single hit to the database.  By denormalizing (always ensuring latest copy of) the speaker.person.name information within the event object,  during index, update, link or unlink calls .For example, here is how ‘event’ may look like in denormalization settings (in the file joins/index.txt)   CODE ```   [event]    sessions{title, description}    speakers.person{name}   ``` CODE             Based on your configuration the CRUD module works to automatically maintain the denormalised storage of speaker and session data in the event entities.\n  You only need to link or unlink two entities by a relationship. Everything else is taken care by Godspeed.  Maintenance of the denormalised state LINK-> ​ #maintenance-of-the-denormalised-state <-LINK Here are some scenarios in which the automatic denormalization will trigger in our example database.  Whenever you update the name of a person, the events where he or she spoke, will also get updated with person’s new name.    When you index (store) the event for first time in the database, and it contains speakers ids, the speaker’s name will also get copied inside the event entity as it gets stored/indexed.    When the event is linked to a speaker, the speaker’s name will get copied inside the event entity    When the event is unlinked from a speaker, the speaker’s id, name etc will get removed from the event entity  The Butterfly effect LINK-> ​ #the-butterfly-effect <-LINK As you just saw, any update can potentially create a ripple update across entire Graph, for maintaining correct data state as per the denormalisation and also the data dependency rules like union and copy (more on the latter below).Since this is handled automatically, it saves the developer from the overhead of maintaining a consistent, denormalised graph state across all updates. Her code doesn’t need to save the updated field value at multiple places in the database- a big overhead, lots of confusing code, more bugs... Instead, she simply declares the behavior just once, in a human readable way. After that she leaves it to Godspeed to do all the internal bookkeeping to upkeep a correct denormalised graph state all the time.In ElasticSearch, MongoDB and other NoSQL stores, we can make use of the JSON style storage and do the joins within one document. In comparison to SQL way of rows, the document way of NoSQL allows for the denormalization easily. Have a look at how the denormalized speakers relationship is stored within an Godspeed event document.    CODE ```   {      \"_index\": \"events\",      \"_type\": \"event\",      \"_id\": \"294464\",      \"_version\": 4,      \"_source\": {        \"speakers\": [          {            \"_id\": \"c6c35e3b21815a4209054505ac5e1680a954efdf\",            \"own\": true,            \"data\": {              \"person\": {                \"_id\": \"1\",                \"_version\": 1,                \"data\": {                  \"english\": {                    \"name\": \"His Holiness the 14th Dalai Lama\"                  },                  \"tibetan\": {                      \"name\" : \"ང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་\"                  }                }              }            }          }        ]      }    }   ``` CODE","metadata":{"source":"scripts/gs.json","line":35,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#batching-of-queries","title":"CRUD Module Introduction  Batching of queries ​"}},{"pageContent":"Note: This strategy is perhaps best applied in write less and read more scenarios. In many data models, data of an entity in your graph may depend on the data of other related entities. For ex. if a married woman has a new child, the husband also has a new child. And vice versa.\nGodspeed gives you an easy way to manage complex data dependencies between related entities of your information graph. As any update is made to any Entity in your Graph, Godspeed checks if any part of the remaining Graph should be updated by this change as per your data model settings. If yes, it updates the entire affected Graph (Butterfly effect). This saves LOTS of lines of code, time and effort in maintaining your inter-dependent data state so that you can move faster with your development goals. For now Godspeed supports two kinds of dependencies - Union from and Copy.  Union from   Settings are in configFolder/schema/union.toml Union from operation can be used to compute and store distinct values, whether relationships or data values, merged from field values of multiple related entities.This is useful for one to many or many to many relationships. Please look at the following examples to understand.   CODE ```   [conference]    speakers = '+talks.speaker' #As soon as a talk is linked to a conferece, or an already linked talk gets linked to a speaker, *the talk’s speaker is also linked to the conference as one of its speakers, if not already linked before*. Vice versa happens if the talk is unlinked to its speaker, or the talk is removed from the conference    topics = '+talks.topics' #As soon as a talk is linked to an conference, or a topic is set to an already linked talk, the talk’s topic is also added to the conference as one of its topics, if not already there. Vice versa happens if the talk is unliked to the conference, or the topic is removed from the talk.    [‘person’]    grandChildren = +‘children.children’ #Whenever a person’s child gets a new child, the new child gets added to the person’s grandchildren    [‘folder’]    fileTypes = ‘+childFolders.fileTypes + childFiles.type’ #Calculate union of all file types existing in the entire folder tree (recursively). Anytime, any file gets added to any child folder in this tree, the type of that file gets unioned with the list of fileTypes of that child folder, and all its parent folders up in the hierarchy.   ``` CODE               Copy   Settings are in configFolder/schema/union.toml Currently the copy functionality is achieved from within the union configuration.This is effective for many to one or one to one relations. For ex.   CODE ```   [person]    inLaws = \"+spouse.parents\" #This will ensure copy of in laws between husband and wife    [file]    permissions = \"+folder.permissions\" #Whenever a folder’s permissions are updated the underlying files’ permissions are updated automatically. You can still manually override them, without affecting the folder. But whenever the folder’s permissions are updated again, the file’s permissions will get overwritten.   ``` CODE","metadata":{"source":"scripts/gs.json","line":36,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#transactions","title":"CRUD Module Introduction  Transactions ​"}},{"pageContent":"Settings file: configFolder/common.toml. In that set,  CODE ``` supportedLanguages = [‘english’ , ‘tibetan’, ‘thirdLanguage’] ``` CODE If your data is in a single language or is language agnostic, then supportedLanguages = []The fields which are declared multilingual, are stored like this in the _source of the entities.   CODE ```   \"english\": {        \"name\": \"His Holiness the 14th Dalai Lama\"    },    \"tibetan\": {        \"name\": \"ྋགོང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་པ།\"    }   ``` CODE              When creating, updating, searching or getting an entity, you have to specify the full path of every field, including its language. In search and get calls, you specify langs parameter, for the languages in which the data is to be fetched. By default data in all supported languages is fetched.","metadata":{"source":"scripts/gs.json","line":37,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/CRUD/intro#dual-writes","title":"CRUD Module Introduction  Dual writes ​"}},{"pageContent":"The data related settings of any project are all contained in  CODE ``` config/data ``` CODE  folder, in a nested hierarchy.\nThe configLoader of GS_data reads the config/data path and loads all the configurations in a JSON for use by the  CODE ``` gs_data ``` CODE  module.","metadata":{"source":"scripts/gs.json","line":38,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup","title":"Model Setup  Model Setup"}},{"pageContent":"The data config folder is located within  CODE ``` config ``` CODE  folder of the project, just like all other configurations like exports, telemetry.   CODE ```   .                   //Project root        ./src            ./actions   //This will contain all the API contracts defined in this project by developer (For API schema driven development)        ./config            ./exports   //The exported functions from ../src or imported modules            ./data      //Here will lie the data specific configurations read by the GS_data module.            ./telemetry            ...         //So on and so forth for other modules   ``` CODE","metadata":{"source":"scripts/gs.json","line":39,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#introduction","title":"Model Setup  Introduction ​"}},{"pageContent":"The folder will contain the following information in heirarchy   CODE ```       ./config/data            index.(yaml | toml | json)                  //For common fields like supportedLanguages, defaultPrimaryDB, requestTimeout etc.            ./schema                ./entities                    entityA.(yaml | toml)                    entityB.(yaml | toml)                ./relationships                    definitions.yaml | definitions.toml | definitions.gsl                    ./definitions                               // Alternatively from above line                        `${entityA} <> ${entityB}`.(gsl | yaml) // Keep all the relationships aggregated by the two entities.                    dataDependencies.gsl                        // All automatically aggregated fields with functions like union, copy and in future (average, max, min).                    denormalization.gsl                         // Copy of current elasticgraph's joins/index.txt            ./performance                ./batching //Or batching.yaml containing batch size and timeouts for different DBs of each kind                    elasticsearch.yaml                    postgres.yaml                    mongodb.yaml            ./databases //Database settings                elasticsearch.(yaml | toml)                mongodb.(yaml | toml)                postgres.(yaml | toml)            ./environments                dev.env                staginv.env                production.env   ``` CODE","metadata":{"source":"scripts/gs.json","line":40,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#setup-of-the-dbs","title":"Model Setup  Setup of the DBs ​"}},{"pageContent":"There will also be variables definable in environment files, i.e. dev.env, staging.env and production.env files.\nThese files will have some predefined variables, some empty variables. They will get their data replaced/filled by devops process as per the business use case.","metadata":{"source":"scripts/gs.json","line":41,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#entities-and-model","title":"Model Setup  Entities and model  ​"}},{"pageContent":"LINK-> Argo Events https://argoproj.github.io/argo-events/ <-LINK    LINK-> Argo Workflows https://argoproj.github.io/workflows/#:~:text=Argo%20Workflows%20is%20an%20open,using%20a%20graph%20(DAG). <-LINK    LINK-> Debezium https://debezium.io/ <-LINK    LINK-> Kafka https://kafka.js.org/ <-LINK","metadata":{"source":"scripts/gs.json","line":42,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#relationships","title":"Model Setup  Relationships  ​"}},{"pageContent":"Development environment LINK-> ​ #development-environment <-LINK  Dockerized  Linux or Mac Development practices LINK-> ​ #development-practices <-LINK  Sprint planning  Properly formatted issue/task creation  LINK-> read more /docs/faq#q5-what-is-our-development-process-and-quality-metrics <-LINK   Documentation  Coding standards  Test Coverage  Git ops  LINK-> read more /docs/springboot-integration/intro#sdk-features- <-LINK Diversity & cutting edge LINK-> ​ #diversity--cutting-edge <-LINK  Everything is better than the others for something  Learn and adopt different languages, frameworks & technologies  Be quick to discover and adapt new technologies and practices","metadata":{"source":"scripts/gs.json","line":43,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#denormalisation","title":"Model Setup  denormalisation ​"}},{"pageContent":"Documentation of every product and microservice  Coding standards  Training modules  Docker files and image links  Git repository links  Other useful links and reading material  Recommended: Docusauras","metadata":{"source":"scripts/gs.json","line":44,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#data-dependency-implementation","title":"Model Setup  Data dependency implementation  ​"}},{"pageContent":"Informtaion exchange  Fast communication  Helping each other  Recommended stack: Discourse and Slack","metadata":{"source":"scripts/gs.json","line":45,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/model-setup#multi-linguality","title":"Model Setup  Multi Linguality  ​"}},{"pageContent":"As part of our devops, we have automated our system & infra using Gitops, Kubernetes, ArgoCD, Crossplane.\nOur system infra automation can easily be integrated with existing or legacy apps.For example:\nvideo demo of  LINK-> springboot integration https://drive.google.com/drive/folders/1xTFd6N7YteLLg3Hehx8tTn6aDhxgFpWn <-LINK","metadata":{"source":"scripts/gs.json","line":46,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding","title":"Introduction  Introduction"}},{"pageContent":"Our entire effort is to be a low code, easy to learn platform without too many things to learn, while getting big jobs done. A bunch of engineers have already trained and are developing microservices. Based on our data, it takes around 3~5 days for a young intern or engineer to get started on delivering enterprise level microservices.","metadata":{"source":"scripts/gs.json","line":47,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding#folder-location","title":"Introduction  Folder location ​"}},{"pageContent":"All our upgrades go through peer reviews and test coverage (80%). We follow feature based branching. As part of our CI workflow, a developer can't commit/merge to the dev/master branches, unless all the test cases are passing. This ensures continuous sanity checks of our main branches.Documentation and test coverage are integral parts of quality metrics.\nCode and image vulnerability scans are also followed to ensure security within the code and images.Story/Bug Life Cycle LINK-> ​ #storybug-life-cycle <-LINK      tip     Todo  - Created by product owner or ticket creator.   In Progress  - By developer when they start the work.   Documentation  - By developer when they implement the feature.   Code Review  - By developer when they finish the documentation.   QA  - By a peer developer when they are testing the feature.   Done  - By person merging the pull request.","metadata":{"source":"scripts/gs.json","line":48,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding#folder-structure","title":"Introduction  Folder structure ​"}},{"pageContent":"Many times, the upgrades work with a simple update in package.json and  LINK-> updating the project /docs/microservices/introduction-cli/#update <-LINK .    If at all a core framework update is needed, it is done as per the SLA. Security patches, fixes or feature inclusion will be part of the SLA itself.    Irrespective of our SLAs, we also take an initiative to proactively support important integrations and upgrades from its side, and make it available to all clientele and potential users.    The system will have default support for free and open source software. But based on client requirements, we can provide integrations for paid versions as well based on SLA and priority. If an upgrade has a license cost, it shall be borne by the client should it decide to use it.    These changes can be done by the client team itself, because it will have proper documentation, access and right to modify source for its internal uses, and there will be minimum 80% test coverage with test automation, and KT/support by us (latter as per the SLA).","metadata":{"source":"scripts/gs.json","line":49,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/scaffolding#environment-variables","title":"Introduction  Environment variables ​"}},{"pageContent":"Since all the implementation is done against the open standards and pluggable interfaces, as long as the new technology is adhering to those standards drop-in replacement will be feasible.    If the technology is introduced that does not adhere to the open standards, then some work will be needed to create adapters and avoid vendor lock-ins. But still, the integration will have to be compliant to the interfaces, for them to work, giving a uniformity of implementation and replacement. The modular architecture and modular design is plugin based, allowing for new integrations without much hassle.    This can be done by the client itself, or by us, depending on our engagement.","metadata":{"source":"scripts/gs.json","line":50,"url":"https://docs.godspeed.systems/docs/data-at-flow-and-at-rest/technology-used/intro","title":"Technologies used (Default)  Technologies used (Default)"}},{"pageContent":"We currently support Mongodb, Postgres, MySQL, SQLServer, SQLite, MariaDB, CockroachDB, AWS Aurora, Azure SQL via  LINK-> Prisma https://www.prisma.io/ <-LINK . We are in the process of adding Elasticsearch in Q2, 2022.","metadata":{"source":"scripts/gs.json","line":51,"url":"https://docs.godspeed.systems/docs/development-process","title":"Development Process  Development Process"}},{"pageContent":"Yes there is an extensive support for  LINK-> DB transactions https://www.prisma.io/docs/concepts/components/prisma-client/transactions <-LINK .","metadata":{"source":"scripts/gs.json","line":52,"url":"https://docs.godspeed.systems/docs/development-process#developer-culture-practises-and-upskilling","title":"Development Process  Developer culture practises and upskilling ​"}},{"pageContent":"This decoupling is possible because of the universal datastore schema, CRUD API and migration process.\nFor more, please refer  LINK-> prisma docs https://www.prisma.io/docs/ <-LINK .","metadata":{"source":"scripts/gs.json","line":53,"url":"https://docs.godspeed.systems/docs/development-process#developer-portal--forum","title":"Development Process  Developer portal & forum ​"}},{"pageContent":"The performance of an API endpoint depends on the service PLUS DB working together. For example, DB connection pooling and utilization, transaction handling, batching of independent queries, optimization of indexes and queries, denormalization (for cross table queries and aggregations), memoization/caching (for faster read and solving N+1 queries problem), CQRS setup between multiple DBs.Godspeed includes algorithms and best performance practices like the ones mentioned above. We are constantly striving to improve the performance. Next up is the feature of caching of output of workflow tasks and DB queries.","metadata":{"source":"scripts/gs.json","line":54,"url":"https://docs.godspeed.systems/docs/development-process#portal","title":"Development Process Developer portal & forum ​  Portal ​"}},{"pageContent":"First of all, the hop is completely optional. There are a few benefits of using this hop, however, including  Become decoupled with the choice of database provider, so that if a DB changes ,the app code does not change.    Low code configuration of CRUD service (saves effort of development, QA & maintenance)    Data federation across multiple DBs and APIs. One can execute multiple queries to configured sources within a single query.","metadata":{"source":"scripts/gs.json","line":55,"url":"https://docs.godspeed.systems/docs/development-process#developer-forum","title":"Development Process Developer portal & forum ​  Developer forum ​"}},{"pageContent":"It shall be done in two ways.  By having separate DBs for every tenant. This will be costly but will be PCI compliant. It will also provide data isolation if needed for each tenant.    By having a tenant_id in every row/document of every table/collection/index in the database.This will be cost effective and easy to maintain but the data across multiple tenants will be in a single database.","metadata":{"source":"scripts/gs.json","line":56,"url":"https://docs.godspeed.systems/docs/development-process#devops-practices","title":"Development Process  DevOps Practices: ​"}},{"pageContent":"Start by creating a new microservice in  LINK-> 10 minutes /docs/microservices/setup/getting-started <-LINK , referring our docs.  Migration of existing microservices or monoliths:  Generate CRUD APIs and workflows out of the box, by introspecting the database of an existing app, via the CLI. Then start customizing and using it as per your need.  If you have existing Open API spec for a service, then you can generate the Godspeed event schema out of the box. (Coming soon)","metadata":{"source":"scripts/gs.json","line":57,"url":"https://docs.godspeed.systems/docs/faq","title":"COMMON FAQs  COMMON FAQs"}},{"pageContent":"It is possible to opt out of the Godspeed framework without any kind of lock-in in which case all the microservices specific to the client can be developed using some other technology stack. The DBs can be self managed.The data will anyway be hosted on the client’s premise/cloud or its vendor’s cloud. The control of the data is subject to the client’s agreement with their respective cloud vendor, whose hosted database services are being used. But if the client uses self managed DBs, then they are fully in control of their data. This has got nothing to do with Godspeed. The framework comes with no lock-in of any kind and will never do so, as part of our philosophy.","metadata":{"source":"scripts/gs.json","line":58,"url":"https://docs.godspeed.systems/docs/faq#161-what-is-the-learning-curve-of-the-microservice-framework","title":"COMMON FAQs  16.1 What is the learning curve of the microservice framework? ​"}},{"pageContent":"The framework, via Prisma, facilitates developers to access full functionality of any database or tool without being limited by the universal API. They shall be able to execute native database queries directly or via the API itself.","metadata":{"source":"scripts/gs.json","line":59,"url":"https://docs.godspeed.systems/docs/faq#162-what-is-the-development-process-and-quality-metrics","title":"COMMON FAQs  16.2 What is the development process and quality metrics? ​"}},{"pageContent":"We currently support REST and planned to support GraphQL and gRPC in Q2, 2022.","metadata":{"source":"scripts/gs.json","line":60,"url":"https://docs.godspeed.systems/docs/faq#163-how-can-we-adopt-new-versions-of-used-technology-easily-and-fast-for-example-the-new-postgres-release","title":"COMMON FAQs  16.3 How can we adopt new versions of used technology easily and fast? For example, the new Postgres release. ​"}},{"pageContent":"Every existing Graphql server in the industry supports REST/JSON interface, custom DSL and along with it, a Graphql interface (Ex. DGraph, Hasura, Apollo, Postgraphile). We are also going the same route by first being REST/JSON based, custom DSL and then adding Graphql in future. This is primarily because of greater familiarity of the REST standard across industry. At the same time, our REST implementation brings some good concepts to include in the development methodology like the concept of giving power to the frontend team to decide what data they want in response, and to get data from multiple sources in one go. We are including the features of Graphql in our design. The foundation our API interface is the unified event schema which we plan to use to generate GraphQL API (planned for Q2, 2022)Having said that, we would like to add that the Graphql standard specification does not specify a few critical things, like “where clause”, “aggregations”, “filters in joins”, “specifying relationships in model”, search/suggest queries, custom annotations, how to migrate, code first or schema first approach, etc. Every vendor has its own flavour of Graphql implementation/API, and there is no compatibility or out-of-the-box interoperability between implementations from different vendors. If the client also implements Graphql by any vendor, including Godspeed, it will be still having its own unique flavor of implementation, and the concept of data federation will not work for consumers of the API, just out of the box, as it appears to be so in theory of Graphql data federation. It will need developers to write custom resolvers to federate request/response from multiple Graphql services.In short Graphql standard lacks standard and unified implementation across industry. Further, we believe based on our survey that the Graphql ecosystem is complex and difficult to learn and extend for the uninitiated, and most developers even today do not know Grapqhl. Those who know find it complex. It lacks bringing agility for a typical developer team who is more comfortable with REST/JSON. It already took banks years to move from XML to JSON. Expecting third party consumers to consume Graphql is another big ask, a few years ahead of time.Still, it's an new upcoming standard with its own benefits. We wish to roll out our own flavor in 2022.","metadata":{"source":"scripts/gs.json","line":61,"url":"https://docs.godspeed.systems/docs/faq#164-how-easy-is-it-to-add-new-technology-in-place-of-an-existing-one-or-add-something-absolutely-new-and-unique-not-existing-in-the-framework","title":"COMMON FAQs  16.4 How easy is it to add new technology in place of an existing one, or add something absolutely new and unique (not existing in the framework)? ​"}},{"pageContent":"DSL will not get loaded if it's not in the right format.  We are planning to add language feature in VSCode for compile time checks.  We have automated test suite generation through the event schema and the developer can add testing as a part of CI process.","metadata":{"source":"scripts/gs.json","line":62,"url":"https://docs.godspeed.systems/docs/faq#165-which-databases-are-currently-supported-what-is-the-roadmap-for-future-support","title":"COMMON FAQs  16.5 Which databases are currently supported? What is the roadmap for future support? ​"}},{"pageContent":"We follow a semantic release process using  LINK-> semantic version (semver) https://semver.org/ <-LINK  with autogenerated Changelog. The developers can change/upgrade the version of the framework for any microservice  LINK-> via the CLI /docs/microservices/introduction-cli/#version <-LINK . After this, they can run the test cases and confirm if everything goes well.","metadata":{"source":"scripts/gs.json","line":63,"url":"https://docs.godspeed.systems/docs/faq#166-does-the-api-handle-db-transactions","title":"COMMON FAQs  16.6 Does the API handle DB transactions? ​"}},{"pageContent":"The framework uses Prisma which already supports paid and non paid features of databases.","metadata":{"source":"scripts/gs.json","line":64,"url":"https://docs.godspeed.systems/docs/faq#167-how-can-apps-be-decoupled-or-loosely-coupled-with-dbs","title":"COMMON FAQs  16.7 How can apps be decoupled or loosely coupled with DBs? ​"}},{"pageContent":"Prisma provides a standardized and widely used migration process, which can be used out of the box.","metadata":{"source":"scripts/gs.json","line":65,"url":"https://docs.godspeed.systems/docs/faq#168-when-using-godspeed-service-alongside-springboot-what-will-be-the-impact-on-performance-with-another-hop-versus-direct-connection-with-db-from-spring-boot","title":"COMMON FAQs  16.8 When using Godspeed service alongside SpringBoot, what will be the impact on performance with another hop, versus direct connection with DB from Spring Boot? ​"}},{"pageContent":"Kubernetes Cluster LINK-> ​ #kubernetes-cluster <-LINK     ArgoCD, Argo events and argo workflow installed on kubernetes cluster LINK-> ​ #argocd-argo-events-and-argo-workflow-installed-on-kubernetes-cluster <-LINK     Git repo with CI and application manifests LINK-> ​ #git-repo-with-ci-and-application-manifests <-LINK     Spring boot application already containerized LINK-> ​ #spring-boot-application-already-containerized <-LINK     Docker registry LINK-> ​ #docker-registry <-LINK","metadata":{"source":"scripts/gs.json","line":66,"url":"https://docs.godspeed.systems/docs/faq#169-what-is-the-strategic-advantage-of-making-db-queries-through-godspeed","title":"COMMON FAQs  16.9 What is the strategic advantage of making DB queries through Godspeed? ​"}},{"pageContent":"Cloning the git repo LINK-> ​ #cloning-the-git-repo <-LINK      CODE ```   $ https://github.com/Mindgreppers/demo-k8s-manifests.git   ``` CODE","metadata":{"source":"scripts/gs.json","line":67,"url":"https://docs.godspeed.systems/docs/faq#1610-how-to-achieve-multi-tenancy-in-dbs-for-a-single-application","title":"COMMON FAQs  16.10 How to achieve multi-tenancy in DBs, for a single application? ​"}},{"pageContent":"Create event source with ingress for the webhook and git secret token LINK-> ​ #create-event-source-with-ingress-for-the-webhook-and-git-secret-token <-LINK      CODE ```   $ cd demo-k8s-manifests/CI-manifests/    $ kubectl create secret generic git-credentials  \\      --from-literal=GIT_TOKEN=TOKEN    $ kubectl create -f spring-webhook.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":68,"url":"https://docs.godspeed.systems/docs/faq#1611-how-can-we-start-adopting-the-godspeed-framework","title":"COMMON FAQs  16.11 How can we start adopting the Godspeed framework? ​"}},{"pageContent":"Create workflow template containing CI steps LINK-> ​ #create-workflow-template-containing-ci-steps <-LINK      CODE ```   $ kubectl create -f CI-workflow-templates.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":69,"url":"https://docs.godspeed.systems/docs/faq#1612-how-to-move-out-of-the-godspeed-framework-can-we-have-a-two-door-exit-ie-can-we-move-out-of-technology-and-data-both","title":"COMMON FAQs  16.12 How to move out of the Godspeed framework? Can we have a two door exit? I.e. Can we move out of technology and data both? ​"}},{"pageContent":"Create CI/CD for the master branch LINK-> ​ #create-cicd-for-the-master-branch <-LINK      CODE ```   $ kubectl create -f spring-master-CI.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":70,"url":"https://docs.godspeed.systems/docs/faq#1613-how-will-we-prevent-unified-crud-api-from-limiting-or-choking-us","title":"COMMON FAQs  16.13 How will we prevent unified CRUD API from limiting or choking us? ​"}},{"pageContent":"Create CI/CD for the non master branch LINK-> ​ #create-cicd-for-the-non-master-branch <-LINK      CODE ```   $ kubectl create -f spring-non-master-CI.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":71,"url":"https://docs.godspeed.systems/docs/faq#1614-what-kind-of-api-standards-does-the-framework-support","title":"COMMON FAQs  16.14 What kind of API standards does the framework support? ​"}},{"pageContent":"Configure the Argo application to sync the git repo folder with kubernetes LINK-> ​ #configure-the-argo-application-to-sync-the-git-repo-folder-with-kubernetes <-LINK      CODE ```   $ argocd app create spring-app --repo https://github.com/Mindgreppers/demo-k8s-manifests.git --path spring-app --dest-namespace demo --dest-server https://kubernetes.default.svc --directory-recurse --sync-policy auto   ``` CODE","metadata":{"source":"scripts/gs.json","line":72,"url":"https://docs.godspeed.systems/docs/faq#1615-why-rest-first-approach--why-not-graphql-first-approach","title":"COMMON FAQs  16.15 Why Rest first approach ? Why not Graphql first approach? ​"}},{"pageContent":"Add the webhook address in the spring boot git repo under webhooks LINK-> ​ #add-the-webhook-address-in-the-spring-boot-git-repo-under-webhooks <-LINK   every push will have a CI trigger the application build. The deployment is done for the master branch only. LINK-> ​ #every-push-will-have-a-ci-trigger-the-application-build-the-deployment-is-done-for-the-master-branch-only <-LINK","metadata":{"source":"scripts/gs.json","line":73,"url":"https://docs.godspeed.systems/docs/faq#1616-how-are-we-doing-testing-given-there-is-quite-a-bit-of-custom-dsl-in-the-framework-how-do-we-ensure-the-correctness","title":"COMMON FAQs  16.16 How are we doing testing given there is quite a bit of custom DSL in the framework. How do we ensure the correctness? ​"}},{"pageContent":"The developer will need to provide abstracted, templated configurations for all the infra and system-level setup. They should not need to learn any underlying technologies for dev ops or automation. The platform will handle the provisioning, securing, configuring, health, scaling, failover and management of the infra and system, in an automated way. The platform will deploy & manage the lifecycle of the following components and functionalities: hardware spanning multiple cloud providers (or on-premise), operating system, network, tools, libraries, data stores, gateways, microservice mesh, message bus, observability, CI/CD, microservices (domain & functional), pipelines & workflows. Technologies used by default  Crossplane  ArgoCD (delivery)  Linkerd (service mesh)  OpenTelemetry (for standardized tracing and monitoring via Jaeger and Prometheus)  Elasticsearch/Kibana /Fluentd (Log collection, transformation, dashboard, alerts)  Jaeger/Elasticsearch (Tracing)  Prometheus/Grafana or Elasticsearch APM (metrics collection, monitoring & alerts)  Proposed opensource framework for Auth - ORY Kratos or Keycloak (IAM), ORY OATHKEEPER (For gateway authorization)","metadata":{"source":"scripts/gs.json","line":74,"url":"https://docs.godspeed.systems/docs/faq#1617-how-will-the-upgrades-and-migrations-be-done-to-the-framework","title":"COMMON FAQs  16.17 How will the upgrades and migrations be done to the framework? ​"}},{"pageContent":"Infrastructure as code ​   We will use declarative YAML configuration for Crossplane. for seamless integration with CI/CD pipelines to have a single source for infra configuration.  Cloud federation & vendor independence ​   The deployment will be done using the Kubernetes cluster with  LINK-> Crossplane https://crossplane.io/ <-LINK  that provides extensive support for cloud providers such as AWS, GCP, Azure and others, along with on-premise. Using this one can not only be vendor-independent but also operate across multiple vendors.  Application portability ​   The API centric control plane is directly used by the application teams to deploy their changes easily, with the least involvement of the devOps team. The configurations & APIs hide infrastructure complexity & reduce learning curve, hence empowering the dev teams to develop, deploy or shift auto-managed applications on the fly.  Gitops and CI/CD based provisioning and configuring ​   All the dev team needs to make a commit to the git repo. The intended changes(as per the diff in the configuration files and code) should get automatically tested & deployed in production, using CI/CD and canary or blue-green deployment approaches. The pull request will need to be accepted by the stakeholders including but not limited to the product manager, engineering head, QA lead. Every commit to git will trigger unit and integration tests whether for infra, microservice or serverless function deployments. In case of test failures, the latest commit should fail to deploy in production. Deployments will not hinder the ongoing service at any time, ensuring high availability. We will use  LINK-> ArgoCD https://argo-cd.readthedocs.io/en/stable/ <-LINK  for the same  Observability stack ​   The stack for observability will be provided out of the box, with certain functionality preset and working without developer intervention.  Logging LINK-> ​ #logging <-LINK   There will be provision for centralized logs stored into Elasticsearch via Fluentd, & visualized via Kibana or Grafana. It is to be used by the microservice framework for fundamental request/response/error logging and by developers for business-level logging.    Monitoring LINK-> ​ #monitoring <-LINK   All the application performance metrics (uptime, CPU, RAM, sync request latency, sync request success/failure) will be automatically stored & monitored centrally via the service mesh. The latency/success/failure metric of the async requests will be stored by the microservice framework. The data will be collected in Prometheus; and the dashboard will be rendered in Grafana.    Tracing LINK-> ​ #tracing <-LINK   Jaeger, along with Elasticsearch backend will be used to collect the trace information for every request. Traces will be collected across both sync and async flows. Every incoming HTTP or async request will carry trace information in its headers. The same will be propagated further through the microservice framework when it makes a sync or async hit to another service. In case of sync hits which shall be routed via the service mesh, the mesh will store the tracing information in the tracing backend. Async hit tracing will be the responsibility of the microservice framework itself, when it will consume an async message. The standard event format being used will carry the tracing headers.    Alerting LINK-> ​ #alerting <-LINK   Grafana can be used to configure alerts based on the monitored metrics.    Authentication ​    LINK-> ORY Kratos https://github.com/ory/kratos <-LINK  will be used to provide authentication and role management service out of the box. But the system is not confined to using ORY Kratos only. The platform users can use any IAM service they wish to use, and it shall be made to work with the remaining system and microservice framework.  Scaffolding ​   A microservice project structure will be auto-generated from the CLI. There will be a scaffolding mechanism through CLI which will generate the project structure for the custom business logic (route, controller, api definition, validation, authorization, data model) of a custom microservice. The framework will also provide a configuration template that can be customized as per the development need.","metadata":{"source":"scripts/gs.json","line":75,"url":"https://docs.godspeed.systems/docs/faq#1618-how-crud-apis-will-support-the-paid-as-well-as-the-non-paid-features-of-databases-such-as-mongodb-for-example-mongodb-free-vs-paid-versions-will-support-different-features","title":"COMMON FAQs  16.18 How CRUD APIs will support the paid as well as the non paid features of databases such as MongoDB. For example: MongoDB free vs paid versions will support different features. ​"}},{"pageContent":"Follwoing dashboards will be available:  Service & function dashboard: ​   All the services will be managed using OpenFAAS which provides an infra agnostic way of deploying services and functions using Docker over Kubernetes.    Data dashboard: ​   It will allow the admins or team to search, view and edit data in the DB of any microservice.    Monitoring dashboard: ​   It will be used to monitor the state of the live production environment. We plan to use Grafana for the same.    Workflows dashboard: ​   Monitor the workflows running or erroring out in the system. For example, ETLs, CI/CD, scheduled jobs, triggered workflows. This will be provided by the tool used underneath.For example, ARGO workflow.    Analytics dashboard: ​   A dashboard to view & download statistics, graphs and reports will be available. Also other dashboards available in open source can be adopted to work with the same data.","metadata":{"source":"scripts/gs.json","line":76,"url":"https://docs.godspeed.systems/docs/faq#1619-how-to-ship-new-models-easily","title":"COMMON FAQs  16.19 How to ship new models easily? ​"}},{"pageContent":"All the services will be managed using OpenFAAS which provides an infra agnostic way of deploying services and functions using Docker over Kubernetes.","metadata":{"source":"scripts/gs.json","line":77,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application","title":"Application deployment procedure  Application deployment procedure"}},{"pageContent":"It will allow the admins or team to search, view and edit data in the DB of any microservice.","metadata":{"source":"scripts/gs.json","line":78,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#prerequisite","title":"Application deployment procedure  Prerequisite ​"}},{"pageContent":"It will be used to monitor the state of the live production environment. We plan to use Grafana for the same.","metadata":{"source":"scripts/gs.json","line":79,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#step-1","title":"Application deployment procedure  Step 1 ​"}},{"pageContent":"Monitor the workflows running or erroring out in the system. For example, ETLs, CI/CD, scheduled jobs, triggered workflows. This will be provided by the tool used underneath.For example, ARGO workflow.","metadata":{"source":"scripts/gs.json","line":80,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#step-2","title":"Application deployment procedure  Step 2 ​"}},{"pageContent":"A dashboard to view & download statistics, graphs and reports will be available. Also other dashboards available in open source can be adopted to work with the same data.","metadata":{"source":"scripts/gs.json","line":81,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#step-3","title":"Application deployment procedure  Step 3 ​"}},{"pageContent":"The following diagram gives an detailed overview of the workflow.IMAGE-> /assets/images/Platform-Architecture-Devops-f29c8128b0791cbee5fb44f65ea7fd39.jpg <-IMAGE","metadata":{"source":"scripts/gs.json","line":82,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#step-4","title":"Application deployment procedure  Step 4 ​"}},{"pageContent":"IMPORTANT NOTE - While Godspeed is providing some standard tools as part of the platform, developers can integrate other tools to cover the same functionality as per the defined API contracts. Because we are using standard protocols like CloudEvents, OpenTelemetry, unified CRUD API, they can integrate any database, cache, message bus, APM/BPM tools, as long as the same API contract is maintained. Most of the tools mentioned below are replaceable as a platform goal. The only exceptions will be tools like Crossplane & Nodejs which are very fundamental to our platform and microservice framework respectively.IMAGE-> /assets/images/es1-0fd1325ea30691340ff78027f632f91d.PNG <-IMAGEAll the dev team needs to do is to make a commit to the git repo and the intended changes as per the diff in the configuration files and code, should get automagically tested & deployed in production, using CI/CD and canary or blue-green deployment approaches.The pull request will need to be accepted by the stakeholders including but not limited to product manager, engineering head, QA lead. Every commit to git will trigger unit and integration tests whether for infra, microservice or serverless function deployments. In case of test failing, the latest commit should fail to deploy in production. Deployments will not hinder the ongoing service at any time, ensuring high availability. We will use  LINK-> ArgoCD https://argo-cd.readthedocs.io/en/stable/ <-LINK  for the same","metadata":{"source":"scripts/gs.json","line":83,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#step-5","title":"Application deployment procedure  Step 5 ​"}},{"pageContent":"LINK-> Crossplane https://crossplane.io/ <-LINK    LINK-> ArgoCD https://argoproj.github.io/cd/ <-LINK  (delivery)   LINK-> Linkerd https://linkerd.io/ <-LINK  (service mesh)   LINK-> OpenTelemetry https://opentelemetry.io/ <-LINK  (for standardized tracing and monitoring via Jaeger and Prometheus)   LINK-> Elasticsearch https://www.elastic.co/ <-LINK / LINK-> Kibana https://www.elastic.co/kibana/ <-LINK  / LINK-> Fluentd https://www.fluentd.org/ <-LINK  (Log collection, transformation, dashboard, alerts)   LINK-> Jaeger https://www.jaegertracing.io/ <-LINK / LINK-> Elasticsearch https://www.elastic.co/ <-LINK  (Tracing)   LINK-> Prometheus https://prometheus.io/ <-LINK / LINK-> Grafana https://grafana.com/ <-LINK  or  LINK-> Elasticsearch APM https://www.elastic.co/observability/application-performance-monitoring <-LINK  (metrics collection, monitoring & alerts)   LINK-> ORY Kratos or Keycloak (IAM) https://stackshare.io/stackups/keycloak-vs-ory-kratos <-LINK ,  LINK-> ORY OATHKEEPER https://www.ory.sh/oathkeeper/#:~:text=Ory%20Oathkeeper%20is%20an%20Open,and%20is%20written%20in%20Go. <-LINK  (For gateway authorization)","metadata":{"source":"scripts/gs.json","line":84,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#step-6","title":"Application deployment procedure  Step 6 ​"}},{"pageContent":"1: Update the apt package index and install packages to allow apt to use a repository over HTTPS: LINK-> ​ #1-update-the-apt-package-index-and-install-packages-to-allow-apt-to-use-a-repository-over-https <-LINK    CODE ```   $ sudo apt-get update    $ sudo apt-get install \\        ca-certificates \\        curl \\        gnupg \\        lsb-release   ``` CODE             2: Add Docker’s official GPG key: LINK-> ​ #2-add-dockers-official-gpg-key <-LINK    CODE ```   $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg   ``` CODE             3: Adding docker apt repository: LINK-> ​ #3-adding-docker-apt-repository <-LINK    CODE ```   $ echo \\      \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\      $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null   ``` CODE             4: Installing docker package using apt: LINK-> ​ #4-installing-docker-package-using-apt <-LINK    CODE ```   $ sudo apt-get update    $ sudo apt-get install docker-ce docker-ce-cli containerd.io -y   ``` CODE             5. Giving permission to user for docker and reboot the system LINK-> ​ #5-giving-permission-to-user-for-docker-and-reboot-the-system <-LINK    CODE ```   $ sudo usermod -aG docker $USER    $ reboot   ``` CODE             6: Verifying docker installation and working: LINK-> ​ #6-verifying-docker-installation-and-working <-LINK    CODE ```   $ sudo docker run hello-world   ``` CODE","metadata":{"source":"scripts/gs.json","line":85,"url":"https://docs.godspeed.systems/docs/infra-and-system/Application#step-7","title":"Application deployment procedure  Step 7 ​"}},{"pageContent":"1: Update the apt package index and install packages to allow apt to use a repository over HTTPS: LINK-> ​ #1-update-the-apt-package-index-and-install-packages-to-allow-apt-to-use-a-repository-over-https-1 <-LINK    CODE ```   $ sudo apt-get update    $ sudo apt-get install \\        ca-certificates \\        curl \\        gnupg \\        lsb-release   ``` CODE             2: Add Docker’s official GPG key: LINK-> ​ #2-add-dockers-official-gpg-key-1 <-LINK    CODE ```   $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg   ``` CODE             3: Adding docker apt repository: LINK-> ​ #3-adding-docker-apt-repository-1 <-LINK    CODE ```   $ echo \\      \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\      $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null   ``` CODE             4: Installing docker package using apt: LINK-> ​ #4-installing-docker-package-using-apt-1 <-LINK    CODE ```   $ sudo apt-get update    $ sudo apt-get install docker-ce docker-ce-cli containerd.io -y   ``` CODE             5. Giving permission to user for docker and reboot the system LINK-> ​ #5-giving-permission-to-user-for-docker-and-reboot-the-system-1 <-LINK    CODE ```   $ sudo usermod -aG docker $USER    $ reboot   ``` CODE             6: Verifying docker installation and working: LINK-> ​ #6-verifying-docker-installation-and-working-1 <-LINK    CODE ```   $ sudo docker run hello-world   ``` CODE","metadata":{"source":"scripts/gs.json","line":86,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro","title":"Introduction  Introduction"}},{"pageContent":"To download docker binary  LINK-> Click here https://docs.docker.com/desktop/windows/install/ <-LINK  LINK-> ​ #to-download-docker-binary-click-here <-LINK","metadata":{"source":"scripts/gs.json","line":87,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#salient-features","title":"Introduction  Salient Features ​"}},{"pageContent":"To download docker binary  LINK-> Click here https://docs.docker.com/desktop/mac/install/ <-LINK  LINK-> ​ #to-download-docker-binary-click-here-1 <-LINK","metadata":{"source":"scripts/gs.json","line":88,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#infrastructure-as-code","title":"Introduction  Infrastructure as code ​"}},{"pageContent":"To download docker binary  LINK-> Click here https://docs.docker.com/compose/install/ <-LINK  LINK-> ​ #to-download-docker-binary-click-here-2 <-LINK","metadata":{"source":"scripts/gs.json","line":89,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#cloud-federation--vendor-independence","title":"Introduction  Cloud federation & vendor independence ​"}},{"pageContent":"example: supports-app   CODE ```   copy docker compose file in directory:-    version: \"3.0\"    services:      zookeeper:        image: confluentinc/cp-zookeeper:7.0.1        environment:          ZOOKEEPER_CLIENT_PORT: 2181          ZOOKEEPER_TICK_TIME: 2000        ports:          - 2181:2181        kafka:        image: confluentinc/cp-kafka:7.0.1        depends_on:          - zookeeper        ports:          - 29092:29092          - 9092:9092        environment:          KAFKA_BROKER_ID: 1          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT          KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1        elasticsearch:        container_name: es01        image: elasticsearch:7.4.2        environment:          - node.name=es01          - discovery.type=single-node          - bootstrap.memory_lock=true          - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"        ulimits:          memlock:            soft: -1            hard: -1        volumes:          - /home/gurjot/elasticsearch/es-data:/usr/share/elasticsearch/data        ports:          - 9200:9200          - 9300:9300        networks:          - elastic        restart: always      networks:      elastic:        driver: bridge   ``` CODE                CODE ```   create a folder under file with name:    es-data   ``` CODE                CODE ```   edit the path of esdata:-     ~/support-apps/es-data.   ``` CODE","metadata":{"source":"scripts/gs.json","line":90,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#application-portability","title":"Introduction  Application portability ​"}},{"pageContent":"The framework provides  LINK-> JWT authentication https://jwt.io/introduction <-LINK  for securely transmitting information among microservices.\nThe user agent should send the JWT in the Authorization header using the Bearer schema. The content of the header should look like the following:   CODE ```   Authorization: Bearer <token>   ``` CODE","metadata":{"source":"scripts/gs.json","line":91,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#gitops-and-cicd-based-provisioning-and-configuring","title":"Introduction  Gitops and CI/CD based provisioning and configuring ​"}},{"pageContent":"You can do JWT configuration in  LINK-> Configuration/Environment variables /docs/microservices/setup/configuration/env-vars/#custom-environment-variablesyaml <-LINK . For example, this is the sample configuration:   CODE ```   jwt:      iss: JWT_ISS #issuer      aud: JWT_AUD #audience      secretOrKey: JWT_SECRET   ``` CODE             You need to export these environment variables in your environment.12.1.1.1 Access JWT payload in Workflow DSL LINK-> ​ #12111-access-jwt-payload-in-workflow-dsl <-LINK You can access the complete JWT payload in  CODE ``` <% inputs.user %> ``` CODE  in workflow DSL as given below:   CODE ```   summary  :   Call an API and transform the     tasks  :          -     id  :   httpbin_step1            description  :   Hit http bin with some dummy data. It will send back same as response            fn  :   com.gs.http            args  :              datasource  :   httpbin              data  :   <% inputs.body %  >                jwt_payload  :   <% inputs.user %  >              config  :                url     :   /anything                method  :   post   ``` CODE","metadata":{"source":"scripts/gs.json","line":92,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#observability-stack","title":"Introduction  Observability stack ​"}},{"pageContent":"Add  CODE ``` authn: true ``` CODE  in the event DSL to enable authentication for any event.   CODE ```   /v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post:       authn: true      fn: com.biz.kyc.ckyc.ckyc_initiate      on_validation_error: com.jfs.handle_validation_error      data:        schema:          body:             required: true            content:              application/json:                schema:                  type: 'object'                  required: []                  properties:                    dob:  { type : 'string', format : 'date', pattern : \"[0-9]{4}-[0-9]{2}-[0-9]{2}\" }                    meta:                      type: 'object'          params:           - name: lender_loan_application_id            in: params            required: true            allow_empty_value: false            schema:              type: string      responses: #Output data defined as per the OpenAPI spec        200:          schema:            data:               required: # default value is false              content:                application/json:                  schema:                     type: object                    properties:                      application_id:                         type: string                    additionalProperties: false                    required: [application_id]   ``` CODE","metadata":{"source":"scripts/gs.json","line":93,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#authentication","title":"Introduction  Authentication ​"}},{"pageContent":"Generally, you will get JWT from your authentication service. For testing purposes, you can generate JWT at  LINK-> https://jwt.io/ https://jwt.io/ <-LINK  by providing the  CODE ``` iss ``` CODE ,  CODE ``` aud ``` CODE  and  CODE ``` secretOrKey ``` CODE  to verify signature. Use the encoded token as JWT authentication token. For example,\nIMAGE-> /assets/images/JWT-854a46e631d594366cb326b2bcc7e9e0.png <-IMAGEIn the above case, the Authorization header should look like:   CODE ```   Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtcy5zYW1wbGUuY29tIiwiYXVkIjoic2FtcGxlLmNvbSJ9._1fpM6VYq1rfKdTEqi8BcPTm8KIm4cNP8VhX0kQOEts   ``` CODE","metadata":{"source":"scripts/gs.json","line":94,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#scaffolding","title":"Introduction  Scaffolding ​"}},{"pageContent":"You can add authentication at datasource level on  LINK-> API datasource /docs/microservices/datasources/api <-LINK . You can define an authn workflow at datasource level which requests to any authentication service for token/authentication then this workflow can return headers, params or statusCodes to the main workflow. Here is the sample spec:\n Datasource    CODE ```   type  :   api    base_url  :   <% config.httpbin.base_url %  >    authn  :   com.jfs.httpbin_auth   ``` CODE             Here,  CODE ``` com.jfs.httpbin_auth ``` CODE  is the authentication workflow which gets called for the authentication of any request to this datasource. Sample workflow using the above datasource    CODE ```   summary  :   Call an API and transform the     tasks  :          -     id  :   httpbin_step1   # the response of this will be accessible within the parent step key, under the step1 sub key            description  :   Hit http bin with some dummy data. It will send back same as response            fn  :   com.gs.http            args  :              datasource  :   httpbin              data  :   <% inputs.body %  >              config  :                url     :   /anything                method  :   post     ``` CODE              Sample authentication workflow  CODE ``` com.jfs.httpbin_auth ``` CODE     CODE ```   summary  :   Auth workflow    tasks  :          -     id  :   auth_step1            description  :   Hit the authn request            fn  :   com.gs.http            args  :              datasource  :   authapi              data  :   <% inputs.query.username %  >              config  :                   url  :   /authenticate                method  :   post          -     id  :   auth_step2            description  :   Transform the response received from authn api            fn  :   com.gs.transform            args  :              headers  :                Authorization  :   <% 'Bearer ' + outputs.auth_step1.auth.token %  >              params  :                queryid  :   <% outputs.auth_step1.params.queryid %  >              statusCodes  :   <% outputs.auth_step1.status_code %  >               ``` CODE             The authentication workflow should return response in this format:   CODE ```   headers  :           header1  :   val1    params  :        param1  :   val1    statusCodes  :     [  401  ,     403  ,     ...  .  ]   ``` CODE                  note   The authentication workflow gets called when any request returns the specified  CODE ``` statusCodes ``` CODE .","metadata":{"source":"scripts/gs.json","line":95,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#dashboards-available","title":"Introduction  Dashboards available ​"}},{"pageContent":"The framework provides authorization, to verify if any event/model is authorized to access specific information or is allowed to execute certain actions.","metadata":{"source":"scripts/gs.json","line":96,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#service--function-dashboard","title":"Introduction  Service & function dashboard: ​"}},{"pageContent":"You can add authorization workflow at the task level in any workflow. The authorization workflow should return allow/deny or json output to the main worklfow.  Allow/Deny  \nIf authz workflow returns data as true/false, it means the task is allowed/denied to get executed.  JSON output  \nIf authz workflow returns JSON output then it is merged with args.data of the task for which authz is being executed.Here is the sample spec:\n Sample workflow calling the authz workflow    CODE ```   summary  :   Call an API    tasks  :          -     id  :   httpbin_step1            description  :   Hit http bin with some dummy data. It will send back same as response            authz  :              fn  :   com.jfs.authz              args  :   <% inputs %  >            fn  :   com.gs.http            args  :              datasource  :   httpbin              data  :   <% inputs %  >              config  :                url     :   /anything                method  :   post   ``` CODE              Sample authorization workflow  CODE ``` com.jfs.authz ``` CODE     CODE ```   summary  :   Authorization workflow    tasks  :        -     id  :   authz_step1          description  :   return allow/deny based upon user          fn  :   com.gs.http          args  :               datasource  :   authz            data  :   <% inputs.body.user %  >            config  :              url     :   /authorize              method  :   post        -     id  :   authz_step2          description  :   transform response from authz api          fn  :   com.gs.transform          args  :     |            <coffee% if outputs.authz_step1.data.code == 200 then {                success: true                data: true            } else if outputs.authz_step1.data.code == 201 then {                success: true                data:                  where:                    role: 'USER'            } else {                success: false                data: false            } %>   ``` CODE             The authorization workflow should return response in this format to allow/deny:   CODE ```   success  :   true/false    data  :   true/false/JSON output   ``` CODE              When data is returned as false i.e. deny then the framework will send  CODE ``` 403 Unauthorized ``` CODE  response.","metadata":{"source":"scripts/gs.json","line":97,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#data-dashboard","title":"Introduction  Data dashboard: ​"}},{"pageContent":"In DB query call, authz workflow can return JSON output with where clause, include clause etc. which will be merged with the args of the main workflow which is doing DB query.Here is the sample spec:\n Sample workflow calling the authz workflow    CODE ```   summary  :   datastore demo    tasks  :        -     id  :   find_user          description  :   find users          authz  :            fn  :   com.jfs.auth            args  :   <% inputs %  >          fn  :   com.gs.datastore          args  :            datasource  :   mongo            data  :              include  :   <% inputs.body.include %  >              where  :   <% inputs.body.where %  >            config  :              method  :   user.findMany   ``` CODE              Sample authorization workflow  CODE ``` com.jfs.authz ``` CODE     CODE ```   summary  :   Authorization workflow    tasks  :        -     id  :   authz_step1          description  :   return allow/deny based upon user          fn  :   com.gs.http          args  :               datasource  :   authz            data  :   <% inputs.body.user %  >            config  :              url     :   /authorize              method  :   post        -     id  :   authz_step2          description  :   transform response from authz api          fn  :   com.gs.transform          args  :     |            <coffee% if outputs.authz_step1.data.code == 200 then {                success: true                data:                  where:                    role: 'USER'            } else {                success: false                data: false            } %>   ``` CODE             When authorization workflow  CODE ``` com.jfs.authz ``` CODE  returns  CODE ``` success: true ``` CODE  then its  CODE ``` data ``` CODE  will be merged with the main workflow which is calling the authz workflow.\nFor example, in the above authz workflow,  CODE ``` data ``` CODE  is returned as:   CODE ```   data  :        where  :          role  :     'USER'   ``` CODE             This data will be merged with the args.data of the main workflow i.e.   CODE ```   args  :        data  :          include  :   <% inputs.body.include %  >          where  :   <% inputs.body.where %  >     # where clause from authz workflow will be merged with this   ``` CODE","metadata":{"source":"scripts/gs.json","line":98,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#monitoring-dashboard","title":"Introduction  Monitoring dashboard: ​"}},{"pageContent":"Godspeed provides caching of the tasks using redis as cache. You can cache the result of any task in the workflows.","metadata":{"source":"scripts/gs.json","line":99,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#workflows-dashboard","title":"Introduction  Workflows dashboard: ​"}},{"pageContent":"Define a datasource with type 'redis' in  LINK->  CODE ``` src/datasources ``` CODE  /docs/microservices/datasources/redis/#881-example-spec <-LINK . Here, redis datasource is defined in  CODE ``` src/datasources/redis.yaml ``` CODE    CODE ```   type  :   redis    url  :   redis  [  s  ]  :  //  [  [  username  ]  [  :  password  ]  @  ]  [  host  ]  [  :  port  ]  [  /db  -  number  ]   ``` CODE","metadata":{"source":"scripts/gs.json","line":100,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#analytics-dashboard","title":"Introduction  Analytics dashboard: ​"}},{"pageContent":"Define default caching datasource in  LINK-> static configuration /docs/microservices/setup/configuration/static-vars/#static-variables <-LINK    CODE ```   log_level  :   debug    lang  :   coffee    server_url  :   https  :  //api.example.com  :  8443/v1/api    caching  :   redis   ``` CODE","metadata":{"source":"scripts/gs.json","line":101,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#developer-workflow-in-action","title":"Introduction Dashboards available ​  Developer workflow in action ​"}},{"pageContent":"Here is the caching spec to write in the workflow.   CODE ```   caching  :          key  :   <key name which is used to cache result in redis  >          invalidate  :   <used to invalidate the cache of some other task. Key name which we want to delete/remove from cache e.g. this field can be used in CRUD types task. While delete operation  ,   invalidate the cache of read or update task  >          cache_on_failure  :   <true  |  false  ,   whether you want to cache the failure result or not. By default  ,   it is false  >          expires  :   <timer in seconds  ,   until the cached result is valid  >          force  :   <true  |  false  ,   force flag to specify not to use cache  ,   always trigger task's function. Set it to true if you don't want to use cache  >   ``` CODE              Example Spec    CODE ```   summary  :   workflow to cache task results    id  :   cache_wf    tasks  :        -     id  :   cache_step1          caching  :            key  :   cache_step1            invalidate  :   cache_step2            cache_on_failure     :     false            expires  :     60            force  :     false          fn  :   com.gs.http          args  :              datasource  :   httpbin              data  :                name  :     'hello'              config  :                url     :   /anything                method  :   post        -     id  :   cache_step2          caching  :            key  :   cache_step2            cache_on_failure     :     false            expires  :     60            force  :     false          fn  :   com.gs.http          args  :              datasource  :   httpbin              data  :                name  :     'cache'              config  :                url     :   /anything                method  :   post   ``` CODE              When the workflow is triggered for the first time, then the result of the two tasks are cached in DB with keys  CODE ``` cache_step1 ``` CODE  and  CODE ``` cache_step2 ``` CODE  for 60 seconds.  If the next call to this workflow occurs within 60 seconds then the cached results will be used, else API call will be triggered.  In the  CODE ``` cache_step1 ``` CODE , invaldiate spec is defined, which is invalidating/deleting the cached result of the  CODE ``` cache_step2 ``` CODE . It means even if  CODE ``` cache_step2 ``` CODE  is cached, if any calls occurs within 60 seconds then the  CODE ``` cache_step1 ``` CODE  will delete the cached result of  CODE ``` cache_step2 ``` CODE . So, no cache will be used for  CODE ``` cache_step2 ``` CODE .","metadata":{"source":"scripts/gs.json","line":102,"url":"https://docs.godspeed.systems/docs/infra-and-system/intro#a-sample-setup","title":"Introduction  A SAMPLE SETUP ​"}},{"pageContent":"Step 1: Create an index.js/index.ts file in  CODE ``` src/middlewares ``` CODE  dierctory in your project.     Project structure    CODE ```   .    ├── config    └── src        └── middlewares            └── index.ts   ``` CODE              Step 2: index.ts/index.js should be exporting array of middleware functions with signature (req, res, next)     index.ts    CODE ```   import     {   uuid   }     from     'uuidv4'  ;      function     addUuid  (  req  :     any  ,   res  :     any  ,   next  :     any  )     {          // Set data        req  .  body  .  uuid   =     uuid  (  )  ;                  // Go to next middleware          next  (  )  ;    }      function     addTitle  (  req  :     any  ,   res  :     any  ,   next  :     any  )     {          // Set data        req  .  body  .  title   =     \"Title from middleware/ts\"  ;                  // Go to next middleware          next  (  )  ;    }      export     default     [  addUuid  ,   addTitle  ]  ;   ``` CODE                  caution   If the current middleware function does not end the request-response cycle, it must call next() to pass control to the next middleware function. Otherwise, the request will be left hanging.    Sample req object  \nHere, two properties  CODE ``` uuid ``` CODE  and  CODE ``` title ``` CODE  are added in the body of req object.   CODE ```   {        \"_events\"  :     {  }  ,        \"_eventsCount\"  :     1  ,        \"httpVersionMajor\"  :     1  ,        \"httpVersionMinor\"  :     1  ,        \"httpVersion\"  :     \"1.1\"  ,        \"complete\"  :     true  ,        \"rawHeaders\"  :     [          \"Content-Type\"  ,          \"application/json\"  ,          \"User-Agent\"  ,          \"PostmanRuntime/7.29.2\"  ,          \"Accept\"  ,          \"*/*\"  ,          \"Cache-Control\"  ,          \"no-cache\"  ,          \"Postman-Token\"  ,          \"7ce46b80-61e1-44c4-b91a-8a3c914797e8\"  ,          \"Host\"  ,          \"localhost:4901\"  ,          \"Accept-Encoding\"  ,          \"gzip, deflate, br\"  ,          \"Connection\"  ,          \"keep-alive\"  ,          \"Content-Length\"  ,          \"2\"        ]  ,        \"rawTrailers\"  :     [  ]  ,        \"aborted\"  :     false  ,        \"upgrade\"  :     false  ,        \"url\"  :     \"/test3\"  ,        \"method\"  :     \"POST\"  ,        \"statusCode\"  :     null  ,        \"statusMessage\"  :     null  ,        \"_consuming\"  :     true  ,        \"_dumped\"  :     false  ,        \"baseUrl\"  :     \"\"  ,        \"originalUrl\"  :     \"/test3\"  ,        \"params\"  :     {  }  ,        \"query\"  :     {  }  ,        \"body\"  :     {          \"uuid\"  :     \"cfc5fc7f-cfdf-4fe7-99ad-08993f90f570\"  ,          \"title\"  :     \"Title from middleware/ts\"        }  ,        \"_body\"  :     true  ,        \"id\"  :     2  ,        \"log\"  :     {  }  ,        \"route\"  :     {          \"path\"  :     \"/test3\"  ,          \"stack\"  :     [            {              \"name\"  :     \"<anonymous>\"  ,              \"keys\"  :     [  ]  ,              \"regexp\"  :     {                \"fast_star\"  :     false  ,                \"fast_slash\"  :     false              }  ,              \"method\"  :     \"post\"            }  ,            {              \"name\"  :     \"<anonymous>\"  ,              \"keys\"  :     [  ]  ,              \"regexp\"  :     {                \"fast_star\"  :     false  ,                \"fast_slash\"  :     false              }  ,              \"method\"  :     \"post\"            }          ]  ,          \"methods\"  :     {            \"post\"  :     true          }        }  ,        \"protocol\"  :     \"http\"  ,        \"secure\"  :     false  ,        \"ip\"  :     \"::ffff:192.168.224.1\"  ,        \"ips\"  :     [  ]  ,        \"subdomains\"  :     [  ]  ,        \"path\"  :     \"/test3\"  ,        \"hostname\"  :     \"localhost\"  ,        \"host\"  :     \"localhost\"  ,        \"fresh\"  :     false  ,        \"stale\"  :     true  ,        \"xhr\"  :     false  ,        \"files\"  :     [  ]    }   ``` CODE","metadata":{"source":"scripts/gs.json","line":103,"url":"https://docs.godspeed.systems/docs/infra-and-system/technology-used/intro","title":"Technologies used (Default)  Technologies used (Default)"}},{"pageContent":"The API datasource acts as a wrapper around third party APIs. It helps interact with third party APIs or own microservices. It takes OpenAPI schema as its setting, and the datasource can be used in  CODE ``` com.gs.http ``` CODE  calls out of the box. Following functionality is provided by the framework based on the schema of the datasource Authentication and authorization as per the spec  Validation of the input to the http method (must be compliant to the API spec)  Validation of the response from the API (must be compliant to the API spec)","metadata":{"source":"scripts/gs.json","line":104,"url":"https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker","title":"Local Dev SetupInstall docker composecreating folder under home directory:-  Local Dev Setup"}},{"pageContent":"If the OpenAPI spec of the API to consume/connect with is available at a URL, then one can simply refer the url here itself.   CODE ```   idfc  :        schema  :   https  :  //raw.githubusercontent.com/Kong/swagger  -  ui  -  kong  -  theme/main/demo/public/specs/httpbin.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":105,"url":"https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#local-debian-setup","title":"Local Dev SetupInstall docker composecreating folder under home directory:-  Local Debian Setup ​"}},{"pageContent":"If there is no OpenAPI spec available for an API, then developer needs to provide details of the API schema in the .yaml file for that datasource.   CODE ```   type  :   api    schema  :    base_url  :   <% config.httpbin.base_url %  >    security  :        -     ApiKey  :   sample  -  app        -     ApiToken  :   <% config.httpbin.api_token %  >      securitySchemes  :        ApiKey  :          type  :   apiKey          in  :   header          name  :   x  -  api  -  key          ApiToken  :          type  :   apiKey          in  :   header          name  :   Authorization   ``` CODE","metadata":{"source":"scripts/gs.json","line":106,"url":"https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#docker-install-on-ubuntu","title":"Local Dev SetupInstall docker composecreating folder under home directory:-  Docker install on Ubuntu ​"}},{"pageContent":"Headers defined at datasource level are applicable for all the workflows, which are using this datasource. For example, in below datasource, headers 'name' and 'title' are sent in each workflow which is using this datasource.   CODE ```   type: api    base_url: <% config.httpbin.base_url %>      headers:      name: godspeed      title: <% inputs.headers['title'] %>   ``` CODE","metadata":{"source":"scripts/gs.json","line":107,"url":"https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#install-docker-on-windows","title":"Local Dev SetupInstall docker composecreating folder under home directory:-  Install docker on windows ​"}},{"pageContent":"Headers defined at task level are applicable for a single task only. You can find the  LINK-> example usage here /docs/microservices/workflows#62-the-tasks-within-workflows <-LINK","metadata":{"source":"scripts/gs.json","line":108,"url":"https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker#install-docker-on-mac","title":"Local Dev SetupInstall docker composecreating folder under home directory:-  Install docker on Mac ​"}},{"pageContent":"You can find the  LINK-> example usage here /docs/microservices/workflows#661-comgshttp <-LINK","metadata":{"source":"scripts/gs.json","line":109,"url":"https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker","title":"Local Dev SetupInstall docker composecreating folder under home directory:-  Install docker compose"}},{"pageContent":"The framework supports AWS as a datasource. It helps in interacting with AWS, to use various AWS services and methods.","metadata":{"source":"scripts/gs.json","line":110,"url":"https://docs.godspeed.systems/docs/local-development-setup/install%20the%20docker","title":"Local Dev SetupInstall docker composecreating folder under home directory:-  creating folder under home directory:-"}},{"pageContent":"The datasources for AWS are defined in  CODE ``` src/datasources ``` CODE . Here, AWS datasource is defined in  CODE ``` aws_s3.yaml ``` CODE .   CODE ```   .    ├── config    └── src        ├── datasources        │   └── httpbin.yaml        │   ├── aws_s3.yaml        ├── events        ├── functions        └── mappings   ``` CODE             Sample configuration in  CODE ``` aws_s3.yaml ``` CODE    CODE ```   type: aws    common:        credentials:            accessKeyId: 'AKIA4KQJJFGY2KPNNOEMmnbv'            secretAccessKey: '+pf5xyyPSUfBNn0V9ZIH0oPVzARBvxoehR+mpzigcdfg'        region: \"ap-south-1\"    services:        S3:            config: {}   ``` CODE","metadata":{"source":"scripts/gs.json","line":111,"url":"https://docs.godspeed.systems/docs/microservices/authen-author","title":"Authentication & Authorization  Authentication & Authorization"}},{"pageContent":"LINK-> Refer here /docs/microservices/workflows/#6614-comgsaws <-LINK  for com.gs.aws workflow.","metadata":{"source":"scripts/gs.json","line":112,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#121-authentication","title":"Authentication & Authorization  12.1 Authentication ​"}},{"pageContent":"The framework takes the approach of schema driven development.\nIt supports multiple kinds of SQL and NoSQL datastores. The developer only needs to specify or generate the schema for a datastore, with authorization policies. The CRUD events and workflows are automatically generated from the schema itself. Shall the developer need to use these within other workflows, they can do that as well. Currently supported datastores   Postgres (via Prisma)  Mysql (via Prisma)  Mongodb (via Prisma)  Elasticsearch (via Elasticgraph, our inhouse implementation providing bunch of exciting features over Elasticsearch, including relationship management and joins.)  The integration supports  Model declaration (For both relational and non-relational stores)  Schema generation from existing database  Universal, autogenerated CRUD API.  Validation of the CRUD requests  Authorization mechanism at the entity, column, row and ownership levels  Automatic caching based on configuration.","metadata":{"source":"scripts/gs.json","line":113,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#1211-jwt-configuration","title":"Authentication & Authorization 12.1 Authentication ​  12.1.1 JWT Configuration ​"}},{"pageContent":"The framework extends  LINK-> Prisma specification http://prisma.io <-LINK  for specifying the schema of any datastore. This can be generated from an  LINK-> existing database #732-cli-commands <-LINK  or manually created by the developer. The schema is present as  CODE ``` {datastore_name}.prisma ``` CODE  file in the  CODE ``` src/datasources ``` CODE  folder.IMAGE-> /assets/images/datastore-datasource-1242f9252ce937e404956c7bc1117afb.jpeg <-IMAGE  Sample Schema     CODE ```   generator client {      provider = \"prisma-client-js\"      output   = \"./generated-clients/mongo\"      previewFeatures = [\"metrics\"]    }      datasource db {      provider = \"mongodb\"      url      = env(\"MONGO_TEST_URL\")    }      model User1 {      id        String      @id @default(auto()) @map(\"_id\") @db.ObjectId      createdAt DateTime @default(now())      email     String   @unique      name      String?    }   ``` CODE","metadata":{"source":"scripts/gs.json","line":114,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#1212-event-spec","title":"Authentication & Authorization 12.1 Authentication ​  12.1.2 Event spec ​"}},{"pageContent":"Any  LINK-> Prisma CLI command https://www.prisma.io/docs/concepts/components/prisma-cli <-LINK  can be executed from godspeed CLI using  CODE ``` godspeed prisma <command> ``` CODE . For example,   CODE ```   $ godspeed prisma db pull --schema=./src/datasources/mongo_pull.prisma                           _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Prisma schema loaded from src/datasources/mongo_pull.prisma    Environment variables loaded from .env    Datasource \"db\"      ✔ Introspected 6 models and wrote them into src/datasources/mongo_pull.prisma in 81ms              *** WARNING ***      Could not determine the types for the following fields.    - Model \"Post\", field: \"slug\"    - Model \"Profile\", field: \"userId\"    - Model \"User\", field: \"email\"      Run prisma generate to generate Prisma Client.   ``` CODE                  note   Please make sure that  CODE ``` godspeed prisma <command> ``` CODE  is executed inside from devcontainer/project root directory.","metadata":{"source":"scripts/gs.json","line":115,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#1213-generate-jwt","title":"Authentication & Authorization 12.1 Authentication ​  12.1.3 Generate JWT ​"}},{"pageContent":"The framework has  LINK-> inbuilt feature /docs/microservices/setup/auto-watch/#auto-watch-and-build <-LINK  of setting up datastore automatically whenever a new  CODE ``` {datastore_name}.prisma ``` CODE  file is created in the  CODE ``` src/datasources ``` CODE  folder. In case, you are getting any error in the datastore setup, then you can refer to below section for manual setup:  During the project setup, if you have not specified the type of datastore you just added, then you will have to execute  CODE ``` godspeed update ``` CODE  in project root directory, outside the dev container. This will deploy the container for this datastore in the dev container environment.","metadata":{"source":"scripts/gs.json","line":116,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#1214-datasource-authentication","title":"Authentication & Authorization 12.1 Authentication ​  12.1.4 Datasource authentication ​"}},{"pageContent":"Prisma model setup is done using prisma generate and db push commands.Step 1: godspeed prisma generate LINK-> ​ #step-1-godspeed-prisma-generate <-LINK    CODE ```   $ godspeed prisma generate --schema=./src/datasources/mongo2.prisma                           _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Environment variables loaded from .env    Prisma schema loaded from src/datasources/mongo2.prisma      ✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo2 in 111ms    You can now start using Prisma Client in your code. Reference: https://pris.ly/d/client      import { PrismaClient } from './src/datasources/generated-clients/mongo2'    const prisma = new PrismaClient()   ``` CODE             Step 2: godspeed prisma db push LINK-> ​ #step-2-godspeed-prisma-db-push <-LINK    CODE ```   $ godspeed prisma db push --schema=./src/datasources/mongo.prisma                           _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Environment variables loaded from .env    Prisma schema loaded from src/datasources/mongo.prisma    Datasource \"db\"      The database is already in sync with the Prisma schema.      ✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo in 149ms   ``` CODE","metadata":{"source":"scripts/gs.json","line":117,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#122-authorization","title":"Authentication & Authorization  12.2 Authorization ​"}},{"pageContent":"Developer can generate CRUD APIs for all the models in a datastore.  CODE ``` Events ``` CODE  and  CODE ``` Workflows ``` CODE  will be auto generated for  CODE ``` Create ``` CODE ,  CODE ``` Read ``` CODE ,  CODE ``` Update ``` CODE  and  CODE ``` Delete ``` CODE  operations for each model in respective datastore. Auto-generated events and workflows will be stored in  CODE ``` /events/{datasourceName}/{modelName} ``` CODE  and  CODE ``` /functions/com/gs/{datasourceName}/{modelName} ``` CODE  folders respectively.   CODE ```   godspeed gen-crud-api   ``` CODE","metadata":{"source":"scripts/gs.json","line":118,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#1221-workflow-dsl","title":"Authentication & Authorization 12.2 Authorization ​  12.2.1 Workflow DSL ​"}},{"pageContent":"Please find an  LINK-> example here /docs/microservices/workflows#763-comgsdatastore <-LINK","metadata":{"source":"scripts/gs.json","line":119,"url":"https://docs.godspeed.systems/docs/microservices/authen-author#1222-sample-db-query-call-authorization","title":"Authentication & Authorization 12.2 Authorization ​  12.2.2 Sample DB query call authorization ​"}},{"pageContent":"You can apply encryption on  CODE ``` String ``` CODE  type fields in Prisma. Be default, the encryption algorithm used is AES-GCM with 256 bit keys.","metadata":{"source":"scripts/gs.json","line":120,"url":"https://docs.godspeed.systems/docs/microservices/caching","title":"Caching  Caching"}},{"pageContent":"In your prisma schema, add  CODE ``` /// @encrypted ``` CODE  to the fields you want to encrypts.\nFor example,  CODE ``` email ``` CODE  field in below schema:   CODE ```   generator client {      provider = \"prisma-client-js\"      output   = \"./generated-clients/mongo\"      previewFeatures = [\"metrics\"]    }      datasource db {      provider = \"mongodb\"      url      = env(\"MONGO_TEST_URL\")    }      model User1 {      id        String      @id @default(auto()) @map(\"_id\") @db.ObjectId      createdAt DateTime @default(now())      email     String   @unique /// @encrypted      name      String?    }   ``` CODE","metadata":{"source":"scripts/gs.json","line":121,"url":"https://docs.godspeed.systems/docs/microservices/caching#91-specifications","title":"Caching  9.1 Specifications ​"}},{"pageContent":"You can specify  CODE ``` prisma_secret ``` CODE  in  LINK-> environment configuration /docs/microservices/setup/configuration/env-vars/#custom-environment-variablesyaml <-LINK \nFor example, this is the sample configuration, set  CODE ``` PRISMA_SECRET ``` CODE  as env variable:   CODE ```   prisma_secret  :   PRISMA_SECRET   # secret used to generate hash of prisma fields   ``` CODE","metadata":{"source":"scripts/gs.json","line":122,"url":"https://docs.godspeed.systems/docs/microservices/caching#911-datasource-spec-for-redis","title":"Caching 9.1 Specifications ​  9.1.1 Datasource spec for redis ​"}},{"pageContent":"The framework supports elasticgraph as a datasource. It supports elasticsearch as datastore. In addition, you can use various features of elasticgraph like deep graph search algorithms, joins, aggregations, multi-lingual support.","metadata":{"source":"scripts/gs.json","line":123,"url":"https://docs.godspeed.systems/docs/microservices/caching#912-configuration","title":"Caching 9.1 Specifications ​  9.1.2 Configuration ​"}},{"pageContent":"The datasources for elasticgraph are defined in  CODE ``` src/datasources ``` CODE . Here,  CODE ``` elasticgraph1.yaml ``` CODE  and  CODE ``` elasticgraph2.yaml ``` CODE  are defined in datasources.   CODE ```   .    ├── config    └── src        ├── datasources        │   └── httpbin.yaml        │   ├── elasticgraph1.yaml        │   ├── elasticgraph2.yaml        ├── events        ├── functions        └── mappings   ``` CODE","metadata":{"source":"scripts/gs.json","line":124,"url":"https://docs.godspeed.systems/docs/microservices/caching#913-workflow-spec","title":"Caching 9.1 Specifications ​  9.1.3 Workflow spec ​"}},{"pageContent":"elasticgraph1.yaml    CODE ```   type  :   elasticgraph    schema_backend  :   /workspace/development/app/src/eg_config/eg1/   # schema path to config files    deep  :     false     # deep feature of elasticgraph to use graph algorithms    collect  :     true     # collect feature of elasticsearch   ``` CODE              elasticgraph2.yaml    CODE ```   type  :   elasticgraph    schema_backend  :   /workspace/development/app/src/eg_config/eg2/   # schema path to config files    deep  :     false     # deep feature of elasticgraph to use graph algorithms    collect  :     true     # collect feature of elasticsearch   ``` CODE","metadata":{"source":"scripts/gs.json","line":125,"url":"https://docs.godspeed.systems/docs/microservices/custom-middleware","title":"Custom Middleware  Custom Middleware"}},{"pageContent":"All the configuration files of elasticgraph datasources should be defined in  CODE ``` src/datasources/eg_config/ ``` CODE  directory.Sample strucutre of config files under  CODE ``` schema_backend ``` CODE  path.   CODE ```   .    ├── eg1    │   ├── collect.toml    │   ├── common.toml    │   ├── config.toml    │   ├── custom.toml    │   ├── elasticsearch.toml    │   ├── joins    │   │   └── search.txt    │   └── schema    │       ├── aggregation.toml    │       ├── dependencies.toml    │       ├── entities    │       │   ├── credit_card.toml    │       │   └── user.toml    │       ├── entitiesInfo.toml    │       ├── relationships.txt    │       ├── suggestions.toml    │       └── union.toml    └── eg2        ├── collect.toml        ├── common.toml        ├── config.toml        ├── custom.toml        ├── elasticsearch.toml        ├── joins        │   └── search.txt        └── schema            ├── aggregation.toml            ├── dependencies.toml            ├── entities            │   ├── credit_card.toml            │   └── user.toml            ├── entitiesInfo.toml            ├── relationships.txt            ├── suggestions.toml            └── union.toml           ``` CODE","metadata":{"source":"scripts/gs.json","line":126,"url":"https://docs.godspeed.systems/docs/microservices/custom-middleware#141-how-to-add-custom-middleware-in-godspeed","title":"Custom Middleware  14.1 How to add custom middleware in Godspeed ​"}},{"pageContent":"The framework has  LINK-> inbuilt feature /docs/microservices/setup/auto-watch/#auto-watch-and-build <-LINK  of setting up elasticgraph model automatically whenever a new configuration is added in  CODE ``` src/datasources/eg_config/ ``` CODE  directory. In case, you are getting any error in the setup, then you can refer execute below step for manual setup:  During the project setup, if you have not selected elasticsearch, then you will have to execute  CODE ``` godspeed update ``` CODE  in project root directory, outside the dev container. This will add elasticsearch in the dev container environment. Step 1: godspeed eg-push LINK-> ​ #step-1-godspeed-eg-push <-LINK    CODE ```   $ godspeed eg-push                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                                > eg_test@1.0.0 eg-push    > for f in src/datasources/eg_config/*; do echo ${f}; node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ${f} all; done      src/datasources/eg_config/eg1   ``` CODE","metadata":{"source":"scripts/gs.json","line":127,"url":"https://docs.godspeed.systems/docs/microservices/datasources/api","title":"API datasource  API datasource"}},{"pageContent":"Developer can generate CRUD APIs for all the entities in  CODE ``` src/datasources/eg_config/ ``` CODE  directory.  CODE ``` Events ``` CODE  and  CODE ``` Workflows ``` CODE  will be auto generated for  CODE ``` Create ``` CODE ,  CODE ``` Read ``` CODE ,  CODE ``` Update ``` CODE  and  CODE ``` Delete ``` CODE  operations for each entity in respective datastore. Auto-generated events and workflows will be stored in  CODE ``` /events/{datasourceName}/{entityName} ``` CODE  and  CODE ``` /functions/com/gs/eg/{datasourceName}/{entityName} ``` CODE  folders respectively.   CODE ```   $ godspeed gen-crud-api                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                                > eg_test@1.0.0 gen-crud-api    > npx godspeed-crud-api-generator      Select datasource / schema to generate CRUD APIs    Events and Workflows are generated for elasticgraph.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":128,"url":"https://docs.godspeed.systems/docs/microservices/datasources/api#821-api-datasource-schema-defined-externally","title":"API datasource  8.2.1 API datasource schema defined externally ​"}},{"pageContent":"The framework provides feature to extend datasources where you can add new datasources with any customized type as per your business logic.","metadata":{"source":"scripts/gs.json","line":129,"url":"https://docs.godspeed.systems/docs/microservices/datasources/api#822-api-datasource-schema-defined-within-the-yaml-file","title":"API datasource  8.2.2 API datasource schema defined within the yaml file ​"}},{"pageContent":"You can define your datasource in yaml file inside  CODE ``` src/datasources ``` CODE  directory. For example, newDatasource.yaml is defined in the datasources.   CODE ```   .    ├── config    └── src        ├── datasources        │   └── httpbin.yaml        │   ├── kafka1.yaml        │   └── newDatasource.yaml        ├── events        ├── functions        └── mappings   ``` CODE              The three keys in yaml  CODE ``` type ``` CODE ,  CODE ``` loadFn ``` CODE  and  CODE ``` executeFn ``` CODE  are mandatory to define any new datasource which is not provided by the framework as core datasources. You can define other key/vaue pairs as per your need. Below is a sample of newDatasource.yaml   CODE ```   type: sample    loadFn: com.sample.loader    executeFn: com.sample.execute    client_url: https://sample.com    client_id: sample123   ``` CODE","metadata":{"source":"scripts/gs.json","line":130,"url":"https://docs.godspeed.systems/docs/microservices/datasources/api#823-headers-defined-at-datasource-level","title":"API datasource  8.2.3 Headers defined at datasource level ​"}},{"pageContent":"It defines the type of the datasource like api, soap, datastore, etc.","metadata":{"source":"scripts/gs.json","line":131,"url":"https://docs.godspeed.systems/docs/microservices/datasources/api#824-headers-defined-at-task-level","title":"API datasource  8.2.4 Headers defined at task level ​"}},{"pageContent":"It defines the load function which loads the client for the datasource. The developer must define the load function in the workflows as mentioned in the below project structure. The loadFn can be a js/ts function which takes the datasource yaml as an input and return an object that contains client.   CODE ```   .    ├── config    └── src        ├── datasources        ├── events        ├── functions        │   └── com        │       └── sample        │           ├── loader.ts        │           └── execute.ts        └── mappings   ``` CODE             A sample of loader.ts   CODE ```   export default async function(args:{[key:string]:any;}) {        const ds = {            ...args,            client: new SampleClient(args)            };        return ds;        }   ``` CODE","metadata":{"source":"scripts/gs.json","line":132,"url":"https://docs.godspeed.systems/docs/microservices/datasources/api#825-example-usage","title":"API datasource  8.2.5 Example usage ​"}},{"pageContent":"It defines the execute function which gets executed in the workflow. The developer must define the execute function in the workflows as mentioned in the above project structure. The executeFn can be a js/ts function which takes the  LINK-> workflow args /docs/microservices/workflows/#62-the-tasks-within-workflows <-LINK  as input and return status/output.   CODE ```   export default async function(args:{[key:string]:any;}) {        if(args.datasource) {            const client = args.datasource.client;            const data = args.data;              if (!Array.isArray(args.data)) {                data = [args.data];            }    . . . . . . . . . .            } else {            return { success: false, code: 500, data: 'datasource not found in the workflow' };        }    }   ``` CODE","metadata":{"source":"scripts/gs.json","line":133,"url":"https://docs.godspeed.systems/docs/microservices/datasources/aws","title":"Introduction  Introduction"}},{"pageContent":"CODE ```   /sample_helloworld.http.post  :        id  :   sample_event        fn  :   com.jfs.sample_helloworld        body  :             description  :   The body of the query          required  :     true          content  :            application/json  :     # For ex. application/json application/xml              schema  :                   type  :   object                properties  :                  name  :                       type  :   string                required  :     [  name  ]   ``` CODE","metadata":{"source":"scripts/gs.json","line":134,"url":"https://docs.godspeed.systems/docs/microservices/datasources/aws#871-example-spec","title":"Introduction  8.7.1 Example spec ​"}},{"pageContent":"CODE ```   summary  :   hello world    tasks  :        -     id  :   helloworld_step1          fn  :   com.sample.execute          args  :            datasource  :   newDatasource            data  :   <% inputs %  >            config  :              method  :   sample   ``` CODE","metadata":{"source":"scripts/gs.json","line":135,"url":"https://docs.godspeed.systems/docs/microservices/datasources/aws#872-comgsaws-workflow","title":"Introduction  8.7.2 com.gs.aws workflow ​"}},{"pageContent":"Any kind of entity which provides read and write mechanism for data is considered a datasource. For example, an API, a SQL or NoSQL datastore which includes RDBMS, key value stores, document stores etc. The settings for each datasource lies in  CODE ``` src/datasources ``` CODE  directory.IMAGE-> data:image/png;base64,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 <-IMAGE","metadata":{"source":"scripts/gs.json","line":136,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore","title":"Introduction  Introduction"}},{"pageContent":"Currently supported types   LINK-> API /docs/microservices/datasources/api <-LINK    LINK-> Datastores /docs/microservices/datasources/datastore <-LINK  (SQL/NoSQL)  Postgres  Mysql  Mongodb     LINK-> Kafka /docs/microservices/datasources/kafka <-LINK    LINK-> Elasticsearch /docs/microservices/datasources/elasticgraph <-LINK   Upcoming  S3  File system","metadata":{"source":"scripts/gs.json","line":137,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#831-schema-specification","title":"Introduction  8.3.1 Schema specification ​"}},{"pageContent":"The framework supports kafka as a datasource. It helps in interacting with kafka, to send/receive events on a kafka message bus.","metadata":{"source":"scripts/gs.json","line":138,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#832-cli-commands","title":"Introduction  8.3.2 CLI Commands ​"}},{"pageContent":"The datasources for kafka are defined in  CODE ``` src/datasources ``` CODE . Here, two kafka clients  CODE ``` kafka1.yaml ``` CODE  and  CODE ``` kafka2.yaml ``` CODE  are defined in datasources.   CODE ```   .    ├── config    └── src        ├── datasources        │   └── httpbin.yaml        │   ├── kafka1.yaml        │   └── kafka2.yaml        ├── events        ├── functions        └── mappings   ``` CODE             Sample configuration in  CODE ``` kafka1.yaml ``` CODE    CODE ```   type: kafka    client_id: my_service    brokers: [ \"kafka:9092\" ]   ``` CODE","metadata":{"source":"scripts/gs.json","line":139,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#833-prisma-datastore-setup","title":"Introduction  8.3.3 Prisma Datastore Setup ​"}},{"pageContent":"The framework supports Redis as a datasource. It helps to utilize redis in different ways.","metadata":{"source":"scripts/gs.json","line":140,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#model-setup","title":"Introduction 8.3.3 Prisma Datastore Setup ​  Model setup ​"}},{"pageContent":"The datasources for Redis are defined in  CODE ``` src/datasources ``` CODE . Here, Redis datasource is defined in  CODE ``` redis.yaml ``` CODE .   CODE ```   .    ├── config    └── src        ├── datasources        │   └── httpbin.yaml        │   ├── redis.yaml        ├── events        ├── functions        └── mappings   ``` CODE             Sample configuration in  CODE ``` redis.yaml ``` CODE    CODE ```   type: redis    url: redis[s]://[[username][:password]@][host][:port][/db-number]   ``` CODE             For full redis configuration, Refer  LINK-> redis node client documentation https://github.com/redis/node-redis/blob/master/docs/client-configuration.md <-LINK .","metadata":{"source":"scripts/gs.json","line":141,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#834-auto-generating-crud-apis-from-data-store-models","title":"Introduction  8.3.4 Auto generating CRUD APIs from data store models ​"}},{"pageContent":"The developer will use scaffolding provided by the platform to setup a new microservice project. In the configuration template, (s)he will configure the microservice for the required functionality, data model & performance tunings. Once done, (s)he can migrate the DBs and run the microservice, using the CLI during the local development, and using the GitOps process for staging/production deployment. Simple settings will provide out of the box functionalities like JWT token based authorization, APIs for multi db CRUD, analytics, search, suggest, document, notifications, event publishing/subscription, observability. This can be used to run standalone domain agnostic functional services like notification service! Or to run a separate microservice which does only the job of data federation and nothing else (Such a service is called backend for frontend aka BFF)","metadata":{"source":"scripts/gs.json","line":142,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#835-sample-datastore-crud-task","title":"Introduction  8.3.5 Sample datastore CRUD task ​"}},{"pageContent":"If for a domain microservice like Lead Origination System, there is any custom validations, business logic, event consumers, REST routes, orchestration flows etc that need to be written, the developer needs to add those within the microservice project, using the respective interface and scaffolding structure provided by the framework. This way a developer can get a custom microservice on top of the fundamental microservice framework capabilities. They can mix and match capabilities provided out of the box with custom capabilities added on top by them.IMAGE-> /assets/images/es2-164552cb07e31a0cd6cd7d59b2d8f0d6.PNG <-IMAGE","metadata":{"source":"scripts/gs.json","line":143,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#836-prisma-encryption-of-fields","title":"Introduction  8.3.6 Prisma encryption of fields ​"}},{"pageContent":"A microservice can be configured to consume events from variety of  LINK-> event sources #61-event-types <-LINK , like HTTP, gRpc, GraphQl, S3 etc. The event schema, for each event source, closely follows the OpenAPI specification. It includes The name/topic/URL of the event  The event source and other information for the source (for ex. group_id in case of Kafka events)  The event handler workflow  Validation (input and output)  Examples of input and output The response of the event is flexible for the developer to change as per the requirement.","metadata":{"source":"scripts/gs.json","line":144,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#8361-specification","title":"Introduction 8.3.6 Prisma encryption of fields ​  8.3.6.1 Specification ​"}},{"pageContent":"Currently supported  http.{method_type} For example, post or get  Kafka  salesforce  cron  Planned  Webhook  S3  gRPC  GraphQL  Websocket","metadata":{"source":"scripts/gs.json","line":145,"url":"https://docs.godspeed.systems/docs/microservices/datasources/datastore#8362-configuration","title":"Introduction 8.3.6 Prisma encryption of fields ​  8.3.6.2 Configuration ​"}},{"pageContent":"All event declarations are stored in the src/events folder, in YAML files.","metadata":{"source":"scripts/gs.json","line":146,"url":"https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph","title":"Introduction  Introduction"}},{"pageContent":"The framework provides request and response schema validation out of the box.Request schema validation LINK-> ​ #request-schema-validation <-LINK Sample spec for request schema.   CODE ```   body:      content:        application/json:          schema:            type: 'object'            required: []            properties:              dob:                type: 'string'                format : 'date'                pattern : \"[0-9]{4}-[0-9]{2}-[0-9]{2}\"   ``` CODE             If request schema validation fails, then status code 400 is returned.Response schema validation LINK-> ​ #response-schema-validation <-LINK Sample spec for response schema.   CODE ```   responses: #Output data defined as per the OpenAPI spec      200:        description:        content:          application/json: # For ex. application/json application/xml            schema:              type: object              properties:                application_id:                  type: string              additionalProperties: false              required: [application_id]            examples: # <string, ExampleObject>              example1:                summary:                description:                value:                  application_id: PRM20478956N                external_value:   ``` CODE             If response schema validation fails, then status code 500 is returned.","metadata":{"source":"scripts/gs.json","line":147,"url":"https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#851-folder-structure","title":"Introduction  8.5.1 Folder Structure ​"}},{"pageContent":"For an HTTP event, the headers, query, params and body data are captured in a standard format, and made available in the  CODE ``` inputs ``` CODE  object  LINK-> for use in the workflows #example-workflow-consuming-an-http-event <-LINK . The inputs (event) object has following properties:   CODE ```   - query: `<%inputs.query.var_name%>` # present in case of http events    - params: `<%inputs.params.path_param%>` # present in case of http events    - headers: `<%inputs.headers.some_header_key%>` # present in case of http events    - body: `<%inputs.body.key%>` # Present for all events except for http events which don't have a body. For ex. http.get    - files: `<%input.files%>` # Any files uploaded via HTTP event. Not present in other kind of events   ``` CODE             Example spec for HTTP event LINK-> ​ #example-spec-for-http-event <-LINK    CODE ```      /v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post  :     #Adding .http.post after        #the endpoint exposes the endpoint as REST via the POST method (in this example)        fn  :   com.biz.kyc.ckyc.ckyc_initiate   #The event handler written in ckyc_initiate.yml, and        # kept in src/workflows/com/biz/kyc/ckyc folder (in this example)        on_validation_error  :   com.jfs.handle_validation_error   # The validation error handler if event's json schema validation gets failed and        # kept in src/workflows/com/jfs/ folder (in this example)        body  :          required  :     true          content  :            application/json  :              schema  :                type  :     'object'                required  :     [  ]                properties  :                  dob  :      {     type     :     'string'  ,     format     :     'date'  ,     pattern     :     \"[0-9]{4}-[0-9]{2}-[0-9]{2}\"     }                  meta  :                    type  :     'object'          params  :        -     name  :   lender_loan_application_id          in  :   params   # same as open api spec: one of cookie, path, query, header          required  :     true          allow_empty_value  :     false          schema  :            type  :   string        responses  :     #Output data defined as per the OpenAPI spec          200  :            description  :            required  :     # default value is false            content  :              application/json  :     # For ex. application/json application/xml                schema  :                  type  :   object                  properties  :                    application_id  :                      type  :   string                  additionalProperties  :     false                  required  :     [  application_id  ]                examples  :     # <string, ExampleObject>                  example1  :                    summary  :                    description  :                    value  :                      application_id  :   PRM20478956N                    external_value  :                encoding  :          400  :            description  :            required  :     # default value is false            content  :              application/json  :     # For ex. application/json application/xml                schema  :                  type  :   object                  properties  :                    lender_response_code  :                      type  :   string                examples  :     # <string, ExampleObject>                  example1  :                    summary  :                    description  :                    value  :                      lender_response_code  :   E001                    external_value  :              encoding  :   ``` CODE             Example workflow consuming an HTTP event LINK-> ​ #example-workflow-consuming-an-http-event <-LINK    CODE ```       summary  :   Simply returning query & body data of an http.post event        id  :   some_unique_id        tasks  :          -     id  :   step1            fn  :   com.gs.return            args  :   <%inputs.body%  >     # Evaluation of dynamic values happens via <% %>. The type of scripting can be coffee/js.            # Here we are returning the body of the HTTP post event.   ``` CODE             Example workflow (on_validation_error handler) handling json schema validation error LINK-> ​ #example-workflow-on_validation_error-handler-handling-json-schema-validation-error <-LINK    CODE ```       summary  :   Handle json scehma validation error        id  :   error_handler        tasks  :          -     id  :   erorr_step1            fn  :   com.gs.kafka            args  :              datasource  :   kafka1              data  :     # publish the event and validation error to kafka on a topic                value  :                  event  :   <% inputs.event %  >                  validation_error  :   <% inputs.validation_error %  >              config  :                topic  :   kafka_error_handle                method  :   publish   ``` CODE","metadata":{"source":"scripts/gs.json","line":148,"url":"https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#852-datasource-dsl","title":"Introduction  8.5.2 Datasource DSL ​"}},{"pageContent":"A kafka event is specified as  CODE ``` {topic_name}.{datasourceName}.{group_id} ``` CODE  in  LINK-> the kafka event specification #example-spec-for-kafka-event <-LINK . The  CODE ``` group_id ``` CODE  represents identifier for all the consumers of the group. Only one consumer of the group will consume a message. This is useful for microservices, when a single services runs in multiple K8s pods. Each pod is part of the same group. This ensures the message is eventually consumed by any one of the pods.The message body of a kafka event is captured and represented as  CODE ``` inputs.body ``` CODE  for  LINK-> consumption in the handler workflow #example-workflow-consuming-a-kafka-event <-LINK .Datasource for kafka LINK-> ​ #datasource-for-kafka <-LINK The datasources for kafka are defined in  CODE ``` src/datasources ``` CODE .  LINK-> Refer Kafka as datasource /docs/microservices/datasources/kafka/#741-example-spec <-LINK  for more information.Example spec for kafka event LINK-> ​ #example-spec-for-kafka-event <-LINK    CODE ```   kafka-consumer1.kafka1.kafka_proj  :     # This event will be triggered whenever        # a new message arrives on the topic_name        id  :   /kafkaWebhook        fn  :   com.jfs.publish_kafka   #The event handler written in publish_kafka.yml, and        # kept in src/workflows/com/jfs folder (in this example)        on_validation_error  :   com.jfs.handle_validation_error   # The validation error handler if event's json schema validation gets failed and        # kept in src/workflows/com/jfs folder (in this example)        body  :          description  :   The body of the query          content  :            application/json  :     # For ex. application/json application/xml              schema  :                type  :   object                properties  :                  name  :                    type  :   string                required  :     [  name  ]   ``` CODE             Example workflow consuming a kafka event LINK-> ​ #example-workflow-consuming-a-kafka-event <-LINK    CODE ```       summary  :   Handle kafka event        id  :   some_unique_id        tasks  :          -     id  :   step1            summary  :   Publish an event with this data            fn  :   com.gs.kafka            args  :     # similar to Axios format              datasource  :   kafka1              config  :                method  :   publish                topic  :   publish  -  producer1              data  :                value  :   <% inputs %  >            # Here we are publishing an event data to another topic   ``` CODE             Refer  LINK-> com.gs.kafka /docs/microservices/workflows/#662-comgskafka <-LINK  native function to publish an event on kafka.","metadata":{"source":"scripts/gs.json","line":149,"url":"https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#853-configuration-files-of-elasticgraph","title":"Introduction  8.5.3 Configuration files of elasticgraph ​"}},{"pageContent":"A salesforce event is specified as  CODE ``` {topic_name}.salesforce.{datasource_name} ``` CODE   CODE ``` topic_name ``` CODE is salaesforce event topic\n CODE ``` datasource_name ``` CODE  is name of the  CODE ``` salesforce ``` CODE datasource filenamePrerequisite: For using  CODE ``` salesforce ``` CODE , You need to enable  CODE ``` redis ``` CODE  datasource. You can enable  CODE ``` redis ``` CODE while creating a new  CODE ``` godspeed ``` CODE  project or run  CODE ``` godspeed update ``` CODE  on an existing project.  in  CODE ``` config/default.yaml ``` CODE add a property as  CODE ``` caching: redis ``` CODE . Where  CODE ``` redis ``` CODE  is datasource name. If your  CODE ``` redis ``` CODE  type datasource name is  CODE ``` redis1.yaml ``` CODE , then  CODE ``` caching: redis1 ``` CODE  will be the correct configuration. Example of  CODE ``` salesforce ``` CODE datasource, eg:  CODE ``` src/datasources/salaeforce.yaml ``` CODE    CODE ```   type  :   salesforce    connection  :          # Please Check  https:#jsforce.github.io/document/            #1. Username and Password Login          # you can change loginUrl to connect to sandbox or prerelease env.          # loginUrl : 'https:#test.salesforce.com'            #2. Username and Password Login (OAuth2 Resource Owner Password Credential)          oauth2  :              # you can change loginUrl to connect to sandbox or prerelease env.              # loginUrl : 'https:#test.salesforce.com',              clientId     :     '<your Salesforce OAuth2 client ID is here>'              clientSecret     :     '<your Salesforce OAuth2 client secret is here>'              redirectUri     :     '<callback URI is here>'            #3. Session ID          serverUrl     :     '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'          sessionId     :     '<your Salesforce session ID is here>'            #4. Access Token          instanceUrl     :     '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'          accessToken     :     '<your Salesforrce OAuth2 access token is here>'            #5. Access Token with Refresh Token          oauth2  :              clientId     :     '<your Salesforce OAuth2 client ID is here>'              clientSecret     :     '<your Salesforce OAuth2 client secret is here>'              redirectUri     :     '<your Salesforce OAuth2 redirect URI is here>'          instanceUrl     :     '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'          accessToken     :     '<your Salesforrce OAuth2 access token is here>'          refreshToken     :     '<your Salesforce OAuth2 refresh token is here>'      username  :   <% config.salesforce_username %  >    password  :   <% config.salesforce_password %  >   ``` CODE             Example of  CODE ``` salesforce ``` CODE  event:   CODE ```   {  topic_name  }  .salesforce.  {  datasourceName  }    id  :   /salesforcetopic    fn  :   com.jfs.handle_title_events    on_validation_error  :   com.jfs.handle_validation_error    body  :        description  :   The body of the query        content  :          application/json  :            schema  :              type  :   object              properties  :                name  :                  type  :   string              required  :     [  name  ]   ``` CODE","metadata":{"source":"scripts/gs.json","line":150,"url":"https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#854-elasticgraph-setup","title":"Introduction  8.5.4 Elasticgraph Setup ​"}},{"pageContent":"A CRON event will allow you to run events at scheduled time / interval. A CRON event is specified as  CODE ``` {schedule_expression.cron.timezone} ``` CODE     CODE ``` schedule_expression ``` CODE  You can refer  LINK-> crontab https://crontab.guru/ <-LINK  to generate schedule.     CODE ``` timezone ``` CODE  Refer  LINK-> this wikipedia https://en.wikipedia.org/wiki/List_of_tz_database_time_zones <-LINK  to get the timezone format.  Here is an example of a CRON event which run every minute.   every_minute_cron.yaml    CODE ```   \"* * * * *.cron.Asia/Kolkata\"  :       fn  :   com.every_minute   ``` CODE               and corresponding function is   com/every_minute.yaml    CODE ```      summary  :   this workflow will be running every minute       tasks  :         -     id  :   print           description  :   print every           fn  :   com.gs.log           args  :             level  :   info             data  :   HELLO from CRON   ``` CODE","metadata":{"source":"scripts/gs.json","line":151,"url":"https://docs.godspeed.systems/docs/microservices/datasources/elasticgraph#855-auto-generating-crud-apis-for-elasticgraph","title":"Introduction  8.5.5 Auto generating CRUD APIs for elasticgraph ​"}},{"pageContent":"Every microservice in the Godspeed framework has three fundamental abstractions, and the developer needs to work with just these three.  LINK-> Events /docs/microservices/events <-LINK : Events trigger workflows. Events are generated by event sources like REST endpoints, gRPC, message bus, webhooks, websockets, S3, and more...   LINK-> Workflows /docs/microservices/workflows <-LINK : Workflows are triggered by events. They not only perform business logic but also provide orchestration over datasources and microservices, and data/API federation. They will use datasources to store or retrieve data, join across various datasources, transform data, emit events and send responses. The framework provides a YAML dsl with some  LINK-> inbuilt workflows /docs/microservices/workflows#66-inbuilt-functions <-LINK . If YAML does not suffice for any particular case, developers can currently put JS/TS workflows alongside YAML workflows and use them.  Coming in future : Support for other languages.   LINK-> Datasources /docs/microservices/datasources/intro <-LINK : Datasources are locations where data can be stored or read from. For example API datasource (another microservice or third party), datastores (RDBMS, document, key-value), file system, S3 storage, etc. A microservice can use multiple datasources. The framework provides abstractions for Authn/Authz making it easy for the developer to express the same in a low code manner.  These abstractions allow the developer to focus purely on their business logic. 99.9% - 100% of typical functionality needed by the developer is covered by the framework's YAML-based DSL. Devs can forget about the low-level stuff they typically need to do - which accounts for 90% of the work in typical app dev scenario. The framework aims to handle all the low level functionality and saves developer's effort to do the same. For example creating controllers for endpoints, endpoint authentication/authorization, input validation, auto-telemetry with distributed context, setting up DB client and authorizing DB access, authentication of third party API, key management, creating Swagger docs or Postman collection, creating basic test suite based on documentation, etc.There is a standard  LINK-> project structure /docs/microservices/setup/scaffolding#321-scaffolding--project-structure <-LINK  which will give the developer a kickstart to their project and also reference code/declarations, for the kind of stuff they can do using the framework.","metadata":{"source":"scripts/gs.json","line":152,"url":"https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources","title":"Introduction  Introduction"}},{"pageContent":"The developer will use the CLI provided by the framework to setup a new microservice project and start developing. (S)he will configure the events, datasources, and workflows for the required functionality, along with mappings, environment variables, and common configurations, like for telemetry. To configure the datasources,  For datastores: they will either define the db schema or autogenerate it from the existing database using the CLI.   For APIs: they will need to define the APIs OpenAPI schema or provide the url for the same.","metadata":{"source":"scripts/gs.json","line":153,"url":"https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#861-datasource-definition","title":"Introduction  8.6.1 Datasource definition ​"}},{"pageContent":"Note   Some of the features mentioned here are in the product roadmap and planned for upcoming releases.   Schema driven development The developer has to specify the API and data schema to start the development. YAML based DSL and configurations We have YAML based DSL which makes it much easier and succinct to express policies, business logic, and configurations. Code is shorter and easier to comprehend than programming, even for new learners. This DSL can be further customized by developers to add custom requirements.  Multi datastore support The same model configuration & unified CRUD API (including full-text search and autosuggest) will provide interfaces with multiple kinds of datastores (SQL or NoSQL). The API is aimed to provide validation, relationship management, transactions, denormalization, and multilingual support. Each integration will support the possible functionality as per the nature of the store.   Data validation The framework provides validation of third party API requests & responses, datastore queries, and its own API endpoints request and response. The developer only needs to specify the schema of third party API, own microservice API, and datastore model. Rest is taken care of by the framework. In case of more complex validation scenarios, where customer journeys may require conditional validation of incoming requests based on some attributes (in the database or the query {i.e. subject, object, environment, payload}), the developer can add such rules to the application logic as part of the workflows. Authentication The microservice framework authenticates every incoming request and extracts the user role and other info, for further processing, based on a valid JWT token. An IAM provider like ORY Kratos can be integrated into the platform for providing identity service. It will generate a JWT token which will include user id, information, and roles. This token is consumed by the microservices for user validation. Authorization   (  Planned  ) Each microservice will do the job of authorization for any request. Developers will write authorization rules for every microservice in simple configuration files. This will cover not only API endpoint access but also fine grained data access from datastores. This will integrate with third party Authz services in a pluggable way, with abstractions.  Distributed transactions   (  Planned  ) Each domain’s orchestrator is able to use the Saga  LINK-> pattern https://www.baeldung.com/cs/saga-pattern-microservices <-LINK  to ensure distributed transactions across multiple microservices. Autogenerated documentation The framework provides autogenerated documentation using CLI. Autogenerated CRUD API    (  Planned  ) The framework provides autogenereated CRUD APIs from database model. Generated API's can be extended by the developers as per their needs. Autogenerated test suite  The framework provides autogenerated test suite for APIs using CLI.  Multiple languages support In case YAML is not enough for a corner case, developers can write custom business logic in any language. If written in JS/TS, they can place the code within the same microservice project. Other language support will also work in the same way, and is planned for the future. Observability The framework provides automatic  LINK-> observability /docs/telemetry/intro <-LINK  support with correlation, for modern distributed systems, via the OpenTelemetry spec. For the same, it will work in conjunction with the microservice mesh used. The developer can extend that to include customized observability. This can integrate with any tools that support OpenTelemetry.LoggingThe inbuilt logging mechanism will log both sync request/response cycle or async events, for both success and failure scenarios. MonitoringThe framework allows the developer to monitor custom business metrics, along with application level metrics like latency, success, and failures. TracingEvery incoming sync & async request will carry trace information in its headers. The same is propagated further through the microservice framework when it makes a sync or async hit to another service.","metadata":{"source":"scripts/gs.json","line":154,"url":"https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#type","title":"Introduction 8.6.1 Datasource definition ​  type ​"}},{"pageContent":"The CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.","metadata":{"source":"scripts/gs.json","line":155,"url":"https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#loadfn","title":"Introduction 8.6.1 Datasource definition ​  loadFn ​"}},{"pageContent":"Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.  Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.  List the versions of gs_service.  Change the version of gs_service.","metadata":{"source":"scripts/gs.json","line":156,"url":"https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#executefn","title":"Introduction 8.6.1 Datasource definition ​  executeFn ​"}},{"pageContent":"All Prisma commands including DB push, pull or migration.  OAS 3 documentation file generation.  Test suite/Postman collection generation.  Running test suite.","metadata":{"source":"scripts/gs.json","line":157,"url":"https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#862-example-spec-for-the-event","title":"Introduction  8.6.2 Example spec for the event ​"}},{"pageContent":"CODE ```   npm install -g @mindgrep/godspeed   ``` CODE             Once Godspeed CLI is installed, the  CODE ``` godspeed ``` CODE  command can be called from command line. When called without arguments, it displays its help and command usage.   CODE ```   $ godspeed                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Usage: godspeed [options] [command]      Options:      -v, --version                   output the version number      -h, --help                      display help for command      Commands:      create [options] <projectName>      versions                        List all the available versions of gs_service      prepare                         prepare the containers, before launch or after cleaning the containers      version <version>      help [command]                  display help for command   ``` CODE","metadata":{"source":"scripts/gs.json","line":158,"url":"https://docs.godspeed.systems/docs/microservices/datasources/extensible-datasources#863-example-spec-for-the-workflow","title":"Introduction  8.6.3 Example spec for the workflow ​"}},{"pageContent":"The --version option outputs information about your current godspeed version.   CODE ```   $ godspeed -v                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              0.0.26   ``` CODE","metadata":{"source":"scripts/gs.json","line":159,"url":"https://docs.godspeed.systems/docs/microservices/datasources/intro","title":"Datasources  Datasources"}},{"pageContent":"The --help option displays help and command usage.   CODE ```   $ godspeed                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Usage: godspeed [options] [command]      Options:      -v, --version                   output the version number      -h, --help                      display help for command      Commands:      create [options] <projectName>      versions                        List all the available versions of gs_service      prepare                         prepare the containers, before launch or after cleaning the containers      version <version>      help [command]                  display help for command   ``` CODE","metadata":{"source":"scripts/gs.json","line":160,"url":"https://docs.godspeed.systems/docs/microservices/datasources/intro#811-datasource-types","title":"Datasources  8.1.1 Datasource types ​"}},{"pageContent":"The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.   CODE ```   $ godspeed create my_service                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefined    project created    Do you need mongodb? [y/n] [default: n] n    Do you need postgresdb? [y/n] [default: n] y    Please enter name of the postgres database [default: test]     Do you need kafka? [y/n] [default: n] n    Do you need elastisearch? [y/n] [default: n] n    Please enter host port on which you want to run your service [default: 3000] 3100    Fetching release version information...    Please select release version of gs_service from the available list:    latest    1.0.0    1.0.1    1.0.10    1.0.11    1.0.12    1.0.13    1.0.2    1.0.3    1.0.4    1.0.5    1.0.6    1.0.7    1.0.8    1.0.9    base    dev    v1.0.13    Enter your version [default: latest] 1.0.13    Selected version 1.0.13    . . . . . . . .    ``` CODE             Options LINK-> ​ #options <-LINK    CODE ```   $ godspeed help create                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Usage: godspeed create [options] <projectName>      Options:      -n, --noexamples                      create blank project without examples      -d, --directory <existing_project_directory>  existing project template dir      -h, --help                            display help for command   ``` CODE","metadata":{"source":"scripts/gs.json","line":161,"url":"https://docs.godspeed.systems/docs/microservices/datasources/kafka","title":"Introduction  Introduction"}},{"pageContent":"The update can be executed in the following cases: If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute  CODE ``` godspeed update ``` CODE  command before launching the project.  If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute  CODE ``` godspeed update ``` CODE  with the required settings.  If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute  CODE ``` godspeed update ``` CODE command. It fetches the new docker image itself.  Please note that the command should be executed from inside the project root directory.      note   Whenever you update your project using  CODE ``` godspeed update ``` CODE  and open the project in VScode dev container after update, then it is mandatory to do  LINK->  CODE ``` godspeed build ``` CODE  #build <-LINK  inside dev container for the first time.     CODE ```   $ godspeed update                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Do you need postgresdb? [y/n] [default: n]     Do you need kafka? [y/n] [default: n]     Do you need elastisearch? [y/n] [default: n]     Please enter host port on which you want to run your service [default: 3000]     Fetching release version information...    Please select release version of gs_service from the available list:    latest    1.0.0    1.0.1    1.0.2    1.0.3    1.0.4    dev    stable    Enter your version [default: latest]     Selected version latest    Removing dev_test_devcontainer_node_1                ...     . . . . . . . . . .    Step 1/9 : FROM adminmindgrep/gs_service:latest    latest: Pulling from adminmindgrep/gs_service    824b15f81d65: Already exists    325d38bcb229: Already exists    d6d638bf61bf: Already exists    55daac95cedf: Already exists    4c701498752d: Already exists    a48b0ae49665: Pulling fs layer    4c393fb6deac: Pulling fs layer    4f4fb700ef54: Pulling fs layer    8992963a9530: Pulling fs layer    4f4fb700ef54: Verifying Checksum    4f4fb700ef54: Download complete    4c393fb6deac: Verifying Checksum    4c393fb6deac: Download complete    8992963a9530: Verifying Checksum    8992963a9530: Download complete    a48b0ae49665: Verifying Checksum    a48b0ae49665: Download complete    a48b0ae49665: Pull complete    4c393fb6deac: Pull complete    4f4fb700ef54: Pull complete    8992963a9530: Pull complete    Digest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278ee    Status: Downloaded newer image for adminmindgrep/gs_service:latest     ---> 988917710d1a    Step 2/9 : ARG USERNAME=node     ---> Running in c70404bb4f3e    Removing intermediate container c70404bb4f3e     ---> 47a7406b2473    Step 3/9 : ARG USER_UID=1000     ---> Running in 51e68336d8d8    Removing intermediate container 51e68336d8d8     ---> ce913f6898bb    Step 4/9 : ARG USER_GID=$USER_UID     ---> Running in 7cf1c1f2a3ec    Removing intermediate container 7cf1c1f2a3ec     ---> 91f045b32e0f    Step 5/9 : USER root     ---> Running in f338d755a032    Removing intermediate container f338d755a032     ---> fa9898eb4c23    Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development     ---> Running in eba3659fb919    Removing intermediate container eba3659fb919     ---> 414f34560b0d    Step 7/9 : USER node     ---> Running in 23818c5f4882    Removing intermediate container 23818c5f4882     ---> 1bd65323ae91    Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed     ---> Running in a66cb062390d    . . . . . . . . . .     godspeed update dev_test is done.   ``` CODE","metadata":{"source":"scripts/gs.json","line":162,"url":"https://docs.godspeed.systems/docs/microservices/datasources/kafka#841-example-spec","title":"Introduction  8.4.1 Example spec ​"}},{"pageContent":"The versions command lists all the versions available of gs_service.   CODE ```   $ godspeed versions                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              latest    1.0.0    1.0.1    1.0.10    1.0.11    1.0.12    1.0.13    1.0.2    1.0.3    1.0.4    1.0.5    1.0.6    1.0.7    1.0.8    1.0.9    base    dev    v1.0.13   ``` CODE","metadata":{"source":"scripts/gs.json","line":163,"url":"https://docs.godspeed.systems/docs/microservices/datasources/redis","title":"Introduction  Introduction"}},{"pageContent":"The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.   CODE ```   $ godspeed version 1.0.13                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Generating prisma modules    Starting test1_devcontainer_postgres_1 ...     Starting test1_devcontainer_postgres_1 ... done    Creating test1_devcontainer_node_run   ...     Creating test1_devcontainer_node_run   ... done    Environment variables loaded from .env    . . . . . . . . . .   ``` CODE","metadata":{"source":"scripts/gs.json","line":164,"url":"https://docs.godspeed.systems/docs/microservices/datasources/redis#881-example-spec","title":"Introduction  8.8.1 Example spec ​"}},{"pageContent":"The help command displays help and usage for any command.   CODE ```   $ godspeed help create                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                              Usage: godspeed create [options] <projectName>      Options:      -n, --noexamples                      create blank project without examples      -d, --directory <projectTemplateDir>  local project template dir      -h, --help                            display help for command   ``` CODE","metadata":{"source":"scripts/gs.json","line":165,"url":"https://docs.godspeed.systems/docs/microservices/developer-manual/intro","title":"introWork of the developer  intro"}},{"pageContent":"You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection.  LINK-> Read more here https://www.prisma.io/docs/concepts/components/prisma-cli <-LINK .    CODE ```   $ godspeed prisma <prisma command with args>   ``` CODE","metadata":{"source":"scripts/gs.json","line":166,"url":"https://docs.godspeed.systems/docs/microservices/developer-manual/intro","title":"introWork of the developer  Work of the developer"}},{"pageContent":"You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer  LINK-> Open in Dev container /docs/microservices/setup/getting-started/#step-5-open-in-dev-container <-LINK    CODE ```   godspeed build   ``` CODE","metadata":{"source":"scripts/gs.json","line":167,"url":"https://docs.godspeed.systems/docs/microservices/developer-manual/intro#creating-data-services-or-module-services-like-document-or-notification-service-","title":"introWork of the developer  Creating Data services or module services like Document or Notification service   ​"}},{"pageContent":"You can run your project using dev command.   CODE ```   godspeed dev   ``` CODE","metadata":{"source":"scripts/gs.json","line":168,"url":"https://docs.godspeed.systems/docs/microservices/developer-manual/intro#creating-domain-gateway-orchestrators--servicese-","title":"introWork of the developer  Creating domain gateway, orchestrators & servicese   ​"}},{"pageContent":"You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.   CODE ```   $ godspeed gen-api-docs                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                                > proj_upd@1.0.0 gen-api-docs    > node ../gs_service/dist/api-specs/api-spec.js | pino-pretty      [1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events    [1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml    [1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!   ``` CODE","metadata":{"source":"scripts/gs.json","line":169,"url":"https://docs.godspeed.systems/docs/microservices/events","title":"Events  Events"}},{"pageContent":"You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly.   CODE ```    godspeed gen-test-suite                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                                > proj_upd@1.0.0 gen-test-suite    > npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false        > proj_upd@1.0.0 gen-api-docs    > node ../gs_service/dist/api-specs/api-spec.js | pino-pretty      [1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events    [1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml    [1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!    Input file:  /workspace/development/app/docs/api-doc.yaml    Writing to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }    Conversion successful, collection written to file   ``` CODE","metadata":{"source":"scripts/gs.json","line":170,"url":"https://docs.godspeed.systems/docs/microservices/events#61-event-types","title":"Events  6.1 Event types ​"}},{"pageContent":"You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.   CODE ```   $ godspeed gen-crud-api                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                                > eg_test@1.0.0 gen-crud-api    > npx godspeed-crud-api-generator      Select datasource / schema to generate CRUD APIs    (x) elasticgraph.yaml    ( ) For all    ( ) Cancel   ``` CODE","metadata":{"source":"scripts/gs.json","line":171,"url":"https://docs.godspeed.systems/docs/microservices/events#62-event-schema--examples-for-supported-sources","title":"Events  6.2 Event schema & examples for supported sources ​"}},{"pageContent":"You can run the test suite generated in above command from the following two ways: Postman: Import the collection in postman and run the test suite.  CLI: You can use below command to run the test suite from CLI.  Please make sure your service is up and running before running the test suite.    CODE ```    godspeed test                          _                                   _        __ _    ___     __| |  ___   _ __     ___    ___    __| |      / _` |  / _ \\   / _` | / __| | '_ \\   / _ \\  / _ \\  / _` |     | (_| | | (_) | | (_| | \\__ \\ | |_) | |  __/ |  __/ | (_| |      \\__, |  \\___/   \\__,_| |___/ | .__/   \\___|  \\___|  \\__,_|      |___/                        |_|                                > proj_upd@1.0.0 test    > newman run tests/test-suite.json      newman      Godspeed: Sample Microservice      → Call another (sub) workflow from main workflow      POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]    . . . . . . . .    ``` CODE","metadata":{"source":"scripts/gs.json","line":172,"url":"https://docs.godspeed.systems/docs/microservices/events#621-json-schema-validation","title":"Events 6.2 Event schema & examples for supported sources ​  6.2.1 JSON schema validation ​"}},{"pageContent":"The help command displays help and usage for any command.  LINK-> Click here to know more #help <-LINK","metadata":{"source":"scripts/gs.json","line":173,"url":"https://docs.godspeed.systems/docs/microservices/events#622-http-event","title":"Events 6.2 Event schema & examples for supported sources ​  6.2.2 HTTP event ​"}},{"pageContent":"Mappings is a global object which will be available in your microservice. You can define anything in the mappings i.e. key/value pair map, array, etc. You can access these mappings inside your workflows at any time.","metadata":{"source":"scripts/gs.json","line":174,"url":"https://docs.godspeed.systems/docs/microservices/events#623-kafka-event","title":"Events 6.2 Event schema & examples for supported sources ​  6.2.3 Kafka event ​"}},{"pageContent":"Mappings are present in  CODE ``` src/mappings ``` CODE  directory. The default format is yaml and you can store mappings in the nested directories also. The nested directories are also accessible in the same  CODE ``` mappings ``` CODE  object.   CODE ```   .    ├── config    └── src        └── mappings            └── index.yaml            └── generate.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":175,"url":"https://docs.godspeed.systems/docs/microservices/events#624-salesforce-event","title":"Events 6.2 Event schema & examples for supported sources ​  6.2.4 Salesforce event ​"}},{"pageContent":"This is a sample mapping which is accessible in the workflows inside mappings object using  CODE ``` mappings.Gender ``` CODE  and  CODE ``` mappings.generate.genId ``` CODE     index.yaml    CODE ```   Gender  :        Male  :   M        Female  :   F        Others  :   O   ``` CODE              generate.yaml    CODE ```   genId  :     12345   ``` CODE                  Note   If the file name is index.yaml then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the mappings object like  CODE ``` mappings.Gender ``` CODE .\nHowever, for other file names you need to mention the file name while accessing the mappings object like  CODE ``` mappings.generate.genId ``` CODE   Smaple workflow accessing mappings object:   CODE ```     - id: httpbinCof_step1        description: Hit http bin with some dummy data. It will send back same as response        fn: com.gs.http        args:          datasource: httpbin          params:          data:            personal_email_id: 'ala.eforwich@email.com'            gender: <% mappings.Gender[inputs.body.Gender] %>            id:  <% mappings.generate.genId %>          config:            url : /anything            method: post   ``` CODE","metadata":{"source":"scripts/gs.json","line":176,"url":"https://docs.godspeed.systems/docs/microservices/events#625-cron-event","title":"Events 6.2 Event schema & examples for supported sources ​  6.2.5 CRON event ​"}},{"pageContent":"You can use mapping constants in other mapping files using coffee/js scripting.For example, you have mapping files  CODE ``` index.yaml ``` CODE ,  CODE ``` relations.json ``` CODE  and  CODE ``` reference.yaml ``` CODE . Use the mappings from first two files as reference in the third file as follows:    index.yaml    CODE ```   Gender  :        Male  :   M        Female  :   F        Others  :   O   ``` CODE              relations.json    CODE ```   {          \"id\"  :     1  ,          \"title\"  :     \"Hello World\"  ,          \"completed\"  :     false    }   ``` CODE              reference.yaml    CODE ```   NewGender  :   <% mappings.Gender.Others %  >    title  :    <% mappings.relations.title %  >   ``` CODE","metadata":{"source":"scripts/gs.json","line":177,"url":"https://docs.godspeed.systems/docs/microservices/intro","title":"Introduction  Introduction"}},{"pageContent":"Plugins are small js/ts functions to enhance the workflows capabilities. You can write any piece of code in the plugin and can access it inside your workflows at any time.","metadata":{"source":"scripts/gs.json","line":178,"url":"https://docs.godspeed.systems/docs/microservices/intro#21-developers-work","title":"Introduction  2.1 Developer's work ​"}},{"pageContent":"Plugins are present in  CODE ``` src/plugins ``` CODE  directory. The default format is js/ts and you can store plugins in the nested directories also.   CODE ```   .    ├── config    └── src        └── plugins            └── index.ts            └── time                └── epoch.ts            └── epoch                └── convertEpoch.ts   ``` CODE","metadata":{"source":"scripts/gs.json","line":179,"url":"https://docs.godspeed.systems/docs/microservices/intro#salient-features","title":"Introduction 2.1 Developer's work ​  Salient Features ​"}},{"pageContent":"These are the sample plugins file which export plugin functions named  CODE ``` randomInt ``` CODE  and  CODE ``` convertEpochToDate ``` CODE . plugins/index.ts    CODE ```   export     function     randomInt  (  min  :     number  ,   max  :     number  )     {          return   Math  .  floor  (  Math  .  random  (  )     *     (  max   -   min   +     1  )  )     +   min  ;    }   ``` CODE              plugins/time/epoch.ts    CODE ```   import   format   from     'date-fns/format'  ;      export     function     convertEpochToDate  (  inputTimestamp  :     string  )  {          const   newDateTime   =     new     Date  (  inputTimestamp  )  ;          return     format  (  newDateTime  ,     'yyyy-MM-dd HH:mm:ss'  )  ;    }   ``` CODE              plugins/epoch/convertEpoch.ts    CODE ```   import   format   from     'date-fns/format'  ;      export     default     function     convertEpoch  (  inputTimestamp  :     string  )  {          const   newDateTime   =     new     Date  (  inputTimestamp  )  ;          return     format  (  newDateTime  ,     'yyyy-MM-dd HH:mm:ss'  )  ;    }   ``` CODE                  Note    If the file name is index.ts then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the plugin e.g.  CODE ``` randomInt ``` CODE .      For other file names you need to mention the file name using underscore notation while accessing the plugins function inside your workflow e.g.  CODE ``` time_epoch_convertEpochToDate ``` CODE   If it's a default import then you don't need to mention the plugin function name e.g.  CODE ``` epoch_convertEpoch ``` CODE","metadata":{"source":"scripts/gs.json","line":180,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli","title":"Godspeed CLI  Godspeed CLI"}},{"pageContent":"You can use these plugins in your workflows as given below:   CODE ```     - id: httpbinCof_step1        description: Hit http bin with some dummy data. It will send back same as response        fn: com.gs.http        args:          datasource: httpbin          params:          data:            personal_email_id: 'ala.eforwich@email.com'            id: <% 'UID-' + randomInt(1,9) %>            date: <% time_epoch_convertEpochToDate(inputs.body.datetimestamp) %>            default_date: <% epoch_convertEpoch(inputs.body.datetimestamp) %>          config:            url : /anything            method: post   ``` CODE","metadata":{"source":"scripts/gs.json","line":181,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#41-functionality","title":"Godspeed CLI  4.1 Functionality ​"}},{"pageContent":"The framework provides auto watch/build feature to detect the changes in you project files. This feature is only applicable when you are working inside dev container.        note   Please make sure VS code 'Run On Save' plugin is installed in your dev container environment.  Here is the list of files which are being watched inside the dev container.   CODE ```   src/**/*.yaml|yml|js|json    src/**/*.ts    src/**/*.prisma    src/**/*.toml   ``` CODE               *.prisma files \nThese files are being watched for  LINK-> Datastore as datasources /docs/microservices/datasources/datastore <-LINK  During any datastore setup via Prisma in the dev container, you don't need to setup anything explicitily, the watch feature automatically takes care of setting up the datastores. Refer  LINK-> Prisma Datastore Setup /docs/microservices/datasources/datastore/#733-prisma-datastore-setup <-LINK  for more information.   *.toml files \nThese files are being watched for configuration files of  LINK-> Elasticgraph as datasource /docs/microservices/datasources/elasticgraph/#753-configuration-files-of-elasticgraph <-LINK . If there is any change in *.toml file then auto watch reindexes all the elasticgraph datasources configuration inside  CODE ``` src/datasources/eg_config/ ``` CODE  directory.","metadata":{"source":"scripts/gs.json","line":182,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#outside-the-dev-container","title":"Godspeed CLI 4.1 Functionality ​  Outside the dev container ​"}},{"pageContent":"The environment variables are defined in yaml files under  CODE ``` config/custom-environment-variables.yaml ``` CODE  file. The default directory structure is given as below:   CODE ```   ├── config    │   ├── custom-environment-variables.yaml   ``` CODE                  note   Any configuration which includes secrets or passwords is recommended to be defined using environment variables only.","metadata":{"source":"scripts/gs.json","line":183,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#inside-the-dev-container","title":"Godspeed CLI 4.1 Functionality ​  Inside the dev container ​"}},{"pageContent":"This is a sample for custom environment variables where these variables gets values from environment variables set in the environment.    CODE ```   my_datasource:      base_url: MY_DATASOURCE_BASE_URL      api_key: MY_DATASOURCE_API_KEY      api_token: MY_DATASOURCE_API_TOKEN      kafka:      brokers:        __name: KAFKA_BROKERS        __format: json      client_id: KAFKA_CLIENT_ID      jwt:      issuer: JWT_ISS      audience: JWT_AUD      secretOrKey: JWT_SECRET      prisma_secret: PRISMA_SECRET   ``` CODE             For example,  CODE ``` MY_DATASOURCE_BASE_URL ``` CODE  is defined as an environment variable. To specify its value, you need to export this variable in the environment as given below:   CODE ```   $ export MY_DATASOURCE_BASE_URL=https://httpbin.org/   ``` CODE             After exporting the environment variable, you can access this variable in your project by using scripting  CODE ``` <% config.my_datasource.base_url %> ``` CODE","metadata":{"source":"scripts/gs.json","line":184,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#42-installation","title":"Godspeed CLI  4.2 Installation ​"}},{"pageContent":"The configuration files under  CODE ``` config/ ``` CODE  directory can have specific naming conventions and load order. Please refer  LINK-> File Name and Load Order https://github.com/node-config/node-config/wiki/Configuration-Files#file-load-order <-LINK  for more information.","metadata":{"source":"scripts/gs.json","line":185,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#43-options","title":"Godspeed CLI  4.3 Options ​"}},{"pageContent":"The static variables as well as their values are defined in yaml files under  CODE ``` config/ ``` CODE  directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:   CODE ```   ├── config    │   ├── default.yaml   ``` CODE                  note   Any configuration which includes secrets or passwords is recommended to be defined using environment variables only. Avoid using static variables for secrets and passwords.","metadata":{"source":"scripts/gs.json","line":186,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#--version--v","title":"Godspeed CLI 4.3 Options ​  --version (-v) ​"}},{"pageContent":"This file contains some predefined variables. Below is a sample file which defines the static variables used in Godspeed.   CODE ```   log_level  :   debug    lang  :   coffee    redact  :     [  ]     # fields to hide. Sample: ['ns', 'req.headers']    server_url  :   https  :  //api.example.com  :  8443/v1/api    httpbin  :     # sample api datasource url        base_url  :   https  :  //httpbin.org   ``` CODE              log_level  is the minimum log level to log. Log messages with a lower limit will not get logged. The default value is 'info'.\nThe available levels are 'fatal', 'error', 'warn', 'info', 'debug', 'trace' or 'silent'.\n lang  is the language used for scripting in the workflows. The default value is 'coffee'.\nThe available values are 'coffee' or 'js'. Refer  LINK-> Coffee/JS scripting /docs/microservices/workflows/#65-use-of-coffeejs-for-scripting <-LINK  for more information.\n redact  is the list of fields, the values for which, you want to hide from the logs. The default value is blank. Refer  LINK-> Logs field masking /docs/telemetry/intro/#log-fields-masking <-LINK  for more information.\n server_url  is the custom server url which you want to use as  CODE ``` Servers ``` CODE  in swagger specs/auto generated documentation. Refer  LINK-> Custom Server URL /docs/microservices/swagger-specs/#52-custom-server-url <-LINK","metadata":{"source":"scripts/gs.json","line":187,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#--help--h","title":"Godspeed CLI 4.3 Options ​  --help (-h) ​"}},{"pageContent":"Hereby is a step by step guide on running your first project. The setup is independent of the OS you are running it on.     info   You can also refer to tutorial on  LINK-> Getting Started with Godspeed https://www.youtube.com/watch?v=eEfqTAPAVlY <-LINK .","metadata":{"source":"scripts/gs.json","line":188,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#44-commands-outside-the-dev-container","title":"Godspeed CLI  4.4 Commands: Outside the dev container ​"}},{"pageContent":"gs_service : The framework code version. During this setup, you will be asked to select the version of gs_service.\n Remote containers/Dev containers : Refer  LINK-> VSCode Remote containers https://code.visualstudio.com/docs/remote/containers <-LINK  for more information.","metadata":{"source":"scripts/gs.json","line":189,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#create","title":"Godspeed CLI 4.4 Commands: Outside the dev container ​  create ​"}},{"pageContent":"Please ensure you have the following in your machine NVM, with Node LTS installed (Currently 16+)  Visual Studio Code LTS, with the following plugins installed:   CODE ``` Remote Containers ``` CODE    CODE ``` Run on Save ``` CODE  Refer  LINK-> Run On Save https://marketplace.visualstudio.com/items?itemName=emeraldwalk.RunOnSave <-LINK    CODE ``` Godspeed Extension Pack ``` CODE     Docker-desktop should be up and running.  On Linux systems, please ensure that docker compose plugin is installed. You can verify it by executing  CODE ``` docker compose version ``` CODE  command. Refer  LINK-> Install Compose plugin https://docs.docker.com/compose/install/linux/ <-LINK  for more information.    Git   Hardware recommendations  \nRAM: 8GB\nHard Disk: SSD     tip    Depending your setup, you may need to run the above command using administrator privileges  On Windows machines, sometimes Docker-desktop doesn't start. Make sure you have WSL installed with Ubuntu 18.04, for Docker to work fine.","metadata":{"source":"scripts/gs.json","line":190,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#update","title":"Godspeed CLI 4.4 Commands: Outside the dev container ​  update ​"}},{"pageContent":"Step1: Install the Godspeed CLI LINK-> ​ #step1-install-the-godspeed-cli <-LINK    CODE ```   npm install -g @mindgrep/godspeed   ``` CODE             Step 2: Setting up a project on your local machine LINK-> ​ #step-2-setting-up-a-project-on-your-local-machine <-LINK      note    If you are creating a new project then follow  LINK-> section 2.1 #21-create-a-new-project <-LINK OR     If you are setting up a project from any existing git repository then follow  LINK-> section 2.2 #22-setting-up-a-project-from-an-existing-git-repository <-LINK    2.1 Create a new project LINK-> ​ #21-create-a-new-project <-LINK    CODE ```   godspeed create my_test_project   ``` CODE             During the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.  By default,  CODE ``` latest ``` CODE  version is selected for gs_service. You should select either  CODE ``` latest ``` CODE  or any highest semantic version available in the list. 2.2 Setting up a project from an existing GIT repository LINK-> ​ #22-setting-up-a-project-from-an-existing-git-repository <-LINK Clone the git repository on your local machine.    CODE ```   cd <your git repo>    godspeed update   ``` CODE             During the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.  By default,  CODE ``` latest ``` CODE  version is selected for gs_service. You should select either  CODE ``` latest ``` CODE  or any highest semantic version available in the list. Step3: cd to your project LINK-> ​ #step3-cd-to-your-project <-LINK    CODE ```   cd <your project directory>     ``` CODE             Step4: Start Visual Studio from the project directory LINK-> ​ #step4-start-visual-studio-from-the-project-directory <-LINK    CODE ```   code .     ``` CODE             Step 5: Open in Dev container LINK-> ​ #step-5-open-in-dev-container <-LINK  Again click on the dev container tray icon. If this is your first time, click on  CODE ``` Open folder in Dev Container ``` CODE  . Else for every other time, click on  CODE ``` Re-open in Dev Container ``` CODE   Step 6: Building the project LINK-> ​ #step-6-building-the-project <-LINK    CODE ```     godspeed build   ``` CODE             Step 7: Start the service for local development in watch mode LINK-> ​ #step-7-start-the-service-for-local-development-in-watch-mode <-LINK    CODE ```     godspeed dev   ``` CODE                  tip   With the dev container running, we have auto watch and auto build enabled when you make changes to your project files. You don't need to run build manually everytime you make changes.","metadata":{"source":"scripts/gs.json","line":191,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#versions","title":"Godspeed CLI 4.4 Commands: Outside the dev container ​  versions ​"}},{"pageContent":"If you have successfully reached here, then it is time to start the development of your project!","metadata":{"source":"scripts/gs.json","line":192,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#version","title":"Godspeed CLI 4.4 Commands: Outside the dev container ​  version ​"}},{"pageContent":"The project root folder gets created in current folder under the  CODE ``` projectName ``` CODE  which is used in  CODE ``` godspeed create ``` CODE  command using godspeed CLI. The project contains two folders:  CODE ``` src/ ``` CODE  and  CODE ``` config/ ``` CODE . Click  LINK-> here /docs/microservices/introduction-cli#create <-LINK  for more information on  CODE ``` godspeed create ``` CODE  command.","metadata":{"source":"scripts/gs.json","line":193,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#help","title":"Godspeed CLI 4.4 Commands: Outside the dev container ​  help ​"}},{"pageContent":"Project Structure with no examples LINK-> ​ #project-structure-with-no-examples <-LINK The project contains blank structure with no examples/templates when it is created using  CODE ``` godspeed create -n ``` CODE  command option. Refer  LINK-> command here /docs/microservices/introduction-cli#options <-LINK  for more information.     CODE ```   .    ├── config    │   ├── custom-environment-variables.yaml    │   ├── default.yaml    │   ├── index.yaml    │   └── telemetry    ├── package.json    └── src        ├── datasources        ├── events        ├── functions        └── mappings   ``` CODE             Project Structure with examples LINK-> ​ #project-structure-with-examples <-LINK The project contains following heirarchy with examples when it is created without using  CODE ``` godspeed create -n ``` CODE  command option. Refer  LINK-> command here /docs/microservices/introduction-cli#create <-LINK  for more information.     CODE ```   .    ├── config    │   ├── custom-environment-variables.yaml    │   ├── default.yaml    │   ├── index.yaml    │   └── telemetry    │       └── index.yaml    ├── package.json    └── src        ├── datasources        │   └── httpbin.yaml        ├── events        │   ├── call_another_workflow.yaml        │   ├── document.yaml        │   ├── helloworld.yaml        │   ├── httpbin_anything.yaml        │   ├── run_tasks_in_parallel.yaml        │   ├── sum.yaml        │   └── switch_case.yaml        ├── functions        │   └── com        │       └── biz        │           ├── call_another_wf.yaml        │           ├── documents        │           │   └── upload_file.yaml        │           ├── helloworld.yaml        │           ├── httpbin_anything.yaml        │           ├── run_tasks_in_parallel.yaml        │           ├── sub_wf.yaml        │           ├── sum.js        │           ├── sum_workflow.yaml        │           └── switch_case.yaml        └── mappings            └── index.yaml   ``` CODE","metadata":{"source":"scripts/gs.json","line":194,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#45-commands-inside-the-dev-container","title":"Godspeed CLI  4.5 Commands: Inside the dev container ​"}},{"pageContent":"Godspeed provides a facility to auto-generate and run test suite using CLI.  Click on  LINK-> auto-generate test suite /docs/microservices/introduction-cli/#gen-testsuite <-LINK  for more information on generating the test suite and  LINK-> run test suite /docs/microservices/introduction-cli/#test <-LINK  for more information on running the test suite.","metadata":{"source":"scripts/gs.json","line":195,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#prisma","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  prisma ​"}},{"pageContent":"You can access autogenerated Swagger API specifications at  CODE ``` <domain name>/api-docs ``` CODE  url.\nFor example,    CODE ```   http://localhost:3000/api-docs   ``` CODE             Godspeed also provides a facility to auto-generate OAS 3 documentation using CLI.","metadata":{"source":"scripts/gs.json","line":196,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#build","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  build ​"}},{"pageContent":"You can generate OAS3 documentation using  LINK->  CODE ``` godspeed gen-api-docs ``` CODE  /docs/microservices/introduction-cli/#gen-api-docs <-LINK  CLI command.","metadata":{"source":"scripts/gs.json","line":197,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#dev","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  dev ​"}},{"pageContent":"You can add custom server URL for API documentation in  LINK-> static configuration /docs/microservices/setup/configuration/static-vars/#defaultyaml <-LINK \nBy adding the custom server url, your autogenerated documentation or swagger specs will have this url set in the  CODE ``` Servers ``` CODE .   CODE ```   server_url: https://api.example.com:8443/v1/api   ``` CODE             For example,\nIMAGE-> /assets/images/swagger_spec-5218946d179677ac711303f8d406b4ee.png <-IMAGE","metadata":{"source":"scripts/gs.json","line":198,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#gen-api-docs","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  gen-api-docs ​"}},{"pageContent":"LINK-> Nodejs https://nodejs.org/en/ <-LINK    LINK-> Express https://expressjs.com/ <-LINK  (HTTP server)   LINK-> Webassembly https://webassembly.org/ <-LINK  (multiple language support in Nodejs)   LINK-> Temporal https://temporal.io/ <-LINK  (microservice orchestration and distributed transactions)","metadata":{"source":"scripts/gs.json","line":199,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#gen-test-suite","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  gen-test-suite ​"}},{"pageContent":"Workflows is where the actual computation and flow orchestration happens. The framework supports a YAML based DSL to write workflows and tasks containing the business logic. These workflows can be attached to the events as their handlers, or called from within another workflow. The framework exposes  LINK-> CoffeeScript https://coffeescript.org/ <-LINK /JS based expressions  LINK-> for evaluation of dynamic variables or transformation /docs/microservices/workflows/#65-use-of-coffeejs-for-scripting <-LINK  of data from  CODE ``` inputs ``` CODE  of event, or  CODE ``` outputs ``` CODE  of previous tasks.  Default language for transformations (coffee/js) can be configured in  LINK-> configuration /docs/microservices/setup/configuration/static-vars/#defaultyaml <-LINK","metadata":{"source":"scripts/gs.json","line":200,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#gen-crud-api","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  gen-crud-api ​"}},{"pageContent":"A workflow has the following attributes  summary  - the title   description  - more details   id  - Recommended for better logging visibility   on_error  - Default error handling if any tasks fails.    tasks  - the tasks (workflows or sub-workflows) to be run in series (sequence, or one by one). The tasks invoke other workflows written in YAML or JS/TS. Other languages support is planned.    CODE ```   summary  :   Hello world    description  :   Hello world example which invokes the com.gs.return workflow    id  :   hello_world   # needed for better logging visibility    on_error  :        continue  :     false        response  :          success  :     false          code  :     500          data  :     \"Default error\"    tasks  :     # tasks to be run in sequence (default is sequence)        -     id  :   step1   ## id of this task. Its output will be accessible        # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.          fn  :   com.gs.return          args  :     'Hello World!'     # com.gs.return takes its return value as `args`. Hence the args key.   ``` CODE","metadata":{"source":"scripts/gs.json","line":201,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#test","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  test ​"}},{"pageContent":"A workflow has one or more tasks associated with it.\nA task has the following attributes   id  - Needed for better logging visibility.  It is compulsory for a task.  Importantly, this is also used to access the output of this task in subsequent tasks in the  CODE ``` outputs.{task_id} ``` CODE  path, as shown in  LINK-> example below #define-language-at-workflow-level <-LINK .     summary  - the title     description  - more details     fn  - The handler to be run in this task. It can be one of the  LINK-> framework functions #66-inbuilt-functions <-LINK ,  LINK-> control functions #666-comgsseries <-LINK  (like parallel, sequential, switch),  LINK-> developer written functions #67-developer-written-functions <-LINK , or another workflow.   You can also use scripting in dynamic evaluation of a function name as given in below example. Refer  LINK-> Coffee/JS scripting #65-use-of-coffeejs-for-scripting <-LINK  for more information.     CODE ```   summary  :   Call an API and transform the    tasks  :          -     id  :   transform_fn_step1            description  :   find fn name            fn  :   com.gs.transform            args  :     |            <js%              if (inputs.body.fn == 'sum') {                return 'com.jfs.sum_workflow'              } else {                return 'com.jfs.helloworld'              }            %>          -     id  :   call_fn_step2            description  :   call fn returned in transform_fn_step1            fn  :   <% outputs.transform_fn_step1.data %  >            args  :              name  :   <% inputs.body.name %  >   ``` CODE                   args  - Every handler  CODE ``` fn ``` CODE  has its own argument structure, which is kept in the  CODE ``` args ``` CODE  key. For example,     CODE ```       id  :   httpbin_step1        fn  :   com.gs.http        args  :          datasource  :   httpbin          config  :            url     :   /v1/loan  -  application/<% inputs.params.lender_loan_application_id %  >  /agreement/esign/initiate            method  :   post            headers  :   <% inputs.headers %  >   ``` CODE                  on_error  - What to do if this task fails?     CODE ```       on_error  :     #You can find sample usage of this in the examples below. Just search on_error in this page.          continue  :     false     # Whether the next task should be executed, in case this task fails. by default continue is true.          response  :   <%Coffee/JS expression%  >     |   String   # If specified, the output of `response` is returned as the output of this task. If not specified, the error output is the default output of the failed task.          tasks  :     # If specified, the tasks are executed in series/sequence. The output of the last task in these tasks is the default output of the failed task.            -     id  :   transform_error              fn  :   com.gs.transform              args  :   <% outputs.httpbin_step1 %  >              -     id  :   publish_error              fn  :   com.gs.kafka              args  :                datasource  :   kafka1                data  :                  value  :   <% outputs.transform_error.message %  >                config  :                  topic  :   publish  -  producer1   ``` CODE               The only exception to this is  LINK-> control functions #666-comgsseries <-LINK  like series, parallel, switch, which don't take the  CODE ``` args ``` CODE , for the sake of more readability.     retry  - Retry logic helps to handle transient failures, internal server errors, and network errors with support for constant, exponential and random types. Currently applied only for  CODE ``` com.gs.http ``` CODE  workflow.     CODE ```       retry  :          max_attempts  :     5          type  :   constant          interval  :   PT15m   ``` CODE                  CODE ```       retry  :          max_attempts  :     5          type  :   exponential          interval  :   PT15s   ``` CODE                  CODE ```       retry  :          max_attempts  :     5          type  :   random          min_interval  :   PT5s          max_interval  :   PT10s   ``` CODE","metadata":{"source":"scripts/gs.json","line":202,"url":"https://docs.godspeed.systems/docs/microservices/introduction-cli#help-1","title":"Godspeed CLI 4.5 Commands: Inside the dev container ​  help ​"}},{"pageContent":"The output of every task and function can be expected in the following format within other task  success : true/false. Default value is  CODE ``` true ``` CODE    code :  standard HTTP response codes[1xx, 2xx, 3xx, 4xx, 5xx] Default value is 200   message : any string explaining the response. Optional   data : the actual data returned from the task/function. Optional Note If a task or external JS function returns a value which is not in this JSON structure then framework assumes the output is the data itself & wraps it in this JSON structure with default values.  The output of any previously executed task is accesible in following manner  CODE ``` outputs.step1.code ``` CODE  Example of multiple task with arguments LINK-> ​ #example-of-multiple-task-with-arguments <-LINK    CODE ```   summary  :   Workflow with switch  -  case and transform task    id  :   example_switch_functionality_id    description  :     |      Run two tasks in series. Both take different arguments. First one is switch case task.      Second is transform task which consumes the output of step1 and shapes the final output of this workflow.    tasks  :     # tasks to be run in sequence (default is sequence)        -     id  :   step1_switch   ## id of this switch task. Its output will be accessible          # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.          fn  :   com.gs.switch   # Switch workflow takes `value` and `cases` as arguments. The cases object specifies another task for every case.          value  :   <%inputs.body.condition%  >     # Evaluation of dynamic values happens via <% %>          cases  :            FIRST  :              id  :   1st              fn  :   com.gs.return              args  :     \"'case - 1'\"            SECOND  :              id  :   2nd              fn  :   com.gs.return              args  :     \"'case - 2'\"            THIRD  :              id  :   3rd              fn  :   com.gs.return              args  :     \"'case - 3'\"          defaults  :            id  :   default            fn  :   com.gs.return            args  :   <%inputs.body.default_return_val%  >     #coffee/js script for dyanmic evaluation. Wrapped in <% %>. Same as that used elsewhere in workflows for dynamic calculations and variable substitutions. For ex. as used in com.gs.transform and com.gs.return        -     id  :   step2          fn  :   com.gs.transform          args  :     |     #coffee for dyanmic evaluation. Wrapped in <% %>            <coffee%   {                code  :     200  ,                      data  :   outputs  [  '1st'  ]              }   %  >   ``` CODE","metadata":{"source":"scripts/gs.json","line":203,"url":"https://docs.godspeed.systems/docs/microservices/mappings","title":"Mappings  Mappings"}},{"pageContent":"All the workflows and functions are to be kept in the  CODE ``` src/functions ``` CODE  folder. Their directory tree path, followed by the file name becomes the workflow's fully qualified name or id, by which it can be referenced in the events or within other workflows. The JS function shown below will be available in workflows under the F.Q.N.  CODE ``` com.biz.custom_function ``` CODE . Similarly,  CODE ``` com.biz.create_hdfc_account ``` CODE ,  CODE ``` com.biz.create_parallel ``` CODE  etc. are accessible as handlers from within other  LINK-> workflow tasks #62-the-tasks-within-workflows <-LINK  or events.   IMAGE-> /assets/images/function_folder-361e18f2edd1c48ad8b4c205bdd3e45b.jpeg <-IMAGE","metadata":{"source":"scripts/gs.json","line":204,"url":"https://docs.godspeed.systems/docs/microservices/mappings#101-project-structure","title":"Mappings  10.1 Project structure ​"}},{"pageContent":"A workflow task references and invokes other workflows written in either YAML or JS/TS, via the  CODE ``` fn ``` CODE  key. In future, other languages will also be supported.\nAn  LINK-> event definition /docs/microservices/events#example-spec-for-http-event <-LINK  references the handler yaml workflows by their fully qualified name, via the same  CODE ``` fn ``` CODE  key.","metadata":{"source":"scripts/gs.json","line":205,"url":"https://docs.godspeed.systems/docs/microservices/mappings#102-sample-mappings","title":"Mappings  10.2 Sample mappings ​"}},{"pageContent":"The framework provides coffee/js for Transformations in  LINK->  CODE ``` com.gs.transform ``` CODE  #665-comgstransform <-LINK  and  LINK->  CODE ``` com.gs.return ``` CODE  #6611-comgsreturn <-LINK   Dynamic evaluation or workflow or task variables, event variables, datasource variables. You will find its code in <% %> within various examples in this page below.Define language at global level LINK-> ​ #define-language-at-global-level <-LINK Default language for transformations (coffee/js) is configured in  LINK-> static configuration /docs/microservices/setup/configuration/static-vars/#defaultyaml <-LINK Define language at workflow level LINK-> ​ #define-language-at-workflow-level <-LINK Global configuration for language is overridden by defining specific language inside <coffee/js% %>. For example,   CODE ```       - id: httpbinCof_step2          fn: com.gs.transform          args: |              <coffee% if outputs.httpbinCof_step1.data.json.code == 200 then {                  code: 200,                  success: true,                  data: outputs.httpbinCof_step1.data.json,                  headers: outputs.httpbinCof_step1.data.headers              } else {                  code: 500,                  success: false,                  message: 'error in httpbinCof_step1'              } %>   ``` CODE                CODE ```       - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key          description: upload documents          fn: com.gs.http          args:            datasource: httpbin            params:            data: |              <js% {                [inputs.body.entity_type + 'id']: inputs.body.entity_id,                _.omit(inputs.body, ['entity_type', 'entity_id'])}              %>   ``` CODE             Built-in Javascript modules LINK-> ​ #built-in-javascript-modules <-LINK You can use build-in javascript modules in inline scripting. Only synchronous methods of build-in modules are allowed in inline scripting. For example,   CODE ```   summary  :   upload s3    tasks  :        -     id  :   step1          description  :   upload s3          fn  :   com.gs.aws          args  :            datasource  :   aws_s3            params  :      # fs is used directly in scripting in Body              -     Bucket  :     'godspeedbucket'                Key  :     'file4.yml'                Body  :   <% fs.createReadStream(inputs.files  [  0  ]  .tempFilePath) %  >            config  :              service  :   S3              method  :   putObject   ``` CODE","metadata":{"source":"scripts/gs.json","line":206,"url":"https://docs.godspeed.systems/docs/microservices/mappings#103-use-mappings-constants-in-other-mapping-files","title":"Mappings  10.3 Use mappings constants in other mapping files ​"}},{"pageContent":"The framework provides the following inbuilt functions7.6.1 com.gs.http LINK-> ​ #761-comgshttp <-LINK Send HTTP events to other APIs in Axios compatible format. Example 1    CODE ```       summary  :   agreement esign        id  :   agreement_esign        tasks  :          -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key            description  :   agreement esign            fn  :   com.gs.http            params  :     # query params to be sent in the request              id  :     123            args  :              datasource  :   httpbin              config  :                url     :   /v1/loan  -  application/<% inputs.params.lender_loan_application_id %  >  /agreement/esign/initiate                method  :   post              retry  :              max_attempts  :     5              type  :   constant              interval  :   PT15M              on_error  :              continue  :     true            -     id  :   step2            fn  :   com.gs.transform            args  :     |              <%if outputs.step1.data.success then outputs.step1.data else {                  code: outputs.step1.code,                  success : false,                  data: {                    error_data: outputs.step1.data['error'],                    uuid: outputs.step1.data.uuid,                    status_code_error: outputs.step1.data.status_code_error,                    event: outputs.step1.data.event                  }              }%>   ``` CODE              Example 2    CODE ```       summary  :   upload documents        id  :   upload_documents        tasks  :          -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key            description  :   upload documents            fn  :   com.gs.http            args  :              datasource  :   httpbin              params  :              data  :     |              <js% {                [inputs.body.entity_type + 'id']: inputs.body.entity_id,                _.omit(inputs.body, ['entity_type', 'entity_id'])}              %>              file_key  :   files              files  :   <% inputs.files %  >              config  :                url     :   /v1/documents                method  :   post              retry  :              max_attempts  :     5              type  :   constant              interval  :   PT15M              on_error  :              continue  :     false              response  :   <%'Some error happened in saving' + inputs.body.entity_type%  >            -     id  :   step2            fn  :   com.gs.transform            args  :   <% delete outputs.step1.headers; outputs.step1 %  >     ``` CODE             7.6.2 com.gs.kafka LINK-> ​ #762-comgskafka <-LINK Publish events on Kafka.   CODE ```       summary  :   Publishing incoming event data to a Kafka topic        id  :   push_to_kafka        tasks  :          -     id  :   step1            summary  :   Publish an event with input event's data  ,   adding to_process = true            fn  :   com.gs.kafka            args  :     # similar to Axios format              datasource  :   kafka1              config  :                method  :   publish                topic  :   kyc_initiate_recieved                group_id  :   kyc_domain              data  :     # Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.                value  :   <% inputs %  >     # Your message content. Evaluation of dynamic values happens via <% %>. The type of scripting is coffee.                key  :     # Optional - Used for partitioning.                partition  :     # Optional - Which partition to send the message to.                timestamp  :     # Optional - The timestamp of when the message was created.                headers  :     # Optional - Metadata to associate with your message.   ``` CODE              Refer  LINK-> https://kafka.js.org/docs/producing#message-structure https://kafka.js.org/docs/producing#message-structure <-LINK  for information on data attributes. 7.6.3 com.gs.datastore LINK-> ​ #763-comgsdatastore <-LINK The datastore function allows CRUD access to any supported  LINK-> datastore /docs/microservices/datasources/datastore <-LINK  in a format extending  LINK-> Prisma API http://prisma.io <-LINK .   CODE ```   summary  :   Create and read data    tasks  :        -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key          description  :   Create entity from REST input data (POST request)          fn  :   com.gs.datastore          args  :            datasource  :   mongo   # Which ds to use.            data  :   <% inputs.body +   {  extra_field  :   its_value  }   %  >            config  :              method  :   <% inputs.params.entity_type %  >  .create        -     id  :   step2   # the response of this will be accessible within the parent step key, under the step1 sub key          description  :   test again          fn  :   com.gs.datastore          args  :            datasource  :   mongo   # Adding this knows which ds/model we are talking about here.            config  :     # Similar approach as Axios              method  :   <% inputs.params.entity_type %  >  .findMany     ``` CODE             7.6.4 com.gs.elasticgraph LINK-> ​ #764-comgselasticgraph <-LINK The elasticgraph function allows CRUD access to elasticsearch  LINK-> datastore /docs/microservices/datasources/elasticgraph <-LINK .   CODE ```   summary  :   eg    tasks  :        -     id  :   create_entity1          description  :   create_entity1          fn  :   com.gs.elasticgraph          args  :            datasource  :   elasticgraph1            data  :              index  :   <% inputs.params.entity_type + 's' %  >              type  :     '_doc'              body  :   <% inputs.body %  >            config  :              method  :   index          on_error  :            continue  :     false   ``` CODE             7.6.5 com.gs.transform LINK-> ​ #765-comgstransform <-LINK This function allows to transform data from one format to another using coffee/js scripting.   CODE ```       summary  :   Parallel Multiplexing create loan for hdfc api calls        tasks  :          -     id  :   parallel            fn  :   com.gs.parallel            tasks  :              -     id  :   1st                fn  :   com.gs.return                args  :     |                'parallel task1'                -     id  :   2nd                fn  :   com.gs.return                args  :     |                'parallel task2'          -     id  :   step2            fn  :   com.gs.transform            args  :              code  :     200              data  :   <% outputs.step1_switch.data %  >   ``` CODE             7.6.6 com.gs.series LINK-> ​ #766-comgsseries <-LINK      control flow function   Executes the tasks in series.  By default every top level workflow executes its task in series. But when invoking subworkflows if you need, you can explicitly use series workflow. Its syntax is same as parallel.   CODE ```       summary  :   Parallel Multiplexing create loan for hdfc api calls        tasks  :          -     id  :   parallel            fn  :   com.gs.series            tasks  :              -     id  :   1st                fn  :   com.gs.return                args  :     |                'parallel task1'                -     id  :   2nd                fn  :   com.gs.return                args  :     |                'parallel task2'          -     id  :   step2            fn  :   com.gs.transform            args  :     |            <coffee% {              code: 200,              data: outputs['1st']            } %>   ``` CODE             7.6.7 com.gs.parallel LINK-> ​ #767-comgsparallel <-LINK      control flow function   Executes the child tasks in parallel.  Syntax is same as  LINK-> com.gs.series #666-comgsseries <-LINK    CODE ```       summary  :   Parallel Multiplexing create loan for hdfc api calls        tasks  :          -     id  :   parallel            fn  :   com.gs.parallel            tasks  :              -     id  :   1st                fn  :   com.gs.return                args  :     |                'parallel task1'                -     id  :   2nd                fn  :   com.gs.return                args  :     |                'parallel task2'                -     id  :   3rd                fn  :   com.gs.return                args  :     |                'parallel task3'            -     id  :   step2            fn  :   com.gs.transform            args  :     |            <coffee% {            code: 200,            data: outputs['1st']            } %>   ``` CODE             7.6.8 com.gs.switch LINK-> ​ #768-comgsswitch <-LINK      control flow function   The classic switch-case flow execution  The args of switch-flow are  CODE ``` value ``` CODE  and  CODE ``` cases ``` CODE .  CODE ``` value ``` CODE  takes a coffee/js expression to be evaluated during runtime. Every case has a task associated with it. The task can invoke another function or a workflow.   CODE ```       summary  :   create loan application for lender        tasks  :            -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key              description  :   create account in the bank              fn  :   com.gs.switch              value  :   <%inputs.headers  [  'lender'  ]  %  >              cases  :                httpbin  :                  -     id  :   1st                    fn  :   com.biz.loan_application.httpbin_create_loan_application                    args  :   <%inputs%  >     ``` CODE             7.6.9 com.gs.each_sequential LINK-> ​ #769-comgseach_sequential <-LINK      control flow function   The classic for-each flow execution  The args is list of values in  CODE ``` value ``` CODE  field along with associated tasks. For each value in  CODE ``` value ``` CODE  tasks are executed sequentially. The final output each_sequential is the array of status of the last executed task of each iteration.   CODE ```       summary  :   For each sample        description  :   Here we transform the response of for loop        tasks  :          -     id  :   each_sequential_step1            description  :   for each            fn  :   com.gs.each_sequential            value  :     [  1  ,     2  ,     3  ,     4  ]            tasks  :              -     id  :   each_task1                fn  :   com.gs.transform                args  :   <% 'each_task1 ' + task_value %  >          -     id  :   each_sequential_step2            description  :   return the response            fn  :   com.gs.transform            args  :   <% outputs.each_sequential_step1 %  >   ``` CODE              on_error handling \nYou can add on_error at task level as well as at each_sequential loop level.See the below example, If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the loop else it continues the next tasks.  If all the tasks are failed in loop then the control goes to on_error defined at loop level.      note   on_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.     CODE ```       summary  :   For each sample        description  :   Here we transform the response of for loop        tasks  :          -     id  :   each_sequential_step1            description  :   for each            fn  :   com.gs.each_sequential            value  :     [  1  ,     2  ,     3  ,     4  ]            tasks  :              -     id  :   each_task1                fn  :   com.gs.transform                args  :   <% 'each_task1 ' + task_value %  >                on_error  :     # on_error at task level                  continue  :     false                  response  :   <%Coffee/JS expression%  >     |   String            on_error  :     # on_error at loop level              continue  :     true              response  :   <%Coffee/JS expression%  >     |   String          -     id  :   each_sequential_step2            description  :   return the response            fn  :   com.gs.transform            args  :   <% outputs.each_sequential_step1 %  >   ``` CODE             7.6.10 com.gs.each_parallel LINK-> ​ #7610-comgseach_parallel <-LINK The args is list of values in  CODE ``` value ``` CODE  field along with associated tasks. For each value in  CODE ``` value ``` CODE  tasks are executed in parallel. The final output each_parallel is the array of status of the last executed task of each iteration.   CODE ```       summary  :   For each sample        description  :   Here we transform the response of for loop        tasks  :          -     id  :   each_parallel_step1            description  :   for each            fn  :   com.gs.each_parallel            value  :     [  1  ,     2  ,     3  ,     4  ]            tasks  :              -     id  :   each_task1                fn  :   com.gs.transform                args  :   <% 'each_task1 ' + task_value %  >          -     id  :   each_parallel_step2            description  :   return the response            fn  :   com.gs.transform            args  :   <% outputs.each_parallel_step1 %  >   ``` CODE              on_error handling \nYou can add on_error at task level as well as at each_parallel loop level.See the below example, If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the execution for the next tasks in  CODE ``` tasks ``` CODE  for current  CODE ``` task_value ``` CODE  in  CODE ``` value ``` CODE  list. For example, in the below workflow, if  CODE ``` each_task1 ``` CODE  step of task_value 1 gets failed then  CODE ``` each_task2 ``` CODE  will not get executed on continue false.  If all the tasks are failed in loop then the control goes to on_error defined at loop level.      note   on_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.     CODE ```       summary  :   For each sample        description  :   Here we transform the response of for loop        tasks  :          -     id  :   each_parallel_step1            description  :   for each            fn  :   com.gs.each_parallel            value  :     [  1  ,     2  ,     3  ,     4  ]            tasks  :              -     id  :   each_task1                fn  :   com.gs.transform                args  :   <% 'each_task1 ' + task_value %  >                on_error  :     # on_error at task level                  continue  :     false                  response  :   <%Coffee/JS expression%  >     |   String              -     id  :   each_task2                fn  :   com.gs.transform                args  :   <% 'each_task2 ' + task_value %  >            on_error  :     # on_error at loop level              continue  :     true              response  :   <%Coffee/JS expression%  >     |   String          -     id  :   each_parallel_step2            description  :   return the response            fn  :   com.gs.transform            args  :   <% outputs.each_parallel_step1 %  >   ``` CODE             7.6.11 com.gs.return LINK-> ​ #7611-comgsreturn <-LINK      return statement   The classic return statement  It returns from the current function to the function caller. The function stops executing when the return statement is called.   CODE ```       summary  :   Multiplexing create loan for hdfc api calls        id  :   helloworld        tasks  :          -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key            description  :   create account in the bank            fn  :   com.gs.return            args  :     |            <coffee% 'Hello ' + inputs.query.name %>   ``` CODE             7.6.12 com.gs.log LINK-> ​ #7612-comgslog <-LINK It logs the intermediate inputs/outputs during the workflow execution in pino logging format. The args are  CODE ``` level ``` CODE  and  CODE ``` data ``` CODE .  CODE ``` level ``` CODE  takes any value from the  LINK-> Pino log levels https://github.com/pinojs/pino/blob/master/docs/api.md#options <-LINK  and  CODE ``` data ``` CODE  takes a coffee/js expression to be evaluated during runtime or anything (like string, number, etc.) which you want to get logged during the workflow execution.   CODE ```       summary  :   Summing x + y        description  :   Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params  !        tasks  :          -     id  :   sum_step1            description  :   add two numbers            fn  :   com.jfs.sum            args  :              x  :     1              y  :     2          -     id  :   sum_step2            description  :   log the output in logs            fn  :   com.gs.log            args  :              level  :   info   # log levels: info, debug, error, warn, fatal, silent, trace              data  :   <% outputs.sum_step1 %  >          -     id  :   sum_step3            description  :   return the response            fn  :   com.gs.transform            args  :   <% outputs.sum_step1 %  >   ``` CODE             7.6.13 com.gs.dynamic_fn LINK-> ​ #7613-comgsdynamic_fn <-LINK It executes the workflow whose name is dynamically returned as the output of its task list. The tasks of this function should return a string output which will be the name of the workflow to be executed.  Event DSL     CODE ```   '/sum.http.get'  :        fn  :   com.jfs.sum_dynamic        summary  :   A workflow to sum x and y        description  :   This workflow sums two integers        params  :          -     name  :   x            in  :   query            required  :     true            allow_empty_value  :     false            schema  :              type  :   string            -     name  :   y            in  :   query            required  :     true            allow_empty_value  :     false            schema  :              type  :   string   ``` CODE               com.jfs.sum_dynamic.yaml     CODE ```   summary  :   Dynamic function to call com.jfs.sum_workflow.yaml    description  :   This function dynamically is taking workflow name and executing it at the runtime.    tasks  :        -     id  :   sum_dynamic_step1          description  :   add two numbers          fn  :   com.gs.dynamic_fn          tasks  :     # the tasks should return a string value which will the name of the workflow to be executed.          # For example, in below task list, final workflow name will be `com.jfs.sum_workflow`            -     id  :   get_wf_name_step1              fn  :   com.gs.transform              args  :   com.jfs.sum_workflow            -     id  :   get_wf_name_step2   # this task is returning a workflow name dynamically              fn  :   com.gs.transform              args  :   <% outputs.get_wf_name_step1.data %  >   ``` CODE               com.jfs.sum_workflow.yaml     CODE ```   summary  :   Summing x + y    description  :   Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params  !    tasks  :        -     id  :   sum_step1          description  :   add two numbers          fn  :   com.gs.return          args  :     |         <%           +inputs.query.x + +inputs.query.y         %>   ``` CODE             7.6.14 com.gs.aws LINK-> ​ #7614-comgsaws <-LINK Interacts with AWS to use its various services and methods.  CODE ``` params ``` CODE  is the list of params to the AWS service methods. We are using AWS v3 style services. Please refer  LINK-> AWS S3 https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/clients/client-s3/classes/s3.html <-LINK  for AWS S3 methods.    CODE ```   summary  :   upload s3    tasks  :        -     id  :   step1          description  :   upload s3          fn  :   com.gs.aws          args  :            datasource  :   aws_s3            params  :              -     Bucket  :     'godspeedbucket'                Key  :     'file4.yml'                Body  :   <% fs.createReadStream(inputs.files  [  0  ]  .tempFilePath) %  >            config  :              service  :   S3              method  :   putObject   ``` CODE             7.6.15 com.gs.redis LINK-> ​ #7615-comgsredis <-LINK Developer can read / write to redis datasource using standard redis client functions.   CODE ```   summary  :   demonstration of redis functions    id  :   accessing_redis    tasks  :        -     id  :   store_value_to_key          description  :   Writing user info in redis with key user          fn  :   com.gs.redis          args  :            config  :              method  :   set            data  :              key  :   user              value  :   Adam        -     id  :   retrieve_user_set_in_previous_task          description  :   Retriving user from redis          fn  :   com.gs.redis          args  :            config  :              method  :   get            data  :              key  :   user   ``` CODE             7.6.16 com.gs.if, com.gs.elif, com.gs.else LINK-> ​ #7616-comgsif-comgselif-comgselse <-LINK      control flow function   The classic if-else flow execution  The args are  CODE ``` condition ``` CODE  and  CODE ``` tasks ``` CODE .  CODE ``` condition ``` CODE  takes a coffee/js expression to be evaluated during runtime. The  CODE ``` tasks ``` CODE  can invoke another function or a workflow.   CODE ```   summary  :   Returning hello world    tasks  :        -     id  :   if          fn  :   com.gs.if          condition  :   <% inputs.query.status == 'Hello' %  >          tasks  :            -     id  :   step1              description  :   Return hello world              fn  :   com.gs.return              args  :     'Hello!'          -     id  :   elif1          description  :   Return hello world          fn  :   com.gs.elif          condition  :   <% inputs.query.status == 'Hell' %  >          tasks  :            -     id  :   step2              description  :   Return hello world              fn  :   com.gs.return              args  :     'Hell!'          -     id  :   elif2          description  :   Return hello world          fn  :   com.gs.elif          condition  :   <% inputs.query.status == 'Hel' %  >          tasks  :            -     id  :   step3              description  :   Return hello world              fn  :   com.gs.return              args  :     'Hel!'          -     id  :   else          description  :   Return hello world          fn  :   com.gs.else          tasks  :            -     id  :   step4              description  :   Return hello world              fn  :   com.gs.return              args  :     'Hi!'   ``` CODE","metadata":{"source":"scripts/gs.json","line":207,"url":"https://docs.godspeed.systems/docs/microservices/plugins","title":"Plugins  Plugins"}},{"pageContent":"Developer can write functions in JS/TS and  LINK-> kept in src/functions folder #63-location-and-fully-qualified-name-id-of-workflows-and-functions <-LINK  at a path, which becomes its fully qualified name. Other languages support is planned. Once it is written, the function can be invoked from within any workflow or sub-workflow, with its fully qualified name and argument structure.IMAGE-> /assets/images/function_folder-361e18f2edd1c48ad8b4c205bdd3e45b.jpeg <-IMAGE   CODE ```       summary  :   Custom workflow invocation        id  :   custom_function        tasks  :          -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key            description  :   custom_fn            fn  :   com.biz.custom_function   # Can be JS/TS workflow in src/com/xyz directory with filename being custom.{js|ts}            args  :              arg1  :     'hello world'              arg2  :     'hello again'   ``` CODE","metadata":{"source":"scripts/gs.json","line":208,"url":"https://docs.godspeed.systems/docs/microservices/plugins#111-project-structure","title":"Plugins  11.1 Project structure ​"}},{"pageContent":"Headers defined at workflow level are applicable for a single workflow only. You can find the  LINK-> example usage here /docs/microservices/workflows#62-the-tasks-within-workflows <-LINK","metadata":{"source":"scripts/gs.json","line":209,"url":"https://docs.godspeed.systems/docs/microservices/plugins#112-sample-plugins","title":"Plugins  11.2 Sample plugins ​"}},{"pageContent":"The framework provides file upload feature to upload files. Here is the sample event and workflow spec to upload any file. Event Spec    CODE ```   /document.http.post  :        fn  :   com.biz.documents.upload_file        id  :     '/sendDocuments'        summary  :   upload document        description  :   upload document on httpbin        data  :          schema  :            body  :              required  :     false              content  :                multipart/form-data  :                  schema  :                    type  :   object                    properties  :                      fileName  :                        type  :   string                        format  :   binary   ``` CODE             7.9.1 Workflow spec to upload files with same file key LINK-> ​ #791-workflow-spec-to-upload-files-with-same-file-key <-LINK    CODE ```       summary  :   upload file        id  :   upload_file        tasks  :          -     id  :   step1   # the response of this will be accessible within the parent step key, under the step1 sub key            description  :   upload docfileuments            fn  :   com.gs.http            args  :              datasource  :   httpbin              params  :              file_key  :   files              files  :   <% inputs.files %  >              config  :                url     :   /v1/documents                method  :   post              retry  :              max_attempts  :     5              type  :   constant              interval  :   PT15M   ``` CODE                  Note   If file_key is same for all the files then you can use above workflow DSL. In case you have different file_keys for multiple files then you can directly use  CODE ``` <% inputs.file_obj %> ``` CODE  as given in the below section 6.9.2  7.9.2 Workflow spec to upload multiple files with different file keys LINK-> ​ #792-workflow-spec-to-upload-multiple-files-with-different-file-keys <-LINK    CODE ```   summary  :   upload multiple documents    tasks  :          -     id  :   upload_multiple_files_step1            description  :   upload multiple documents            fn  :   com.gs.http            args  :              datasource  :   httpbin              data  :   <% inputs.body %  >              files  :   <% inputs.file_obj %  >              config  :                url     :   /anything                method  :   post   ``` CODE             7.9.3 Workflow spec to upload file directly from URL LINK-> ​ #793-workflow-spec-to-upload-file-directly-from-url <-LINK    CODE ```   summary  :   upload document from url    tasks  :        -     id  :   upload_url_step1          description  :   upload document from url          fn  :   com.gs.http          args  :            datasource  :   httpbin            data  :   <% inputs.body %  >            files  :              sample  :                url  :   https  :  //s3.ap  -  south  -  1.amazonaws.com/sample.pdf                method  :   get            config  :              url     :   /anything              method  :   post              headers  :                   Content-Type  :     'multipart/form-data'   ``` CODE","metadata":{"source":"scripts/gs.json","line":210,"url":"https://docs.godspeed.systems/docs/microservices/plugins#113-sample-workflow-using-plugins","title":"Plugins  11.3 Sample workflow using plugins ​"}},{"pageContent":"CODE ```      Content Type: application/json ; charset= utf- 8       Method: POST       URL: /api/notification/v1/publish/sendEmail   ``` CODE","metadata":{"source":"scripts/gs.json","line":211,"url":"https://docs.godspeed.systems/docs/microservices/scaffolding","title":"Scaffolding  Scaffolding"}},{"pageContent":"CODE ```        recipientsTo      STRING         message           STRING         from              STRING         Subject           STRING     ``` CODE","metadata":{"source":"scripts/gs.json","line":212,"url":"https://docs.godspeed.systems/docs/microservices/setup/auto-watch","title":"Auto watch and build  Auto watch and build"}},{"pageContent":"CODE ```      Status_Code: INTEGER   ``` CODE","metadata":{"source":"scripts/gs.json","line":213,"url":"https://docs.godspeed.systems/docs/microservices/setup/configuration/env-vars","title":"Environment variables  Environment variables"}},{"pageContent":"CODE ```      Content Type: application/json ; charset= utf- 8       Method: POST       URL: URL: /api/notification/v1/publish/sendBulkEmail   ``` CODE","metadata":{"source":"scripts/gs.json","line":214,"url":"https://docs.godspeed.systems/docs/microservices/setup/configuration/env-vars#custom-environment-variablesyaml","title":"Environment variables  custom-environment-variables.yaml ​"}},{"pageContent":"CODE ```        recipientsToList      [STRING, STRING...]       message                STRING       from                   STRING       Subject                STRING     ``` CODE","metadata":{"source":"scripts/gs.json","line":215,"url":"https://docs.godspeed.systems/docs/microservices/setup/configuration/intro","title":"3.3.1 Introduction  3.3.1 Introduction"}},{"pageContent":"CODE ```      Status_Code: INTEGER   ``` CODE","metadata":{"source":"scripts/gs.json","line":216,"url":"https://docs.godspeed.systems/docs/microservices/setup/configuration/intro#file-naming-and-load-order","title":"3.3.1 Introduction  File Naming and Load Order ​"}},{"pageContent":"CODE ```      Content Type: application/json ; charset= utf- 8       Method: POST       URL: URL: /api/notification/v1/publish/sendBulkTemplateEmail   ``` CODE","metadata":{"source":"scripts/gs.json","line":217,"url":"https://docs.godspeed.systems/docs/microservices/setup/configuration/static-vars","title":"Static variables  Static variables"}},{"pageContent":"CODE ```      recipientsToList      [STRING, STRING...]       templateId             INTEGER       templateParam          [{“placeholder1” : “value1”}, {“placeholder2” : “value2”} ]       from                   STRING       Subject                STRING     ``` CODE","metadata":{"source":"scripts/gs.json","line":218,"url":"https://docs.godspeed.systems/docs/microservices/setup/configuration/static-vars#defaultyaml","title":"Static variables  default.yaml ​"}},{"pageContent":"CODE ```      Status_Code: INTEGER   ``` CODE","metadata":{"source":"scripts/gs.json","line":219,"url":"https://docs.godspeed.systems/docs/microservices/setup/getting-started","title":"Getting started  Getting started"}},{"pageContent":"CODE ```      Content Type: application/json ; charset= utf- 8       Method: POST       URL: URL: /api/notification/v1/publish/sendSMS   ``` CODE","metadata":{"source":"scripts/gs.json","line":220,"url":"https://docs.godspeed.systems/docs/microservices/setup/getting-started#311-glossary","title":"Getting started  3.1.1 Glossary ​"}},{"pageContent":"CODE ```      recipientsTo           INTEGER       message                STRING       from                   INTEGER   ``` CODE","metadata":{"source":"scripts/gs.json","line":221,"url":"https://docs.godspeed.systems/docs/microservices/setup/getting-started#312-pre-requisites","title":"Getting started  3.1.2 Pre-requisites ​"}},{"pageContent":"CODE ```      Status_Code: INTEGER   ``` CODE             Here recipientsTo and from must be valid mobile numbers. Message conent and length should meet the criteria of SMS.","metadata":{"source":"scripts/gs.json","line":222,"url":"https://docs.godspeed.systems/docs/microservices/setup/getting-started#313-steps-to-get-started","title":"Getting started  3.1.3 Steps to get started ​"}},{"pageContent":"CODE ```      Content Type: application/json ; charset= utf- 8       Method: POST       URL: URL: /api/notification/v1/publish/sendBulkSMS   ``` CODE","metadata":{"source":"scripts/gs.json","line":223,"url":"https://docs.godspeed.systems/docs/microservices/setup/getting-started#314-time-to-start-the-development","title":"Getting started  3.1.4 Time to start the development ​"}},{"pageContent":"CODE ```      recipientsToList       [INTEGER, INTEGER]       message                STRING       from                   INTEGER   ``` CODE","metadata":{"source":"scripts/gs.json","line":224,"url":"https://docs.godspeed.systems/docs/microservices/setup/scaffolding","title":"Introduction  Introduction"}},{"pageContent":"CODE ```      Status_Code: INTEGER   ``` CODE             Here recipientsTo and from must be valid mobile numbers. Message content & length should meet the criteria of SMS.","metadata":{"source":"scripts/gs.json","line":225,"url":"https://docs.godspeed.systems/docs/microservices/setup/scaffolding#321-scaffolding--project-structure","title":"Introduction  3.2.1 Scaffolding & Project structure ​"}},{"pageContent":"CODE ```      Content Type: application/json ; charset= utf- 8       Method: POST       URL: URL: /api/notification/v1/publish/sendWhatsappText   ``` CODE","metadata":{"source":"scripts/gs.json","line":226,"url":"https://docs.godspeed.systems/docs/microservices/setup/tests","title":"Introduction  Introduction"}},{"pageContent":"CODE ```      recipientsTo           INTEGER       message                STRING       message_type           \"TEXT\"       Channel                “whatsapp”       from                   INTEGER   ``` CODE","metadata":{"source":"scripts/gs.json","line":227,"url":"https://docs.godspeed.systems/docs/microservices/swagger-specs","title":"Introduction  Introduction"}},{"pageContent":"CODE ```      Status_Code: INTEGER   ``` CODE             Here recipientsTo and from must be valid mobile numbers. Message should meet the criteria prescribed by Whatsapp.","metadata":{"source":"scripts/gs.json","line":228,"url":"https://docs.godspeed.systems/docs/microservices/swagger-specs#51-cli-command-to-generate-documentation","title":"Introduction  5.1 CLI command to generate documentation ​"}},{"pageContent":"CODE ```         Status - HTTP status code of response.            All response is in JSON format.            All request parameters are mandatory unless explicitly marked as [optional]     ``` CODE","metadata":{"source":"scripts/gs.json","line":229,"url":"https://docs.godspeed.systems/docs/microservices/swagger-specs#52-custom-server-url","title":"Introduction  5.2 Custom Server URL ​"}},{"pageContent":"All status codes are standard HTTP status codes. The below ones are used in this API. LINK-> ​ #all-status-codes-are-standard-http-status-codes-the-below-ones-are-used-in-this-api <-LINK    CODE ```        2XX - Success of some kind           4XX - Error occurred in client’s part           5XX - Error occurred in server’s part     ``` CODE             following are the status codes LINK-> ​ #following-are-the-status-codes <-LINK    CODE ```         Status Code    Description            200             OK            201             Created            202             Accepted (Request accepted, and queued for execution)            400             Bad request            401             Authentication failure            403             Forbidden            404             Resource not found            405             Method Not Allowed            412             Precondition Failed            413             Request Entity Too Large            500             Internal Server Error            501             Not Implemented            503             Service Unavailable            504             Invalid data     ``` CODE","metadata":{"source":"scripts/gs.json","line":230,"url":"https://docs.godspeed.systems/docs/microservices/technology-used/intro","title":"Technologies used (Default)  Technologies used (Default)"}},{"pageContent":"To Be Done","metadata":{"source":"scripts/gs.json","line":231,"url":"https://docs.godspeed.systems/docs/microservices/workflows","title":"Workflows  Workflows"}},{"pageContent":"To Be Done","metadata":{"source":"scripts/gs.json","line":232,"url":"https://docs.godspeed.systems/docs/microservices/workflows#71-the-structure-of-workflows","title":"Workflows  7.1 The structure of workflows ​"}},{"pageContent":"CODE ```   `name    namespace    git        repoUrl        version    includedFunctions        users            registration                auths                    JWT                        enabled: false                validations                    - <fnName>                    - <fn2Name>                preHooks                    - <fnName>                onError                    - <fnName>                postHooks                    - <fnName>        crud            create                otel: false   ``` CODE","metadata":{"source":"scripts/gs.json","line":233,"url":"https://docs.godspeed.systems/docs/microservices/workflows#72-the-tasks-within-workflows","title":"Workflows  7.2 The tasks within workflows ​"}},{"pageContent":"This document is intended for stakeholders, tech leaders, architects & developers. It will provide high level goals, tenets, design principles, components & features of the platform for the intended audience.","metadata":{"source":"scripts/gs.json","line":234,"url":"https://docs.godspeed.systems/docs/microservices/workflows#the-output-of-task--external-function","title":"Workflows  The output of task & external function ​"}},{"pageContent":"Godspeed is aimed at empowering teams to develop, maintain and observe microservices based backends, with high velocity, scalability, quality and performance.\n  We want development (and hence also QA) teams to bypass all the repeatable and reusable work involved in building modern distributed backends with domain driven design, multi-tenancy, microservices and serverless functions. We want the developers to be able to speedily develop microservices in days, instead of months.For the same, we are trying to provide everything that a team needs to create and operate modern microservices. It will be configuration/templating driven, plug & play, extensible by nature and cloud independent. There will be no vendor lock-in, either with Godspeed or any vendor used. It will give developers choice and control over the kind of tools, DBs and cloud providers they wish to use, while following standards and unified interfaces.This framework is being systematically developed by Mindgrep over the last years, across various projects by extracting abstractions and reusable components. It is actively being customized/expanded/improved with new adaptations.IMAGE-> /assets/images/snowburg-89ff72501cfac4151257437cdf03eb25.png <-IMAGE","metadata":{"source":"scripts/gs.json","line":235,"url":"https://docs.godspeed.systems/docs/microservices/workflows#73-location-and-fully-qualified-name-id-of-workflows-and-functions","title":"Workflows  7.3 Location and fully qualified name (id) of workflows and functions ​"}},{"pageContent":"THE GOALS OF THE FRAMEWORK ARE AIMED TO MAKE BUSINESS AGILE BY EMPOWERING THE PRODUCT & DEVELOPMENT TEAMS TO DELIVER EXCELLENT SOLUTIONS VERY FAST.","metadata":{"source":"scripts/gs.json","line":236,"url":"https://docs.godspeed.systems/docs/microservices/workflows#74-referencing-a-workflow-within-an-event-or-another-workflow","title":"Workflows  7.4 Referencing a workflow within an event or another workflow ​"}},{"pageContent":"Godspeed provides low code implementation, YAML based DSL, prebuilt feature set and easy project setup, making like of developers easy. Thus empowering them to focus and accomplish their core work with the least amount of effort, time & cost.","metadata":{"source":"scripts/gs.json","line":237,"url":"https://docs.godspeed.systems/docs/microservices/workflows#75-use-of-coffeejs-for-scripting","title":"Workflows  7.5 Use of Coffee/JS for scripting ​"}},{"pageContent":"The framework provides fundamental functionalities of “a modern microservice” out of the box so that developer only needs to focus on business logic (80% reduction in work).\nIMAGE-> /assets/images/productivity-267ee9517a173b1d8ad0cfb07c47a864.png <-IMAGE","metadata":{"source":"scripts/gs.json","line":238,"url":"https://docs.godspeed.systems/docs/microservices/workflows#76-inbuilt-functions","title":"Workflows  7.6 Inbuilt functions ​"}},{"pageContent":"Module owners can start shipping microservices within a week's ramp-up time. If at all, only a couple of members in the ogranization need to know the nitty gritty. Rest can just train to use the framework, and deliver with their help,or ours.","metadata":{"source":"scripts/gs.json","line":239,"url":"https://docs.godspeed.systems/docs/microservices/workflows#77-developer-written-functions","title":"Workflows  7.7 Developer written functions ​"}},{"pageContent":"The framework can read the environmental variables from a secure source like K8s Vault. For data in transit and data at rest, we use encryption mechanisms. Also, the framework supports JWT Authentication. Further, all hits to other APIs are secured via security schemas specified in their Open API Specification (OAS 3). Fine grained authorization at API and datasources level is in the roadmap.  LINK-> Read more /docs/security/intro <-LINK","metadata":{"source":"scripts/gs.json","line":240,"url":"https://docs.godspeed.systems/docs/microservices/workflows#78-headers-defined-at-workflow-level","title":"Workflows  7.8 Headers defined at workflow level ​"}},{"pageContent":"Migrate existing data models to Godspeed via database introspection. Autogenerate CRUD APIs based on the data models. Migrate existing API based on its introspection, to create Godspeed compliant events - planned. Now, all that remains for developers, is simply to migrate the business logic.","metadata":{"source":"scripts/gs.json","line":241,"url":"https://docs.godspeed.systems/docs/microservices/workflows#79-file-upload-feature","title":"Workflows  7.9 File Upload feature ​"}},{"pageContent":"IMAGE-> /assets/images/features-9205caf77b700ced3cc5915b21ce5907.png <-IMAGE","metadata":{"source":"scripts/gs.json","line":242,"url":"https://docs.godspeed.systems/docs/notification-api","title":"Notification API  Notification API"}},{"pageContent":"Developer does not need to do anything at the levels lower than the schema (events, datasources) and business logic. All that, including project setup with required docker containers, is handled by the framework. The developers need not to repeat any work from api to api or project to project.","metadata":{"source":"scripts/gs.json","line":243,"url":"https://docs.godspeed.systems/docs/notification-api#notification-service-can-be-run-as-independent-microservices-and-as-a-module-within-other-microservices","title":"Notification API  Notification service can be run as independent microservices and as a module within other microservices. ​"}},{"pageContent":"Pluggable interfaces allow new integrations without changing code. For example, replacing datastores, APM/BPM tools, analytics engines, cache, email provider, file storage, CRM etc. should ideally require no change in the application code.","metadata":{"source":"scripts/gs.json","line":244,"url":"https://docs.godspeed.systems/docs/notification-api#1-sendemail","title":"Notification API  1. SendEmail ​"}},{"pageContent":"Use standards in designing the system. For example, events using CouldEvents. Observability using OpenTelemetry.","metadata":{"source":"scripts/gs.json","line":245,"url":"https://docs.godspeed.systems/docs/notification-api#request-url","title":"Notification API 1. SendEmail ​  Request URL ​"}},{"pageContent":"The three fundamental abstractions in the Godspeed are events (sync/async), workflows (business logic) and datasources (APIs/datastores).  LINK-> Read more /docs/microservices/intro <-LINK","metadata":{"source":"scripts/gs.json","line":246,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json","title":"Notification API 1. SendEmail ​  Parameters for the request Json ​"}},{"pageContent":"We will follow  LINK-> OpenTelemetry https://opentelemetry.io/ <-LINK  (OTEL) SDKs to collect and observe telemetry data, including application performance monitoring. This will be integrable with a plethora of open source or commercial tools of choice that integrate with the standard OTEL protocol.  LINK-> Read more /docs/telemetry/intro <-LINK","metadata":{"source":"scripts/gs.json","line":247,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json","title":"Notification API 1. SendEmail ​  Parameters for the response JSON ​"}},{"pageContent":"The three main dimensions of Godspeed framework: events, workflows and datasources.IMAGE-> /assets/images/framework-architecture-b3443d983a42a3f88fe69100a4bb568d.png <-IMAGE","metadata":{"source":"scripts/gs.json","line":248,"url":"https://docs.godspeed.systems/docs/notification-api#here-recipientsto-and-from-must-be-validated-as-valid-email-format","title":"Notification API  Here recipientsTo and from must be validated as valid email format. ​"}},{"pageContent":"Use cases include any kind of microservice, CRUD microservice, wrapper service, search and suggest service, backend for frontend service, orchestration service, domain gateway service, etc.","metadata":{"source":"scripts/gs.json","line":249,"url":"https://docs.godspeed.systems/docs/notification-api#2-sendbulkemail","title":"Notification API  2. sendBulkEmail ​"}},{"pageContent":"Generative AI based microservice code generation [In progress - Q1]  Generative AI based app generation [Q-2]  Support to define and handle custom event sources [Done - Q1]    Adding capability for defining reusable modules and use them in projects [Q-2]  Support for Java, Golang, Python{on prioritisation by partners} [Q-2]  Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]","metadata":{"source":"scripts/gs.json","line":250,"url":"https://docs.godspeed.systems/docs/notification-api#request-url-1","title":"Notification API 2. sendBulkEmail ​  Request URL ​"}},{"pageContent":"AI based FAQ & troubleshooting [Q-1]  VS code Debugger  for step through debuggability[Q-2]  Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]","metadata":{"source":"scripts/gs.json","line":251,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-1","title":"Notification API 2. sendBulkEmail ​  Parameters for the request Json ​"}},{"pageContent":"Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]  K8s based Grafana observability stack - [Done- Q1]  Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]  K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]","metadata":{"source":"scripts/gs.json","line":252,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-1","title":"Notification API 2. sendBulkEmail ​  Parameters for the response JSON ​"}},{"pageContent":"Support for Authentication for dynamic JWT tokens [Q1]  Support to call YAML workflows from JS workflows [Q1]  Support for using mapping file constants in other mapping file [Q1]","metadata":{"source":"scripts/gs.json","line":253,"url":"https://docs.godspeed.systems/docs/notification-api#3-sendbulktemplateemail","title":"Notification API  3. sendBulkTemplateEmail ​"}},{"pageContent":"Support for validating / formatting inline js/coffee in yaml files [Q-1]  Support to show proper error hints in events, workflows and datasources yaml files [Q-1]  Help / Tooltip for different kind godspeed functions [Q-1]  Support for JS/TS syntax check in workflows/datasources [Q-1]  Better navigate between events and workflows and definitions through [Q-1]","metadata":{"source":"scripts/gs.json","line":254,"url":"https://docs.godspeed.systems/docs/notification-api#request-url-2","title":"Notification API 3. sendBulkTemplateEmail ​  Request URL ​"}},{"pageContent":"Unified dashboard with SSO for CD and observability.  Java flavour of microservice framework (on customer demand)","metadata":{"source":"scripts/gs.json","line":255,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-2","title":"Notification API 3. sendBulkTemplateEmail ​  Parameters for the request Json ​"}},{"pageContent":"In Godspeed landscape, a configuration can be expressed in two ways.","metadata":{"source":"scripts/gs.json","line":256,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-2","title":"Notification API 3. sendBulkTemplateEmail ​  Parameters for the response JSON ​"}},{"pageContent":"When the config is simple and small, it is perhaps better to put all of it in a single yaml/json/toml file sample_project_module.yaml    CODE ```     user        name: 'Ayush'          address:            city: 'Dharamsala'            locality:              pincode: 176052              landmark: 'Hill ventures adventure park'     ``` CODE","metadata":{"source":"scripts/gs.json","line":257,"url":"https://docs.godspeed.systems/docs/notification-api#4-sendsms","title":"Notification API  4. SendSMS ​"}},{"pageContent":"But when a configuration is growing large and has many nested components, it is perhaps better to break them in separate folder/file structure, for better readability and maintenance.\nWithin any folder, If there is an index.yaml/toml/json, its keys will be loaded at the root path ending at that folder's name.  Any other files' data is loaded under the key of that filename  Nested folders' data is loaded recursively using the same approach, under the key of the nested folders  The config loader in GS will load collated JSON from nested configurations stored in folder structure and give the same output as if it was stored within a single file.  sample_project_module    CODE ```   ./sample_project_module      index.yaml        name: 'Ayush'                     //Contents of index.yaml file      address        index.yaml          city: 'Dharamsala'              //Content of address/index.yaml file        locality.yaml          pincode: 176052          landmark: 'Hill ventures adventure park'   ``` CODE","metadata":{"source":"scripts/gs.json","line":258,"url":"https://docs.godspeed.systems/docs/notification-api#request-url-3","title":"Notification API 4. SendSMS ​  Request URL ​"}},{"pageContent":"Both these settings will ead to the same output as shown in Way 1.","metadata":{"source":"scripts/gs.json","line":259,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-3","title":"Notification API 4. SendSMS ​  Parameters for the request Json ​"}},{"pageContent":"There are two kinds of projects : Microservice  Serverless Any project can Have its own code (./src)  Include other libraries/modules (package.json)  Add middleware to functions (imported or in /src)  Export functions (own or imported) via HTTP, message bus or socket  A CLI is planned to create the scaffolding structure. For now template git repository will be made available.","metadata":{"source":"scripts/gs.json","line":260,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-3","title":"Notification API 4. SendSMS ​  Parameters for the response JSON ​"}},{"pageContent":"Configuration of any kind can be written in a single yaml/toml/json file, or can be broken down into nested folders. Any single file when getting too big, can be broken down into folders.  LINK-> Read more here /docs/scaffolding/config-loading <-LINK   Middleware: Functions authored in /src or imported from other modules, when loaded at service start time, can be wrapped as GSInstruction, with zero or more pre and post hooks including validations and auth,  LINK-> based on middleware settings #common-middleware <-LINK  of the project and overriden settings per function    CODE ```   ./                                              // Project root directory      src/                                          // It includes your authored functions which you wish to expose via the microservice interfaces as API. The FQN of any exported from any function, is the folder path to that function relative to /src      test/                                         // Test cases for the project      ui/                                           // Any UI related code including static files          static //html, images, css          src //React, react-native, Ionic,      config/                                       // All the configuration for this project, including that of imported modules and also own exported functions.        src/                                        // Any config required by the code in src folder        imported_modules          auth/                                     // Auth related config          telemetry/                                // Telemetry related config          data/                                     // Data related config, including model, databases used, batch settings, internationalization/localization etc.        middleware/                                 // Inserting pre and post function hooks to functions ;          common/                                   // Applicable to all functions, be it imported functions or functions defined in src          function_overrides/                       // Middleware related config        exported_functions/                         // Configuration for function/modules to be exported over REST, message bus or socket (whether from /src or imported modules)        test/                                       // Any config required by the tests        microservice/                               // When exposed as microservice this is required. It contains any microservice level settings. For example, the microservice name, domain name, open API channels (like message bus, REST).          domainName: 'lending'          microserviceName: 'credit_card'          enabled_channels: ['REST', 'messageBus', 'socket']  //By default all exported functions will be exported via all enabled channels        serverless/                                 // When exposed as serverless function this is required. It contains any FAAS level settings.          domainName: 'lending'          FAASName: 'some_ETL'          trigger: 'messageBus' | 'gitOps' ...      //For full list of supported triggers, see the ArgoEvents for supported sources      package.json                                  // All package info including the imported modules and dependencies      ReadMe.md   ``` CODE              TODO: Add details for microservice/serverless config for different environments like dev/staging/production.","metadata":{"source":"scripts/gs.json","line":261,"url":"https://docs.godspeed.systems/docs/notification-api#5-sendbulksms","title":"Notification API  5. SendBulkSMS ​"}},{"pageContent":"In Godspeed land, the API schema is collection of defined and exported functions with middleware hooks like param validation & authorization.  LINK-> Refer the core runtime /docs/writing-business-logic/functions <-LINK  for the same.\nIn Godspeed land, you need to write only the business logic & configurations, and not write any code for setting up the server, defining routes, listening to different sync/async channels, sending responses etc.\nThis way the business logic of a function is decoupled from the way this function is exported and consumed, saving development and testing work, and also saving code repetition.\nAll you need to export a function is to define its config in /config/exported_functions.   CODE ```   ./config      exported_functions/        com          abc            functionA                               // The Fullly qualified name (FQN) of the exported function to external consumer will be `${domainName}.${microserviceName}.com.abc.functionA`                                                    // On event interfaces, the microservie or serverless will be registered to listen on the FQN of this function. For REST, the FQN will itself become the URL for that endpoint.              enabled_channels:                     // If channels are not specified for this function, it is exportd via all the channels exposed by this service. In case of HTTP, default export will be POST.                REST:                  methodType: 'GET' | 'POST'...     // The params of GET request and payload of POST request become the arguments of the underlying function, to be called with its middleware                messageBus: true | false            // Default value: true. By default every function is exported on all the exported channels of this microservice (see microservice config detailed in above section)                socket: true | false                // If a channel is not set at the microservice config level, yet a function can be exported on that channel by this local override   ``` CODE","metadata":{"source":"scripts/gs.json","line":262,"url":"https://docs.godspeed.systems/docs/notification-api#request-url-4","title":"Notification API 5. SendBulkSMS ​  Request URL ​"}},{"pageContent":"Like discussed already, any function exported an be given middleware hooks to be run before and after the function execution. These are useful for param validation, authorization and any other use cases as need be.\nThe developer gets default middleware functions defined in  CODE ``` /config/middleware/common ``` CODE . He can further tweak the middleware for any function used in the project. Local changes will override the global settings.\nThese settings will be same in case of FAAS or microservice project.   CODE ```   ./config        middleware/          common/                                                       // all functions will have common middleware defined here            preAuths              com.mg.gs.telemetry.createSpan              dot.separated.fqn.fn2            auths //GSAssert              f.q.n2.cachedAclsBasedAuth              f.q.n2.ownershipBasedAuth            validations //GSAssert              f.q.n3.applyValidationA              f.q.n4.applyValidationB            onError            finally              com.mg.gs.telemetry.closeSpan              com.mg.gs.telemetry.EFKLog              com.mg.gs.telemetry.trace              com.mg.gs.telemetry.sendLatencyMetric            function_overrides                                             //function specific overrides values here            com              godspeed                lending                  createLoanAccount                    middleware                      preAuths                        push // | prepend | set                          //One can add middleware before or after the common middleware. Or replace (set) the common middleware with override.                          - f.q.n.fn1                          - dot.separated.fqn.afterAll                        prepend                          - f.q.n.beforeAll                      auths //GSAssert                        set // | prepend | set                          - f.q.n2.cachedAclsBasedAuth                          - f.q.n2.ownershipBasedAuth                      validations                        prepend                          - f.q.n3.applyValidationA                          - f.q.n4.applyValidationB                      finally   ``` CODE","metadata":{"source":"scripts/gs.json","line":263,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-4","title":"Notification API 5. SendBulkSMS ​  Parameters for the request Json ​"}},{"pageContent":"The introduction of code level security is as follows:","metadata":{"source":"scripts/gs.json","line":264,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-4","title":"Notification API 5. SendBulkSMS ​  Parameters for the response JSON ​"}},{"pageContent":"Methodologies for code scanning, vulnerability prevention, and security are listed below:  GitHub secret scanning to avoid committing private keys and secrets into the codebase across all git branches.    Use of CodeQL to scan and analyze code for security vulnerabilities and code related problems. This will be integrated in the CI using GitHub Actions.    Dependabot alerts will be configured on the github repos for the early detection of vulnerabilities in the third-party libraries and packages.    Integrate  LINK-> Snyk https://snyk.io/ <-LINK  container security to the Kubernetes cluster to identify and fix the vulnerabilities across all image layers. This will be hooked up in the CI process.    Web Application security testing will be done using Zed Attack Proxy (ZAP) to identify risks of malicious attacks.","metadata":{"source":"scripts/gs.json","line":265,"url":"https://docs.godspeed.systems/docs/notification-api#6-sendwhatsapptext","title":"Notification API  6. SendWhatsAppText ​"}},{"pageContent":"The entire platform will be hosted inside a restricted private network similar to Amazon Virtual Private Cloud (VPC). All communication between the internet and this network will be encrypted with HTTPS.","metadata":{"source":"scripts/gs.json","line":266,"url":"https://docs.godspeed.systems/docs/notification-api#request-url-5","title":"Notification API 6. SendWhatsAppText ​  Request URL ​"}},{"pageContent":"All personally identifiable and sensitive information will be encrypted when stored in the database. This will be achieved using client side field encryption within the microservices/CRUD APIs. The encryption of the fields will be configurable at the time of defining the schema. For example, a MongoDB client will encrypt the fields using Authenticated encryption with associated data (AEAD) with HMAC-SHA-512 MAC before sending the data to the MongoDB server. This is supported out of the box using  LINK-> mongodb-client-encryption https://www.npmjs.com/package/mongodb-client-encryption <-LINK  library.During transit, the communication between microservices will follow a mutual TLS approach to ensure that the parties at each end of the network are who they claim to be. Additionally the data in transit will be encrypted as long as it was configured in the schema.","metadata":{"source":"scripts/gs.json","line":267,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-request-json-5","title":"Notification API 6. SendWhatsAppText ​  Parameters for the request Json ​"}},{"pageContent":"No Personally identifiable information (PII) to be present in logs. This will have to be ensured by the developers through model configuration. Once configured, the specific information will be redacted from the logs by the framework. Additionally, the use of pre-commit git hooks such as  LINK-> Husky https://www.npmjs.com/package/husky <-LINK  will prevent committing console logs using  LINK-> ESlint https://eslint.org/ <-LINK  rules.","metadata":{"source":"scripts/gs.json","line":268,"url":"https://docs.godspeed.systems/docs/notification-api#parameters-for-the-response-json-5","title":"Notification API 6. SendWhatsAppText ​  Parameters for the response JSON ​"}},{"pageContent":"Cache to support encryption at rest and in-transit. Caching services such as Redis Enterprise have built in encryption support data in transit and at rest. Additionally, Amazon ElastiCache for Redis, an in-memory distributed caching mechanism, provides in-transit and at rest encryption to protect the data.","metadata":{"source":"scripts/gs.json","line":269,"url":"https://docs.godspeed.systems/docs/notification-api#7-glossary","title":"Notification API  7. Glossary ​"}},{"pageContent":"Documents to be stored as Blobs and will be encrypted at rest. Storage services such as Amazon S3 allow configuring the default encryption on a bucket. Doing so will encrypt all the newly added objects using server side encryption.","metadata":{"source":"scripts/gs.json","line":270,"url":"https://docs.godspeed.systems/docs/notification-api#conventions","title":"Notification API 7. Glossary ​  Conventions ​"}},{"pageContent":"Secret Management -- Using Hashicorp Vault or AWS Secret Manager or Azure Key Vault. Hashicorp Vault is cloud agnostic","metadata":{"source":"scripts/gs.json","line":271,"url":"https://docs.godspeed.systems/docs/notification-api#status-codes","title":"Notification API 7. Glossary ​  Status Codes ​"}},{"pageContent":"In Godspeed land, one can trigger any kind of serverless workflows (akin to Lambda functions) from a diversity of sources. This is programming language, framework and cloud agnostic. Technologies used   LINK-> ArgoEvents https://argoproj.github.io/argo-events/ <-LINK    LINK-> ArgoWorkflow https://argoproj.github.io/workflows/ <-LINK  Salient Feature LINK-> ​ #salient-feature <-LINK  MULTIPLE TRIGGER SOURCES. MULTIPLE TRIGGERED DESTINATIONS \nArgo Events is a CloudEvents compliant, event-driven workflow automation framework for Kubernetes. It integrates with more than 20 trigger sources and can trigger multiple kinds of workflows. Manages everything from simple, linear, real-time to complex, multi-source events. It can trigger K8s objects, Argo Workflows, OpenFAAS functions, AWS Lamdba and other Serverless workloads, etc. on events from a variety of sources like git, webhooks, S3, schedules, messaging queues, gcp pubsub, sns, sqs, etc.IMAGE-> /assets/images/es3-31b30e6a4672e4217484712b90c8083d.PNG <-IMAGE","metadata":{"source":"scripts/gs.json","line":272,"url":"https://docs.godspeed.systems/docs/out-of-box/auto-export","title":"Auto Export  Auto Export"}},{"pageContent":"LINK-> ArgoEvents https://argoproj.github.io/argo-events/ <-LINK    LINK-> ArgoWorkflow https://argoproj.github.io/workflows/#:~:text=Argo%20Workflows%20is%20an%20open,using%20a%20graph%20(DAG). <-LINK","metadata":{"source":"scripts/gs.json","line":273,"url":"https://docs.godspeed.systems/docs/out-of-box/auto-export#why-modular-design","title":"Auto Export  Why modular design? ​"}},{"pageContent":"Godspeed can be useful for teams working in any framework or language. They can integrate to Godspeed modules through SDKs in those languages.","metadata":{"source":"scripts/gs.json","line":274,"url":"https://docs.godspeed.systems/docs/out-of-box/auto-export#what-happens-on-importing-a-module","title":"Auto Export  What happens on importing a module? ​"}},{"pageContent":"Telemetry  Out of box telemetry data collection for distrubuted logging, tracing, monitoring  Integrating legacy systems\ncan easily be integrated with log4j etc.  Custom telemetry for BPM(Business Process Monitoring)  Pluggable telemtery sinks/backends(OTEL compliant)  Godspeed will provide out of box preconfigured open source telemetry backeneds as an option      Integration with Godspeed common services: - DB CRUD - Search, suggest & scoring - Data federation (Backend For Frontend) - Notification - Document","metadata":{"source":"scripts/gs.json","line":275,"url":"https://docs.godspeed.systems/docs/out-of-box/auto-export#how-are-modules-imported-in-a-microservice","title":"Auto Export  How are modules imported in a microservice? ​"}},{"pageContent":"The  LINK-> Godspeed domain gateway http://localhost:3000/docs/microservices/intro#the-gateway-microservice <-LINK ) provides Authorization  Orchestration  Distributed transaction","metadata":{"source":"scripts/gs.json","line":276,"url":"https://docs.godspeed.systems/docs/out-of-box/auto-instrumentation","title":"To Be Done  To Be Done"}},{"pageContent":"LINK-> 1.  Preface  /docs/preface <-LINK \n LINK-> 1.1 Introduction /docs/preface/#11-introduction <-LINK \n LINK-> 1.2 Goals /docs/preface/#12-goals <-LINK \n LINK-> 1.3 Features /docs/preface/#13-features <-LINK \n LINK-> 1.4 Tenets /docs/preface/#14-tenets <-LINK \n LINK-> 1.5 Design principals /docs/preface/#15-design-principals <-LINK \n LINK-> 1.6 Framework architecture /docs/preface/#16-framework-architecture <-LINK \n LINK-> 1.7 Scenarios and use cases /docs/preface/#17-scenarios-and-use-cases <-LINK        LINK-> 2.  Introduction  /docs/microservices/intro <-LINK \n LINK-> 2.1 Developer's work /docs/microservices/intro/#21-developers-work <-LINK     LINK-> 3.  Setup  /docs/microservices/setup/getting-started <-LINK \n LINK-> 3.1 Getting started /docs/microservices/setup/getting-started <-LINK \n LINK-> 3.1.1 Glossary /docs/microservices/setup/getting-started/#311-glossary <-LINK \n LINK-> 3.1.2 Pre-requisites /docs/microservices/setup/getting-started/#312-pre-requisites <-LINK \n LINK-> 3.1.3 Steps to get started /docs/microservices/setup/getting-started/#313-steps-to-get-started <-LINK \n LINK-> 3.1.4 Time to start the development /docs/microservices/setup/getting-started/#314-time-to-start-the-development <-LINK     LINK-> 3.2 Project structure /docs/microservices/setup/scaffolding <-LINK \n LINK-> 3.2.1 Scaffolding & Project structure /docs/microservices/setup/scaffolding/#321-scaffolding--project-structure <-LINK     LINK-> 3.3 Configuration /docs/microservices/setup/configuration/env-vars <-LINK \n LINK-> 3.3.1 Introduction /docs/microservices/setup/configuration/intro <-LINK \n LINK-> 3.3.2 Environment variables /docs/microservices/setup/configuration/env-vars <-LINK \n LINK-> 3.3.3 Static variables /docs/microservices/setup/configuration/static-vars <-LINK     LINK-> 3.4 Tests /docs/microservices/setup/tests <-LINK \n LINK-> 3.5 Auto watch and build /docs/microservices/setup/auto-watch <-LINK     LINK-> 4.  CLI  /docs/microservices/introduction-cli <-LINK \n LINK-> 4.1 Functionality /docs/microservices/introduction-cli/#41-functionality <-LINK \n LINK-> 4.2 Installation /docs/microservices/introduction-cli/#42-installation <-LINK \n LINK-> 4.3 Options /docs/microservices/introduction-cli/#43-options <-LINK \n LINK-> 4.4 Commands: Outside the dev container /docs/microservices/introduction-cli/#44-commands-outside-the-dev-container <-LINK \n LINK-> 4.5 Commands: Inside the dev container /docs/microservices/introduction-cli/#45-commands-inside-the-dev-container <-LINK     LINK-> 5.  Swagger Specs  /docs/microservices/swagger-specs <-LINK \n LINK-> 5.1 CLI command to generate documentation /docs/microservices/swagger-specs/#51-cli-command-to-generate-documentation <-LINK \n LINK-> 5.2 Custom Server URL /docs/microservices/swagger-specs/#52-custom-server-url <-LINK     LINK-> 6.  Events  /docs/microservices/events <-LINK \n LINK-> 6.1 Event types /docs/microservices/events/#51-event-types <-LINK \n LINK-> 6.2 Event schema & examples for supported sources /docs/microservices/events/#52-event-schema--examples-for-supported-sources <-LINK \n LINK-> 6.2.1 JSON schema validation /docs/microservices/events/#521-json-schema-validation <-LINK \n LINK-> 6.2.2 HTTP event /docs/microservices/events/#522-http-event <-LINK \n LINK-> 6.2.3 Kafka event /docs/microservices/events/#523-kafka-event <-LINK     LINK-> 7.  Workflows  /docs/microservices/workflows <-LINK \n LINK-> 7.1 The structure of workflows /docs/microservices/workflows/#71-the-structure-of-workflows <-LINK \n LINK-> 7.2 The tasks within workflows /docs/microservices/workflows/#72-the-tasks-within-workflows <-LINK \n LINK-> 7.3 Location and fully qualified name (id)    of workflows and functions /docs/microservices/workflows/#73-location-and-fully-qualified-name-id-of-workflows-and-functions <-LINK \n LINK-> 7.4 Referencing a workflow within an event or another workflow /docs/microservices/workflows/#74-referencing-a-workflow-within-an-event-or-another-workflow <-LINK \n LINK-> 7.5 Use of Coffee/JS for scripting /docs/microservices/workflows/#75-use-of-coffeejs-for-scripting <-LINK     LINK-> 7.6 Inbuilt functions /docs/microservices/workflows/#76-inbuilt-functions <-LINK \n LINK-> 7.6.1 com.gs.http /docs/microservices/workflows/#761-comgshttp <-LINK \n LINK-> 7.6.2 com.gs.kafka /docs/microservices/workflows/#762-comgskafka <-LINK \n LINK-> 7.6.3 com.gs.datastore /docs/microservices/workflows/#763-comgsdatastore <-LINK \n LINK-> 7.6.4 com.gs.elasticgraph /docs/microservices/workflows/#764-comgselasticgraph <-LINK \n LINK-> 7.6.5 com.gs.transform /docs/microservices/workflows/#765-comgstransform <-LINK \n LINK-> 7.6.6 com.gs.series /docs/microservices/workflows/#766-comgsseries <-LINK \n LINK-> 7.6.7 com.gs.parallel /docs/microservices/workflows/#767-comgsparallel <-LINK \n LINK-> 7.6.8 com.gs.switch /docs/microservices/workflows/#768-comgsswitch <-LINK \n LINK-> 7.6.9 com.gs.each_sequential /docs/microservices/workflows/#769-comgseach_sequential <-LINK \n LINK-> 7.6.10 com.gs.each_parallel /docs/microservices/workflows/#7610-comgseach_parallel <-LINK \n LINK-> 7.6.11 com.gs.return /docs/microservices/workflows/#7611-comgsreturn <-LINK \n LINK-> 7.6.12 com.gs.log /docs/microservices/workflows/#7612-comgslog <-LINK \n LINK-> 7.6.13 com.gs.dynamic_fn /docs/microservices/workflows/#7613-comgsdynamic_fn <-LINK \n LINK-> 7.6.14 com.gs.aws /docs/microservices/workflows/#7614-comgsaws <-LINK \n LINK-> 7.6.15 com.gs.redis /docs/microservices/workflows/#7615-comgsredis <-LINK \n LINK-> 7.6.16 com.gs.if, com.gs.elif, com.gs.else /docs/microservices/workflows/#7616-comgsif-comgselif-comgselse <-LINK       LINK-> 7.7 Developer written functions /docs/microservices/workflows/#77-developer-written-functions <-LINK \n LINK-> 7.8 Headers defined at workflow level /docs/microservices/workflows/#78-headers-defined-at-workflow-level <-LINK        LINK-> 7.9 File Upload feature /docs/microservices/workflows/#79-file-upload-feature <-LINK \n LINK-> 7.9.1 Workflow spec to upload files with same file key /docs/microservices/workflows/#791-workflow-spec-to-upload-files-with-same-file-key <-LINK \n LINK-> 7.9.2 Workflow spec to upload multiple files with different file keys /docs/microservices/workflows/#792-workflow-spec-to-upload-multiple-files-with-different-file-keys <-LINK \n LINK-> 7.9.3 Workflow spec to upload file directly from URL /docs/microservices/workflows/#793-workflow-spec-to-upload-file-directly-from-url <-LINK     LINK-> 8.  Datasources  /docs/microservices/datasources/intro <-LINK \n LINK-> 8.1 Introduction /docs/microservices/datasources/intro <-LINK \n LINK-> 8.1.1 Datasource types /docs/microservices/datasources/intro/#811-datasource-types <-LINK     LINK-> 8.2 API datasource /docs/microservices/datasources/api <-LINK \n LINK-> 8.2.1 API datasource schema defined externally /docs/microservices/datasources/api/#821-api-datasource-schema-defined-externally <-LINK \n LINK-> 8.2.2 API datasource schema defined within the yaml file /docs/microservices/datasources/api/#822-api-datasource-schema-defined-within-the-yaml-file <-LINK \n LINK-> 8.2.3 Headers defined at datasource level /docs/microservices/datasources/api/#823-headers-defined-at-datasource-level <-LINK \n LINK-> 8.2.4 Headers defined at task level /docs/microservices/datasources/api/#824-headers-defined-at-task-level <-LINK \n LINK-> 8.2.5 Example usage /docs/microservices/datasources/api/#825-example-usage <-LINK     LINK-> 8.3 Datastore as datasource /docs/microservices/datasources/datastore <-LINK \n LINK-> 8.3.1 Schema specification /docs/microservices/datasources/datastore/#831-schema-specification <-LINK \n LINK-> 8.3.2 CLI Commands /docs/microservices/datasources/datastore/#832-cli-commands <-LINK \n LINK-> 8.3.3 Prisma Datastore Setup /docs/microservices/datasources/datastore/#833-prisma-datastore-setup <-LINK \n LINK-> 8.3.4 Auto generating CRUD APIs from data store models /docs/microservices/datasources/datastore/#834-auto-generating-crud-apis-from-data-store-models <-LINK \n LINK-> 8.3.5 Sample datastore CRUD task /docs/microservices/datasources/datastore/#835-sample-datastore-crud-task <-LINK     LINK-> 8.4 Kafka as datasource /docs/microservices/datasources/kafka <-LINK \n LINK-> 8.4.1 Example spec /docs/microservices/datasources/kafka/#841-example-spec <-LINK     LINK-> 8.5 Elasticgraph as datasource /docs/microservices/datasources/elasticgraph <-LINK \n LINK-> 8.5.1 Folder Structure /docs/microservices/datasources/elasticgraph/#851-folder-structure <-LINK \n LINK-> 8.5.2 Datasource DSL /docs/microservices/datasources/elasticgraph/#852-datasource-dsl <-LINK \n LINK-> 8.5.3 Configuration files for elasticgraph /docs/microservices/datasources/elasticgraph/#853-configuration-files-of-elasticgraph <-LINK \n LINK-> 8.5.4 Elasticgraph Setup /docs/microservices/datasources/elasticgraph/#854-elasticgraph-setup <-LINK \n LINK-> 8.5.5 Auto generating CRUD APIs for elasticgraph /docs/microservices/datasources/elasticgraph/#855-auto-generating-crud-apis-for-elasticgraph <-LINK     LINK-> 8.6 Extensible datasources /docs/microservices/datasources/extensible-datasources <-LINK \n LINK-> 8.6.1 Datasource definition /docs/microservices/datasources/extensible-datasources/#861-datasource-definition <-LINK \n LINK-> 8.6.2 Example spec for the event /docs/microservices/datasources/extensible-datasources/#862-example-spec-for-the-event <-LINK \n LINK-> 8.6.3 Example spec for the workflow /docs/microservices/datasources/extensible-datasources/#863-example-spec-for-the-workflow <-LINK     LINK-> 8.7 AWS as datasource /docs/microservices/datasources/aws <-LINK \n LINK-> 8.7.1 Example spec /docs/microservices/datasources/aws/#871-example-spec <-LINK \n LINK-> 8.7.2 com.gs.aws workflow /docs/microservices/datasources/aws/#872-comgsaws-workflow <-LINK     LINK-> 8.8 Redis as datasource /docs/microservices/datasources/redis <-LINK \n LINK-> 8.8.1 Example spec /docs/microservices/datasources/redis/#881-example-spec <-LINK     LINK-> 9.  Caching  /docs/microservices/caching <-LINK \n LINK-> 9.1 Specifications /docs/microservices/caching/#91-specifications <-LINK \n LINK-> 9.1.1 Datasource spec for redis /docs/microservices/caching/#911-datasource-spec-for-redis <-LINK \n LINK-> 9.1.2 Configuration /docs/microservices/caching/#912-configuration <-LINK \n LINK-> 9.1.3 Workflow spec /docs/microservices/caching/#913-workflow-spec <-LINK     LINK-> 10.  Mappings  /docs/microservices/mappings <-LINK \n LINK-> 10.1 Project structure /docs/microservices/mappings/#101-project-structure <-LINK \n LINK-> 10.2 Sample mappings /docs/microservices/mappings/#102-sample-mappings <-LINK \n LINK-> 10.3 Use mappings constants in other mapping files /docs/microservices/mappings/#103-use-mappings-constants-in-other-mapping-files <-LINK     LINK-> 11.  Plugins  /docs/microservices/plugins <-LINK \n LINK-> 11.1 Project structure /docs/microservices/plugins/#111-project-structure <-LINK \n LINK-> 11.2 Sample plugins /docs/microservices/plugins/#112-sample-plugins <-LINK \n LINK-> 11.3 Sample workflow using plugins /docs/microservices/plugins/#113-sample-workflow-using-plugins <-LINK     LINK-> 12.  Authentication & Authorization  /docs/microservices/authen-author <-LINK \n LINK-> 12.1 Authentication /docs/microservices/authen-author/#121-authentication <-LINK \n LINK-> 12.1.1 JWT Configuration /docs/microservices/authen-author/#1211-jwt-configuration <-LINK \n LINK-> 12.1.2 Event spec /docs/microservices/authen-author/#1212-event-spec <-LINK \n LINK-> 12.1.3 Generate JWT /docs/microservices/authen-author/#1213-generate-jwt <-LINK \n LINK-> 12.1.4 Datasource authentication /docs/microservices/authen-author/#1214-datasource-authentication <-LINK     LINK-> 12.2 Authorization /docs/microservices/authen-author/#122-authorization <-LINK \n LINK-> 12.2.1 Workflow DSL /docs/microservices/authen-author/#1221-workflow-dsl <-LINK \n LINK-> 12.2.2 Sample DB query call authorization /docs/microservices/authen-author/#1222-sample-db-query-call-authorization <-LINK     LINK-> 13.  Telemetry  /docs/telemetry/intro <-LINK \n LINK-> 13.1 Introduction /docs/telemetry/intro/#131-introduction <-LINK \n LINK-> 13.1.1 Architecture /docs/telemetry/intro/#1311-architecture <-LINK     LINK-> 13.2 Goals /docs/telemetry/intro/#132-goals <-LINK \n LINK-> 13.3 Configuration /docs/telemetry/intro/#133-configuration <-LINK \n LINK-> 13.3.1 OTEL exporter endpoint /docs/telemetry/intro/#1331-otel-exporter-endpoint <-LINK \n LINK-> 13.3.2 OTEL service name /docs/telemetry/intro/#1332-otel-service-name <-LINK     LINK-> 13.3.3 Logging /docs/telemetry/intro/#1333-logging <-LINK \n LINK-> 13.3.3.1 Log level /docs/telemetry/intro/#13331-log-level <-LINK \n LINK-> 13.3.3.2 Log fields masking /docs/telemetry/intro/#13332-log-fields-masking <-LINK \n LINK-> 13.3.3.3 Log format /docs/telemetry/intro/#13333-log-format <-LINK \n LINK-> 13.3.3.4 Add custom identifiers in logs /docs/telemetry/intro/#13334-add-custom-identifiers-in-logs <-LINK     LINK-> 13.4 Custom metrics, traces and logs (BPM)    /docs/telemetry/intro/#134-custom-metrics-traces-and-logs-bpm <-LINK \n LINK-> 13.4.1 DSL spec for custom metrics /docs/telemetry/intro/#1341-dsl-spec-for-custom-metrics <-LINK \n LINK-> 13.4.2 DSL spec for custom trace /docs/telemetry/intro/#1342-dsl-spec-for-custom-trace <-LINK \n LINK-> 13.4.3 DSL spec for custom logs /docs/telemetry/intro/#1343-dsl-spec-for-custom-logs <-LINK     LINK-> 13.5 Observability Stack /docs/telemetry/intro/#135-observability-stack <-LINK \n LINK-> 13.6 Recommended model for telemetry signals /docs/telemetry/intro/#136-recommended-model-for-telemetry-signals <-LINK     LINK-> 14.  Custom Middleware  /docs/microservices/custom-middleware/ <-LINK \n LINK-> 14.1 How to add custom middleware in Godspeed /docs/microservices/custom-middleware/#141-how-to-add-custom-middleware-in-godspeed <-LINK     LINK-> 15.  Roadmap  /docs/roadmap <-LINK     LINK-> 16.  FAQ  /docs/faq <-LINK \n LINK-> 16.1 What is the learning curve of the microservice framework? /docs/faq/#151-what-is-the-learning-curve-of-the-microservice-framework <-LINK \n LINK-> 16.2 What is the development process and quality metrics? /docs/faq/#152-what-is-the-development-process-and-quality-metrics <-LINK \n LINK-> 16.3 How can we adopt new versions of used technology easily and fast? For example, the new Postgres release. /docs/faq/#153-how-can-we-adopt-new-versions-of-used-technology-easily-and-fast-for-example-the-new-postgres-release <-LINK \n LINK-> 16.4 How easy is it to add new technology in place of an existing one, or add something absolutely new and unique (not existing in the framework)   ? /docs/faq/#154-how-easy-is-it-to-add-new-technology-in-place-of-an-existing-one-or-add-something-absolutely-new-and-unique-not-existing-in-the-framework <-LINK \n LINK-> 16.5 Which databases are currently supported? What is the roadmap for future support? /docs/faq/#155-which-databases-are-currently-supported-what-is-the-roadmap-for-future-support <-LINK \n LINK-> 16.6 Does the API handle DB transactions? /docs/faq/#156-does-the-api-handle-db-transactions <-LINK \n LINK-> 16.7 How can apps be decoupled or loosely coupled with DBs? /docs/faq/#157-how-can-apps-be-decoupled-or-loosely-coupled-with-dbs <-LINK \n LINK-> 16.8 When using Godspeed service alongside SpringBoot, what will be the impact on performance with another hop, versus direct connection with DB from Spring Boot? /docs/faq/#158-when-using-godspeed-service-alongside-springboot-what-will-be-the-impact-on-performance-with-another-hop-versus-direct-connection-with-db-from-spring-boot <-LINK \n LINK-> 16.9 What is the strategic advantage of making DB queries through Godspeed? /docs/faq/#159-what-is-the-strategic-advantage-of-making-db-queries-through-godspeed <-LINK \n LINK-> 16.10 How to achieve multi-tenancy in DBs, for a single application? /docs/faq/#1510-how-to-achieve-multi-tenancy-in-dbs-for-a-single-application <-LINK \n LINK-> 16.11 How can we start adopting the Godspeed framework? /docs/faq/#1511-how-can-we-start-adopting-the-godspeed-framework <-LINK \n LINK-> 16.12 How to move out of the Godspeed framework? Can we have a two door exit? I.e. Can we move out of technology and data both? /docs/faq/#1512-how-to-move-out-of-the-godspeed-framework-can-we-have-a-two-door-exit-ie-can-we-move-out-of-technology-and-data-both <-LINK \n LINK-> 16.13 How will we prevent unified CRUD API from limiting or choking us? /docs/faq/#1513-how-will-we-prevent-unified-crud-api-from-limiting-or-choking-us <-LINK \n LINK-> 16.14 What kind of API standards does the framework support? /docs/faq/#1514-what-kind-of-api-standards-does-the-framework-support <-LINK \n LINK-> 16.15 Why Rest first approach ? Why not Graphql first approach? /docs/faq/#1515-why-rest-first-approach--why-not-graphql-first-approach <-LINK \n LINK-> 16.16 How are we doing testing given there is quite a bit of custom DSL in the framework. How do we ensure the correctness? /docs/faq/#1516-how-are-we-doing-testing-given-there-is-quite-a-bit-of-custom-dsl-in-the-framework-how-do-we-ensure-the-correctness <-LINK \n LINK-> 16.17 How will the upgrades and migrations be done to the framework? /docs/faq/#1517-how-will-the-upgrades-and-migrations-be-done-to-the-framework <-LINK \n LINK-> 16.18 How CRUD APIs will support the paid as well as the non paid features of databases such as MongoDB. For example: MongoDB free vs paid versions will support different features. /docs/faq/#1518-how-crud-apis-will-support-the-paid-as-well-as-the-non-paid-features-of-databases-such-as-mongodb-for-example-mongodb-free-vs-paid-versions-will-support-different-features <-LINK \n LINK-> 16.19 How to ship new models easily? /docs/faq/#1519-how-to-ship-new-models-easily <-LINK","metadata":{"source":"scripts/gs.json","line":277,"url":"https://docs.godspeed.systems/docs/out-of-box/dual-write","title":"To Be Done  To Be Done"}},{"pageContent":"RECOMMENDED STACK, STANDARDS & PROCESSES  Preferred  Alternatives      Soon to be available on  LINK-> official documentation site. https://gs-docs-iota.vercel.app/docs/notification-api <-LINK     Containerisation  Docker    Developer setup  Docker with Godspeed repository (Docker images and templates)    Cloud provisioning  Gitops, Kubernetes, Crossplane    Software provisioning and configuring  Git ops, Argo events, ArgoWorkflows, Argo CD, Argo Rollout    IAM  ORY Kratos/Keycloak    Gateway authorisation  ORY OATHKEEPER    Ingress gateway  NGINX Proxy/Istio/Kong/Ambassdor/Trafeik    Service mesh  Linkerd    Microservice framework  SpringBoot + Open Telemetry SDK + Java SDK Godspeed: SDK with TS, JS, Webassembly (Java, Python, Go, .Net, C#, JS, TS..)    Serverless/ETL framework  \"Argo events, Argo Workflow, Godspeed SDK with webassembly. \"    Distributed transactions, microservice orchestration    Godspeed function-DAG interface with Temporal plugin.  SpringBoot with Temporal integration .      Document service  Document service. Godspeed document service or MinIO  MinIO has community and commercial editions for hosting a S3 comptabile document service.    Notification service  Godspeed based service with  LINK-> universal API https://gs-docs-iota.vercel.app/docs/notification-api <-LINK .  Adapters with providers.    Eventual consistency (polygot persistence)  Godspeed plus Debezium plus Kafka    Databases  Planned support for Mongodb, Elasticsearch    Later support for Postegres, Mysql    Testing Godspeed itself  Chai/Mocha    Test cases for business logic (in any language/framework)  Can be written in any langauge/framework and integrated in CI/CD    MessageBus/Queue  Kafka, ActiveMQ    Telemetry - origination  SDKs in each of Springboot and Godspeed service, compliant with OTEL    Observability   DataDog     Observability.logging  Elasticsearch, FluentBit, Kibana  CloudWatch    Observability.monitoring  Prometheus/Grafana  CloudWatch    Observability.tracing  Jaeger  X-RAY    Observability.alerting  Grafana    Version control  Git & GitHub    Standards- telemetry  OpenTelementry    Standards- events  CloudEvents    Search, Suggest, Analytics  Elasticsearch    Data-events  Debezium + Godspeed (fast to create and execute ETLs)    CI/CD  Argo Events,ARGO Workflow, ArgoCD    Security- Key secret management  Hashicorp Vault and Sealed Secrets (Kubernetes)    Security- Network  VPC    Security- Code  Github, Synk    Encryption","metadata":{"source":"scripts/gs.json","line":278,"url":"https://docs.godspeed.systems/docs/preface","title":"GodSpeed – A Microservice framework  GodSpeed – A Microservice framework"}},{"pageContent":"For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the  LINK-> OpenTelemetry standard http://opentelemetry.io <-LINK  and its supporting tech ecosystem.  Not even a single request must go untracked!","metadata":{"source":"scripts/gs.json","line":279,"url":"https://docs.godspeed.systems/docs/preface#11-introduction","title":"GodSpeed – A Microservice framework  1.1 Introduction ​"}},{"pageContent":"IMAGE-> /assets/images/otel_arch-2b18524c51b2533d21bdf8bc597d8b8a.png <-IMAGE Both  Traces  and  Metrics  are sent to OTEL Collector directly.  Tempo  is used as tracing backend for traces and  Prometheus  is used for metrics with  Mimir  as its backend.  For  Logs , a fluent bit daemonset is running on node, which collects logs from various applications on the node.  Loki  is used as logs aggregation solution.","metadata":{"source":"scripts/gs.json","line":280,"url":"https://docs.godspeed.systems/docs/preface#12-goals","title":"GodSpeed – A Microservice framework  1.2 Goals ​"}},{"pageContent":"No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.","metadata":{"source":"scripts/gs.json","line":281,"url":"https://docs.godspeed.systems/docs/preface#developer-friendly","title":"GodSpeed – A Microservice framework 1.2 Goals ​  Developer friendly ​"}},{"pageContent":"Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.","metadata":{"source":"scripts/gs.json","line":282,"url":"https://docs.godspeed.systems/docs/preface#enhancing-developer-productivity","title":"GodSpeed – A Microservice framework 1.2 Goals ​  Enhancing developer productivity ​"}},{"pageContent":"Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.","metadata":{"source":"scripts/gs.json","line":283,"url":"https://docs.godspeed.systems/docs/preface#smaller-micro-teams-and-lesser-learning-curve","title":"GodSpeed – A Microservice framework 1.2 Goals ​  Smaller, micro teams and lesser learning curve ​"}},{"pageContent":"Specify the IP address of your OTEL collector as env variable. Refer  LINK-> OTEL Exporter https://opentelemetry.io/docs/reference/specification/protocol/exporter/#endpoint-urls-for-otlphttp <-LINK  for more information.   CODE ```   $ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317   ``` CODE             For example,   CODE ```   export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:4317   ``` CODE","metadata":{"source":"scripts/gs.json","line":284,"url":"https://docs.godspeed.systems/docs/preface#security","title":"GodSpeed – A Microservice framework 1.2 Goals ​  Security ​"}},{"pageContent":"Specify the service name by which you want to setup observability and set it as env variable.    CODE ```   $ export OTEL_SERVICE_NAME=sample_proj1   ``` CODE             Let's assume you have setup SigNoz as the exporter then you will see something like this:\nIMAGE-> /assets/images/Metrics-e9fcb53bf4bf1cfabc8e0fff28f3669e.png <-IMAGE\nIMAGE-> /assets/images/SigNoz-graph-4e28f7c7c4aee98b1244bca5fcdef00d.png <-IMAGE\nIMAGE-> /assets/images/Traces-320f9d7e9ea8013043fc4cd21594db96.png <-IMAGE In case you have any questions, please reach out to us on our  LINK-> Discord channel https://discord.com/channels/983323669809999882/983323669809999885 <-LINK .","metadata":{"source":"scripts/gs.json","line":285,"url":"https://docs.godspeed.systems/docs/preface#easy-and-fast-migrations","title":"GodSpeed – A Microservice framework 1.2 Goals ​  Easy and fast migrations ​"}},{"pageContent":"13.3.3.1 Log level LINK-> ​ #13331-log-level <-LINK The minimum level set to log above this level. Please refer  LINK-> Pino log levels https://github.com/pinojs/pino/blob/master/docs/api.md#options <-LINK  for more information. Set  CODE ``` log_level ``` CODE  in  LINK-> Static variables /docs/microservices/setup/configuration/static-vars#defaultyaml <-LINK 13.3.3.2 Log fields masking LINK-> ​ #13332-log-fields-masking <-LINK If you want to hide sensitive information in logs then define the fields which need to be hidden in  CODE ``` redact ``` CODE  feature in  LINK-> Static variables /docs/microservices/setup/configuration/static-vars#defaultyaml <-LINK . Please refer  LINK-> Pino redaction paths https://github.com/pinojs/pino/blob/master/docs/redaction.md#paths <-LINK  for more information.13.3.3.3 Log format LINK-> ​ #13333-log-format <-LINK By default, the logs are dumped in  LINK-> OTEL Logging format https://opentelemetry.io/docs/reference/specification/logs/data-model/ <-LINK  when you deploy your service anywhere (UAT, Prod, K8s, etc.) except inside the vscode remote containers/dev containers.    CODE ```   {\"Body\":\"adding body schema for /upload_doc.http.post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}    {\"Body\":\"adding body schema for /upload_multiple_docs.http.post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}    {\"Body\":\"adding body schema for /upload_s3.http.post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}    {\"Body\":\"registering http handler /another_workflow post\",\"Timestamp\":\"1676531763727000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}    {\"Body\":\"registering http handler /create/:entity_type post\",\"Timestamp\":\"1676531763728000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{}}    . . . . . . . . . . .     {\"Body\":\"args.retry {\\\"max_attempts\\\":3,\\\"type\\\":\\\"constant\\\",\\\"interval\\\":5000}\",\"Timestamp\":\"1676531764656000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"a58ef2d7ff7725c39f1e058bf22fe724\",\"SpanId\":\"751bc314bb6286b4\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"}}    {\"Body\":\"Result of _executeFn test_step1 {\\\"success\\\":true,\\\"code\\\":200,\\\"data\\\":{\\\"args\\\":{},\\\"data\\\":\\\"{\\\\\\\"data\\\\\\\":{\\\\\\\"lan\\\\\\\":\\\\\\\"12345\\\\\\\"}}\\\",\\\"files\\\":{},\\\"form\\\":{},\\\"headers\\\":{\\\"Accept\\\":\\\"application/json, text/plain, */*\\\",\\\"Content-Length\\\":\\\"24\\\",\\\"Content-Type\\\":\\\"application/json\\\",\\\"Host\\\":\\\"httpbin.org\\\",\\\"Traceparent\\\":\\\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\\\",\\\"User-Agent\\\":\\\"axios/0.25.0\\\",\\\"X-Amzn-Trace-Id\\\":\\\"Root=1-63edd835-22cff8e60555fa522c8544cf\\\"},\\\"json\\\":{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}},\\\"method\\\":\\\"POST\\\",\\\"origin\\\":\\\"180.188.224.177\\\",\\\"url\\\":\\\"https://httpbin.org/anything\\\"},\\\"message\\\":\\\"OK\\\",\\\"headers\\\":{\\\"date\\\":\\\"Thu, 16 Feb 2023 07:16:05 GMT\\\",\\\"content-type\\\":\\\"application/json\\\",\\\"content-length\\\":\\\"598\\\",\\\"connection\\\":\\\"close\\\",\\\"server\\\":\\\"gunicorn/19.9.0\\\",\\\"access-control-allow-origin\\\":\\\"*\\\",\\\"access-control-allow-credentials\\\":\\\"true\\\"}}\",\"Timestamp\":\"1676531765810000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"a58ef2d7ff7725c39f1e058bf22fe724\",\"SpanId\":\"751bc314bb6286b4\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"}}    {\"Body\":\"Validate Response JSON Schema Success\",\"Timestamp\":\"1676531765811000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"a58ef2d7ff7725c39f1e058bf22fe724\",\"SpanId\":\"751bc314bb6286b4\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9537a882ae58\",\"process.pid\":61741},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"\"}}   ``` CODE               Dev Format  \nThe  CODE ``` dev format ``` CODE  is basically a transformation of OTEL log format to increase readability for developers.\nPlease note that the default logging format inside vscode dev container on your local machine is  CODE ``` dev format ``` CODE  as given below:   CODE ```   datetime [SeverityText] TraceId SpanId {Attributes} Body   ``` CODE             Sample Logs:   CODE ```   16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post    16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post    16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post    16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post    16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post    16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post    16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post    . . . . . . . . . .     16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"} args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}    16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"test_step1\"} Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd7e4-0b8b6ba319833492520e6b0c\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:14:44 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}    16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"task_id\":\"\"} Validate Response JSON Schema Success   ``` CODE                  note   If you want to change the OTEL format to  CODE ``` dev format ``` CODE , then set the environment variable  CODE ``` NODE_ENV ``` CODE  to  CODE ``` dev ``` CODE  in your environment as given below. The default value of  CODE ``` NODE_ENV ``` CODE  is  CODE ``` production ``` CODE .       CODE ```   export NODE_ENV=dev   ``` CODE             13.3.3.4 Add custom identifiers in logs LINK-> ​ #13334-add-custom-identifiers-in-logs <-LINK You can add any custom identifier in the logging whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   To enable this feature ,you need to specify two things:     CODE ``` log_attributes ``` CODE  variable as  LINK-> environment variable /docs/microservices/setup/configuration/env-vars <-LINK / LINK-> static variable /docs/microservices/setup/configuration/static-vars <-LINK  which contains custom identifiers. For example, this is the sample static configuration:   CODE ```   log_attributes:       mobileNumber: \"query?.mobileNumber\"      id: \"params?.id\"      lan: \"body?.data?.lan\"   ``` CODE              location of the identifier in the request payload. As specified in the above example,   if mobileNumber is present in query params then specify  CODE ``` query?.mobileNumber ``` CODE .  if id is present in path params then specify  CODE ``` params?.id ``` CODE .  if lan is present in data field inside body then specify  CODE ``` body?.data?.lan ``` CODE .        note   Please make sure to add ? in case any field is optional like  CODE ``` body?.data?.lan ``` CODE  so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added.    Sample Logs   Dev format    CODE ```   21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"} Processing event /test/:id.http.post    21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"} event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"835edd29-7c36-4e11-9b79-c661bbd911b0\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}    21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"} event body and eventSpec exist   ``` CODE              OTEL format    CODE ```   {\"Body\":\"Processing event /test/:id.http.post\",\"Timestamp\":\"1676960742403000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"3b66e6f8ec6624f6467af1226503a39e\",\"SpanId\":\"eb6e7d89ac381e9f\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"5252603e08be\",\"process.pid\":828},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"}}    {\"Body\":\"event inputs {\\\"baseUrl\\\":\\\"\\\",\\\"body\\\":{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}},\\\"fresh\\\":false,\\\"hostname\\\":\\\"localhost\\\",\\\"ip\\\":\\\"::ffff:172.22.0.1\\\",\\\"ips\\\":[],\\\"method\\\":\\\"POST\\\",\\\"originalUrl\\\":\\\"/test/12?mobileNumber=9878987898\\\",\\\"params\\\":{\\\"id\\\":\\\"12\\\"},\\\"path\\\":\\\"/test/12\\\",\\\"protocol\\\":\\\"http\\\",\\\"query\\\":{\\\"mobileNumber\\\":\\\"9878987898\\\"},\\\"route\\\":{\\\"path\\\":\\\"/test/:id\\\",\\\"stack\\\":[{\\\"name\\\":\\\"<anonymous>\\\",\\\"keys\\\":[],\\\"regexp\\\":{\\\"fast_star\\\":false,\\\"fast_slash\\\":false},\\\"method\\\":\\\"post\\\"},{\\\"name\\\":\\\"<anonymous>\\\",\\\"keys\\\":[],\\\"regexp\\\":{\\\"fast_star\\\":false,\\\"fast_slash\\\":false},\\\"method\\\":\\\"post\\\"}],\\\"methods\\\":{\\\"post\\\":true}},\\\"secure\\\":false,\\\"stale\\\":true,\\\"subdomains\\\":[],\\\"xhr\\\":false,\\\"headers\\\":{\\\"content-type\\\":\\\"application/json\\\",\\\"user-agent\\\":\\\"PostmanRuntime/7.29.2\\\",\\\"accept\\\":\\\"*/*\\\",\\\"postman-token\\\":\\\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\\\",\\\"host\\\":\\\"localhost:4000\\\",\\\"accept-encoding\\\":\\\"gzip, deflate, br\\\",\\\"connection\\\":\\\"keep-alive\\\",\\\"content-length\\\":\\\"46\\\"},\\\"files\\\":[]}\",\"Timestamp\":\"1676960742403000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"3b66e6f8ec6624f6467af1226503a39e\",\"SpanId\":\"eb6e7d89ac381e9f\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"5252603e08be\",\"process.pid\":828},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"}}    {\"Body\":\"event body and eventSpec exist\",\"Timestamp\":\"1676960742404000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"3b66e6f8ec6624f6467af1226503a39e\",\"SpanId\":\"eb6e7d89ac381e9f\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"5252603e08be\",\"process.pid\":828},\"Attributes\":{\"event\":\"/test/:id.http.post\",\"workflow_name\":\"com.jfs.test\",\"mobileNumber\":\"9878987898\",\"id\":\"12\",\"lan\":\"12345\"}}   ``` CODE","metadata":{"source":"scripts/gs.json","line":286,"url":"https://docs.godspeed.systems/docs/preface#13-features","title":"GodSpeed – A Microservice framework  1.3 Features ​"}},{"pageContent":"Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.","metadata":{"source":"scripts/gs.json","line":287,"url":"https://docs.godspeed.systems/docs/preface#14-tenets","title":"GodSpeed – A Microservice framework  1.4 Tenets ​"}},{"pageContent":"CODE ```   # refer https://github.com/siimon/prom-client    metrics:    -   name: metric_name        type: counter|gauge|histogram|summary        labels:           label1: val1          label2: val2                        # followng functions depending on the metric type and all of them could be scripts, can use inputs/outputs        inc: 10        dec: 10        set: 100        observe: 2000        timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/task   ``` CODE             Example spec LINK-> ​ #example-spec <-LINK In the following example, we are using two custom metrics:  httpbin_calls_total: counter type metric, counter is incremented by 1.  httpbin_calls_duration: histogram type metric, timer is set to true to record duration.    CODE ```   summary: Call an API and transform the     tasks:        - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key          name: http bin step          description: Hit http bin with some dummy data. It will send back same as response          fn: com.gs.http                   metrics:            - name: httpbin_calls_total              help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'              type: counter              labels:                method: httpbin                status_code: <% outputs.httpbin_step1.code %>                             inc: 1            - name: httpbin_calls_duration              help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'              type: histogram              labels:                method: httpbin                status_code: <% outputs.httpbin_step1.code %>                             timer: true                    args:            datasource: httpbin            params: <% inputs.query %>            data: <% inputs.body %>            config:              url : /anything              method: post   ``` CODE","metadata":{"source":"scripts/gs.json","line":288,"url":"https://docs.godspeed.systems/docs/preface#dont-repeat-yourself","title":"GodSpeed – A Microservice framework 1.4 Tenets ​  Don't repeat yourself ​"}},{"pageContent":"CODE ```   trace:        name: span_name        attributes:            attribute1: value1            attribute2: value2   ``` CODE             Example spec LINK-> ​ #example-spec-1 <-LINK In the following example, we are creating a new span named  CODE ``` httpbin_trace ``` CODE  with span attributes  CODE ``` request ``` CODE  and  CODE ``` param ``` CODE . This span gets created when the task starts and ended when the task completes its execution.   CODE ```   summary: Call an API and transform the     tasks:        - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key          name: http bin step          description: Hit http bin with some dummy data. It will send back same as response          fn: com.gs.http          trace:            name: httpbin_trace            attributes:                request: <%inputs.body%>                param: <%inputs.query%>          args:            datasource: httpbin            params: <% inputs.query %>            data: <% inputs.body %>            config:              url : /anything              method: post   ``` CODE","metadata":{"source":"scripts/gs.json","line":289,"url":"https://docs.godspeed.systems/docs/preface#easy-to-extend--customize","title":"GodSpeed – A Microservice framework 1.4 Tenets ​  Easy to extend & customize ​"}},{"pageContent":"CODE ```   logs:        before:            level: fatal|error|warn|info|debug|trace # refer pino for levels            message: 'Sample log before'            params:               param1: val1              param2: val2            attributes:              request:                query: <%inputs.query%>        after:            level: info            message: 'Sample log after'            params:            attributes:    ``` CODE             The logs are dumped in OTEL format. Please refer to  LINK-> OTEL Logging Data model #https://opentelemetry.io/docs/reference/specification/logs/data-model/ <-LINK  for understanding of fields dumped in the logs.  CODE ``` message ``` CODE  and  CODE ``` params ``` CODE  are part of  CODE ``` Body ``` CODE  field and  CODE ``` attributes ``` CODE  are part of  CODE ``` Attributes ``` CODE  field in the log. Example spec LINK-> ​ #example-spec-2 <-LINK In the following example, we are two additional logs before and after the task execution.    CODE ```   summary: Call an API and transform the     tasks:        - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key          name: http bin step          description: Hit http bin with some dummy data. It will send back same as response          fn: com.gs.http          logs:            before:              level: error              message: 'Hello'              params:                 - key1: v1                  key2: v2                - v1              attributes:                 request: <%inputs.query%>            after:              level: error              message: 'World'              params:                 key1: v1                key2: v2              attributes:                 customer_name: <% outputs.httpbin_step1.data.json.customer_name %>           args:            datasource: httpbin            params: <% inputs.query %>            data: <% inputs.body %>            config:              url : /anything              method: post   ``` CODE               Sample Logs       CODE ```   {\"Body\":\"Hello [{\\\"key1\\\":\\\"v1\\\",\\\"key2\\\":\\\"v2\\\"},\\\"v1\\\"]\",\"Timestamp\":\"1676011973016000000\",\"SeverityNumber\":9,\"SeverityText\":\"INFO\",\"TraceId\":\"afde0bf5bb3533d932c1c04c30d91172\",\"SpanId\":\"ad477b2cf81ca711\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9ce06d358ba7\",\"process.pid\":67228},\"Attributes\":{\"request\":{\"status\":\"Hello\"},\"task_id\":\"if\",\"workflow_name\":\"if_else\"}}    . . . . . . . . . . .    {\"Body\":\"World {\\\"key1\\\":\\\"v1\\\",\\\"key2\\\":\\\"v2\\\"}\",\"Timestamp\":\"1676011973019000000\",\"SeverityNumber\":17,\"SeverityText\":\"ERROR\",\"TraceId\":\"afde0bf5bb3533d932c1c04c30d91172\",\"SpanId\":\"ad477b2cf81ca711\",\"TraceFlags\":\"01\",\"Resource\":{\"service.name\":\"unknown_service:node\",\"host.hostname\":\"9ce06d358ba7\",\"process.pid\":67228},\"Attributes\":{\"customer_name\":\"Hell!\",\"task_id\":\"if\",\"workflow_name\":\"if_else\"}}   ``` CODE","metadata":{"source":"scripts/gs.json","line":290,"url":"https://docs.godspeed.systems/docs/preface#standards-driven","title":"GodSpeed – A Microservice framework 1.4 Tenets ​  Standards driven ​"}},{"pageContent":"The complete observability stack with K8s helm-charts will be made available soon.","metadata":{"source":"scripts/gs.json","line":291,"url":"https://docs.godspeed.systems/docs/preface#15-design-principals","title":"GodSpeed – A Microservice framework  1.5 Design principals ​"}},{"pageContent":"Please find the  LINK-> draft documentation here https://docs.google.com/document/d/12V0oaqj81G8nDuCeD46_mHovv6uwaguwd4kVpBC2J6Q/edit#heading=h.zerkjmn66eyq <-LINK . This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.","metadata":{"source":"scripts/gs.json","line":292,"url":"https://docs.godspeed.systems/docs/preface#three-fundamental-abstractions","title":"GodSpeed – A Microservice framework 1.5 Design principals ​  Three fundamental abstractions ​"}},{"pageContent":"Events are used to expose the functions of this microservice to the external world. Whether via HTTP, message bus, gRPC or socket.","metadata":{"source":"scripts/gs.json","line":293,"url":"https://docs.godspeed.systems/docs/preface#unified-observability-for-apm-and-bpm","title":"GodSpeed – A Microservice framework 1.5 Design principals ​  Unified Observability For APM and BPM ​"}},{"pageContent":"Two events needed to complete an HTTP call.","metadata":{"source":"scripts/gs.json","line":294,"url":"https://docs.godspeed.systems/docs/preface#16-framework-architecture","title":"GodSpeed – A Microservice framework  1.6 Framework architecture ​"}},{"pageContent":"Whenever an event has  CODE ``` event.full.name._http.{method_name} ``` CODE  as part of its name,\nthen the framework will start listening on the URL\n CODE ``` ${app_base_url}/event/full/name ``` CODE  against the method ${method_name} which can be PUT, GET, POST etc.\nThe body, params, headers and query of the HTTP request are\nserialized by the framework into the event object and passed to the  CODE ``` __handler ``` CODE  (function handler for this event) which consumes this request and returns a reponse. Implicitly the framework will emit a response for every event which can again be an event or yaml execution. Convention is event_name.response, but if we want to emit any other event, we can invoke any other DAG, it could send event to message_bus or GRPC also. Sample input definition LINK-> ​ #sample-input-definition <-LINK    CODE ```   do_KYC.__http.post:      # exposed by convention as REST URL: app_base_url/do_KYC on method POST      __handler: __src.com.abc.do_KYC      __data: # {body, params, query, headers} Bank API POST url is: /create_loan/${pan}/?user_id=${user_id} & body takes {user_name, address}         __example:            body:              user_name: Ayush              pan: AKJP****              address: India            # In case of HTTP event, query, headers and params will be also present            headers:            query:            params:        __schema: #Validation will happen after recieving and before sending out event. In case of HTTP channel, payload will have metadata.http.{headers, params, query}          # ${config.src.com.pinelabs.li.schemas.create_loan_api} #using template written elsewhere. For ex. compulsory pan, user_name, address          body:            type: object            properties:              user_name: string              pan: string              address: string              required: [user_name, pan, address]          headers:          query:          params:      #__response: someother.do_KYC.http.post.response # Can be implicit or explicit (in case of custom event names)   ``` CODE             Sample response event definition LINK-> ​ #sample-response-event-definition <-LINK The framework, upon recieving the  CODE ``` __response ``` CODE , emits another event whose name is  CODE ``` event.full.name._http.{method_name}.response ``` CODE , by convention. This event is in turn caught by the framework internally itself, and passed on to the  CODE ``` http_event_handler ``` CODE  which then sends over the  CODE ``` __response ``` CODE  data to the HTTP caller.Every event has a schema which determines the shape of its data.\nIn case of HTTP event, it will have body, params, query and headers in its data.\nFurther, note that the event emmitted by the framework will have CloudEvents specific format. This includes the events which returns the HTTP response. This means that the HTTP response will also have CloudEvents format.   CODE ```   do_KYC.__http.post.response: #this URI can be customized. By default eventName.response is the actual response event.      # __handler: __http.response_handler # provided by the framework. No need to specify here      __data: # Bank API POST url is: /create_loan/${pan}/?user_id=${user_id} & body takes {user_name, address}        __example:            body:              user_id: 1            headers:        __schema: #Validation will happen after recieving and before sending out event. In case of HTTP channel, payload will have metadata.http.{headers, params, query}        # Schema can be in any shape, which is supported by the event handler attached to this event            200: *200-json-schema            400: *400-json-schema            500: *500-json-schema   ``` CODE","metadata":{"source":"scripts/gs.json","line":295,"url":"https://docs.godspeed.systems/docs/preface#17-scenarios-and-use-cases","title":"GodSpeed – A Microservice framework  1.7 Scenarios and use cases ​"}},{"pageContent":"The DSL provided by Godspeed is an extension of the YAML spec. Note: Also every keyword will start with double underscores.","metadata":{"source":"scripts/gs.json","line":296,"url":"https://docs.godspeed.systems/docs/roadmap","title":"Roadmap  Roadmap"}},{"pageContent":"A name of the function. It will has response data as the value to its key.   CODE ```   __name: step1   ``` CODE","metadata":{"source":"scripts/gs.json","line":297,"url":"https://docs.godspeed.systems/docs/roadmap#godspeed-framework-roadmap-q1-and-q2---2023","title":"Roadmap  Godspeed Framework Roadmap Q1 and Q2 - 2023 ​"}},{"pageContent":"A basic sumary of the function.   CODE ```   __summary: A sample summary of the function   ``` CODE","metadata":{"source":"scripts/gs.json","line":298,"url":"https://docs.godspeed.systems/docs/roadmap#features-core-framework","title":"Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​  Features [Core Framework] ​"}},{"pageContent":"A basic description of the function.   CODE ```   __summary: A sample description of the function   ``` CODE","metadata":{"source":"scripts/gs.json","line":299,"url":"https://docs.godspeed.systems/docs/roadmap#language-features--debugging-vscode-extension","title":"Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​  Language Features & Debugging VSCode Extension ​"}},{"pageContent":"The YAML function argument that is needed in the function dag, we specify here. The arg consists of 2 parts An example of the how the argument looks for the function using  CODE ``` __example ``` CODE     CODE ```   __example:      sample_arg_1: sample_value_1      sample_arg_2: sample_value_2   ``` CODE","metadata":{"source":"scripts/gs.json","line":300,"url":"https://docs.godspeed.systems/docs/roadmap#platform","title":"Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​  Platform ​"}},{"pageContent":"The DSL allows one to define functions in YAML format. A function definition can invoke A single function using  CODE ``` __ref ``` CODE . This means, internally we would call this function.    CODE ```    __ref: __src.com.abc.anuj   ``` CODE              A series of functions using  CODE ``` __sequence ``` CODE . This means, that we want to run multiple function in our DAG in sequential manner.    CODE ```   __sequence:      - __ref: __modules.imported_module_1.some_function      - __ref: __modules.imported_module_2.some_function_2   ``` CODE              A parallel exeuction of list of functions using  CODE ``` __parallel ``` CODE . This means, that we want to run multiple function in our DAG in parallel manner.    CODE ```   __parallel:      - __ref: __modules.imported_module_1.some_function      - __ref: __modules.imported_module_2.some_function_2   ``` CODE              The functions wrapped around and invoked can be either JS, or TS or YAML functions. Also we would only choose of the options between  CODE ``` __ref ``` CODE ,  CODE ``` __sequential ``` CODE ,  CODE ``` _parallel ``` CODE .  The name contains the response data in nested manner. Say we want data from step1 of DAG, the way to access that would be    CODE ```   __args:      create_user_url: ${__config.los.urls.create_user}      user_id: ${__response.data.step1.data.user_id}      user_name: ${__request.params.user_name}   ``` CODE","metadata":{"source":"scripts/gs.json","line":301,"url":"https://docs.godspeed.systems/docs/roadmap#other-minor-stories--core-framework-platform--language-features","title":"Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​  Other Minor Stories- Core Framework, Platform & Language features ​"}},{"pageContent":"Hooks are like decorators in Python world or annotations in Java world, where you define logic that must execute before or after a function call.\nThe framework has some common hooks for all functions in the project, like Telemetry hooks. But the developer has the flexibility to override or change commmon hooks through  LINK-> function overriding #overriding-a-function <-LINK  defined below.Here are the different kind of hook functions possible   CODE ```     __hooks:        __pre_validations: # This ref is executed for pre_validation        __validations: # This ref is executed for validation        __preauths: # This ref is executed for pre_auths        __auths: # This ref is executed for auths        __pre_ref: # This ref is executed before the function call itself        __post_ref: # This ref is executed after the function call itself        __on_error: # This ref is executed if the function raises an error        __finally: # This ref is executed when the execution of the function call is done   ``` CODE              An example on hooks for  CODE ``` __on_error ``` CODE     CODE ```   __hooks:      __on_error:        - __ref: __log          __args:            data:              key1:value1              key2:value2   ``` CODE","metadata":{"source":"scripts/gs.json","line":302,"url":"https://docs.godspeed.systems/docs/roadmap#enhancements-in-language","title":"Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​  Enhancements in Language ​"}},{"pageContent":"CODE ```   ```    com:      xyz:        someFn:          __name: step1          __summary: Summary of this function          __description: long description          __args:            __example:            __schema:          __ref: com.abc.anuj # JS, TS, yaml  __src.com.a.b.c, __modules          __args:            arg1: 5            arg2: Hello World          __hooks:            __pre_validations:            __validations:            __preauths:            __auths:            __pre_ref:            __post_ref:            __on_error:            __finally:      ```   ``` CODE","metadata":{"source":"scripts/gs.json","line":303,"url":"https://docs.godspeed.systems/docs/roadmap#may-pick-up","title":"Roadmap Godspeed Framework Roadmap Q1 and Q2 - 2023 ​  May pick up ​"}},{"pageContent":"CODE ```   ```    __sequence:      - __ref: src.com.abc.a_function      - __parallel:        - __ref: src.com.abc.b_function        - __ref: src.com.abc.c_function    ```   ``` CODE","metadata":{"source":"scripts/gs.json","line":304,"url":"https://docs.godspeed.systems/docs/scaffolding/config-loading","title":"Config Loading  Config Loading"}},{"pageContent":"CODE ```   __sequence:    __args:      items: ${__request.body.items}      as: item_name      __sequence:        - __ref: __if_else # or __sequence or __parallel          __args:            when:              ${__vars.item_name}:                in: ${__config.shop.inventory.unavailable_items}            then:              __ref: __continue # also there is __break        - __ref: com.ecommerce.add_to_invoice # or __sequence or __parallel          __args:            text: ${__vars.item_name}   ``` CODE","metadata":{"source":"scripts/gs.json","line":305,"url":"https://docs.godspeed.systems/docs/scaffolding/config-loading#introduction","title":"Config Loading  Introduction ​"}},{"pageContent":"Written within the project's src folder (DSL, JS or TS functions)  Exported by the modules included in the project (via package.json)","metadata":{"source":"scripts/gs.json","line":306,"url":"https://docs.godspeed.systems/docs/scaffolding/config-loading#way-1-for-simple-and-small-configuration","title":"Config Loading Introduction ​  Way 1: For simple and small configuration ​"}},{"pageContent":"Purpose","metadata":{"source":"scripts/gs.json","line":307,"url":"https://docs.godspeed.systems/docs/scaffolding/config-loading#way-2-for-large-and-complex-configuration","title":"Config Loading Introduction ​  Way 2: For large and complex configuration ​"}},{"pageContent":"All variables created using  CODE ``` __assign ``` CODE  are available under  CODE ``` __vars ``` CODE","metadata":{"source":"scripts/gs.json","line":308,"url":"https://docs.godspeed.systems/docs/scaffolding/config-loading#conclusion","title":"Config Loading Introduction ​  Conclusion ​"}},{"pageContent":"All variables that are part of the project config are present in the  CODE ``` __config ``` CODE  variable","metadata":{"source":"scripts/gs.json","line":309,"url":"https://docs.godspeed.systems/docs/scaffolding/intro","title":"Project structure  Project structure"}},{"pageContent":"The  CODE ``` __src ``` CODE  variables contains every function under source folder(js, ts, yaml). We can access all these functions using the above variable","metadata":{"source":"scripts/gs.json","line":310,"url":"https://docs.godspeed.systems/docs/scaffolding/intro#introduction","title":"Project structure  Introduction ​"}},{"pageContent":"The  CODE ``` __env ``` CODE  variables contains all the environment variables","metadata":{"source":"scripts/gs.json","line":311,"url":"https://docs.godspeed.systems/docs/scaffolding/intro#project-scaffolding-structure","title":"Project structure Introduction ​  Project Scaffolding Structure ​"}},{"pageContent":"The  CODE ``` __response ``` CODE  has object for the incoming data.How to define variables LINK-> ​ #how-to-define-variables <-LINK    CODE ```     __ref: __assign      __name: nested_step      __args:          create_user_url: ${__config.los.urls.create_user}          user_id: ${__response.data.step1.data.user_id}          user_name: ${__request.params.user_name}   ``` CODE             How to use variables LINK-> ​ #how-to-use-variables <-LINK    CODE ```     __summary: Create loan in LOS      __ref: __http_post      __args:        url: ${__vars.step1.code}/${__vars.user_id}/?user_name=${__vars.user_name}        body: # body is {user_name: string, address: string}          user_name:  ${__event.data.body.user_name}          address:  ${__request.body.address}          loan_id: ${__response.step1.data.loan_id}        query:          user_id: ${__vars.user_id}   ``` CODE             ,  config,  src,  modules,  env,  event.data,  response (starting from the first parent span), __args (of the running GS instruction)","metadata":{"source":"scripts/gs.json","line":312,"url":"https://docs.godspeed.systems/docs/scaffolding/intro#defining-api-schema-and-exporting","title":"Project structure Introduction ​  Defining API schema and exporting ​"}},{"pageContent":"CODE ```    com:        pinelabs:          create_account_hdfc:            __summary: Multiplexing create loan for hdfc api calls            __args:              __parallel:              - __name: step1 # the response of this will be accessible within the parent step key, under the step1 sub key                __description: create account in the bank                __ref: __http_post                __args:                  url: ${__config.banks.urls.hdfc.create_user}/${__args.pan}                  body: # body is {user_name: string, address: string}                    user_name:  ${__request.body.user_name}                    address:  ${__request.body.address}                  query:                    user_name: ${__request.query.user_name}                  headers:                    xyz: 2134234                __hooks:                  __on_error:                    - __ref: __log                      __args:                        level:                        data:                          key1: val1                          key2: val2              - __description: create account in our LOS                __name: step2                __sequence:                  - __ref: __assign                    __name: nested_step                    __args:                        create_user_url: ${__config.los.urls.create_user}                        user_id: ${__response.data.step1.data.user_id}                        user_name: ${__request.params.user_name}                  - __summary: Create loan in LOS                    __ref: __http_post                    __args:                      url: ${__vars.step1.code}/${__vars.user_id}/?user_name=${__vars.user_name}                      body: # body is {user_name: string, address: string}                        user_name:  ${__event.data.body.user_name}                        address:  ${__request.body.address}                        loan_id: ${__response.step1.data.loan_id}                      query:                        user_id: ${__vars.user_id}                      headers:                        access_token: ${__env.hdfc_token}                    __hooks:                      __on_error:                        - ${__super.__on_error}                      __finally:                        - ${__super.preauths}                    __on_err:                        __args:                          acceptable: true                          retry:                            count: 3                            interval: 100 #milliseconds                            strategy: incremental_backoff                            onError:                              __ref: *alias_deadqueue_ref                          saga_compensation:                            __ref: __notification__email                              __args:                                #args for compensation                            __on_err:                              __args:                                ignore: true              - __description: send event to message bus of successful loan creation                __name: item_name                __ref: __send_message # For example send the request to MB to notify any consumers that this API has been called on this microservice                  __args:                    topic: com.abc.li.create_loan.success                    body:                      data: ${__request}                    headers:                      custom_header_1: custom_value              - __description: Save in the DB                __ref: __data.insert                __args:                  _type: user                  _id: ${user_id}                    body:                      user_name: ${__vars.user_name}            hooks:              validation:              auths:                - role_permission            __on_error:              __return:     ``` CODE","metadata":{"source":"scripts/gs.json","line":313,"url":"https://docs.godspeed.systems/docs/scaffolding/intro#common-middleware","title":"Project structure Introduction ​  Common middleware ​"}},{"pageContent":"A GSInstruction is a wrapper around actual business logic aka  CODE ``` function or action ``` CODE  or even another GSInstruction. This is a core building block of the Godspeed SDK modules, function DAG composition, and the proposed way of doing things from a flexibility, seperation of concern and dynamism point of view.GSInstruction allows to wrap a set of checks and custom behavior before and after the actual action (an atomic action unit of the business logic). The actual function of a GSInstruction can be written in any language. Except for JS and TS, all other language functions are compiled to Webassembly and run on this framework. GSInstruction also has the finally clause to wrap up before returning from this instruction. Function DAG is also an Instruction comprising of set of Instructions recursively.This  CODE ``` layered design ``` CODE  has following benefits   Separation of concern  Business logic is decoupled from authorizations, validations, auto instrumentation, auto exposing REST/Event interface etc. This can be plugged into any kind of microservice framework, including Godspeed.     Flexibility  It gives developer flexibility to implement different business flows around a common action. This can be across products, A/B tests or tenants. This is achieved by reusing core actions while decorating them with different pre and post hooks. For example   Geo fencing  API monetization  Rate limiting  Tenant specific payload validation    Dynamism:  The pre and post hooks of an Instruction can be dynamically updated (added or removed) by the program,  CODE ``` without restarting the service ``` CODE .     Custom observability:  Add business metrices or any other signals.  GSInstruction Constructor LINK-> ​ #gsinstruction-constructor <-LINK    CODE ```       name: String,        preAuthHooks?: [GSInstruction] // Auto telemetry, custom business logic, pre-loading.        auths?: [GSAssert] //RBAC/ABAC/JWT        onAuthError?:[GSAction] // What to do on error in auths        validations?: [GSAssert | GSL] //GSL when parsed, its command should be implemented via a GSAssert interface        onValidationsError?:[GSAction] // What to do on error in validations        preFunctionHooks: [GSAction]        onPreFunctionHooksError?:[GSAction]  // What to do on error in  PreFunctionHooks        _function: [GSAction]        onFunctionError?:[GSAction] //What to do on error in _functions        postFunctionHooks?: [GSAction] //To act upon error, or success cases.        finally?: [GSAction]   ``` CODE             GSInstruction.execute() LINK-> ​ #gsinstructionexecute <-LINK    CODE ```   // Arguments    ctx: GSContext,    params: JSON   ``` CODE             GSReturn LINK-> ​ #gsreturn <-LINK    CODE ```       res: GSResponse //On successful execution        error: GSError //On Error        events: [GSEvent] //Any events that happened when the instruction was running, in order of occurence. Usefor for Business Process Monitoring.   ``` CODE","metadata":{"source":"scripts/gs.json","line":314,"url":"https://docs.godspeed.systems/docs/security/Auth/intro","title":"Auth Spec  Auth Spec"}},{"pageContent":"CODE ```       code: //An error code extending the standards        message: String        stack: [String]//Stack trace        errors: [GSError]   ``` CODE","metadata":{"source":"scripts/gs.json","line":315,"url":"https://docs.godspeed.systems/docs/security/intro","title":"Introduction  Introduction"}},{"pageContent":"CODE ```       code: //A GS error code extending the standards        message: String        data: Any object or data type   ``` CODE","metadata":{"source":"scripts/gs.json","line":316,"url":"https://docs.godspeed.systems/docs/security/intro#security","title":"Introduction  Security ​"}},{"pageContent":"The GSContext includes all the context specific information like tracing information, actor, environment, headers, payload, shared state (if this ctx is shared with other instruction threads, this part can be shared with them), immutable state (personal copy, personal view, for concurrency) A context has the following properties    CODE ```       data: Any object or data type //All memoized data with shared references. References can have promises or actual data. This is not concurrency safe.        immutable: Any object or data type //For storing and accessing references which are unique to this execution context (for concurrency safety, in the functional programming way).        actor: String //JWT and other user specific info        headers: Object //In case there were any headers with the payload in messagebus or in HTTP        payload: Object //The arguments to include in this function        otel: Any object or data type //OTEL compliant trace/span information   ``` CODE","metadata":{"source":"scripts/gs.json","line":317,"url":"https://docs.godspeed.systems/docs/security/intro#1-code-level-security","title":"Introduction  1. Code Level Security ​"}},{"pageContent":"This is typically a condition check that matches a condition against given data or data promise.   CODE ```   ctx: GSContext    data: JSON | GSDataFetch // Internally GSAssert invokes GSDataFetch.getData() and applies the pass/fail condition to it.    condition: [GSCondition] // to run on the data, evaluating to true or false.   ``` CODE             Returns LINK-> ​ #returns <-LINK On successful assertion LINK-> ​ #on-successful-assertion <-LINK A GSResponse instance with following data\npass: true | falseOn error LINK-> ​ #on-error <-LINK It return a GSError instance","metadata":{"source":"scripts/gs.json","line":318,"url":"https://docs.godspeed.systems/docs/security/intro#2-network","title":"Introduction  2. Network ​"}},{"pageContent":"GSDataFetch.invoke() data or promise of it.GSDataFetch can be a DB/cache fetch instruction  a file fetch instruction  HTTP fetch instruction (Own or third party API)  Data federation instruction  Any kind of a function which returns some data","metadata":{"source":"scripts/gs.json","line":319,"url":"https://docs.godspeed.systems/docs/security/intro#3-data-at-rest--transit","title":"Introduction  3. Data at rest & transit ​"}},{"pageContent":"A GSCondition interface is a function which evaluates to true or false, when supplied with  CODE ``` context ``` CODE  and  CODE ``` data ``` CODE \nThis condition can be GSInstruction  A TS/JS function  JSON schema instruction","metadata":{"source":"scripts/gs.json","line":320,"url":"https://docs.godspeed.systems/docs/security/intro#4-logging","title":"Introduction  4. Logging ​"}},{"pageContent":"You can express and run your business logic with Godspeed microservice or servlerless, in the two basic ways Within the Godspeed framework's runtime  As YAML function DAG (Godspeed DSL)  As JS/TS    In a different runtime (Using any language or framework)  Via HTTP, gRpc or event interface    The two basic concepts to learn here are functions and events","metadata":{"source":"scripts/gs.json","line":321,"url":"https://docs.godspeed.systems/docs/security/intro#5-cache","title":"Introduction  5. Cache ​"}},{"pageContent":"The Godspeed framework's runtime has capability to execute a function DAG written in the Godspeed DSL, or in JS/TS. Both kinds of business logic expressions are executed by Godspeed, as  LINK-> GSInstruction /docs/writing-business-logic/functions <-LINK .The framework patches in and executes the business logic as GSInstructions which also provide middleware hooking mechanism. This decouples the function logic and middleware from the runtime environment. When patched into a microservice, the function gets automatically exposed through REST, event driven and socket interfaces, based on the api schema settings. There is a standard way to define and patch business logic and middleware into a Godspeed microservice or in serverless workflows, during both the process load time and run time.","metadata":{"source":"scripts/gs.json","line":322,"url":"https://docs.godspeed.systems/docs/security/intro#6-documents","title":"Introduction  6. Documents ​"}},{"pageContent":"Use Godspeed CLI to generate the folder template (scaffolding) for a project. Import other modules in the project, as per the templating specifications.  Write your business logic in YAML DSL or JS/TS, in the scaffolded module directory.  Modify the microservice config including which namespace/functions of this project are to be exposed as REST/Event endpoints, with query validations.  Start the Godspeed service specifying the path to the project folder.","metadata":{"source":"scripts/gs.json","line":323,"url":"https://docs.godspeed.systems/docs/security/intro#7-vaults","title":"Introduction  7. Vaults ​"}},{"pageContent":"Documentation for Godspeed LINK-> Godspeed Tutorial - 5min ⏱️ /docs/preface <-LINK","metadata":{"source":"scripts/gs.json","line":324,"url":"https://docs.godspeed.systems/docs/serverless%20workflows/intro","title":"Essential 3: (Serverless) Workflow engine  Essential 3: (Serverless) Workflow engine"}},{"pageContent":"Docusaurus was designed from the ground up to be easily installed and used to get your website up and running quickly.","metadata":{"source":"scripts/gs.json","line":325,"url":"https://docs.godspeed.systems/docs/serverless%20workflows/technology-used/intro","title":"Technologies used (Default)  Technologies used (Default)"}},{"pageContent":"Docusaurus lets you focus on your docs, and we'll do the chores. Go ahead and move your docs into the  CODE ``` docs ``` CODE  directory.","metadata":{"source":"scripts/gs.json","line":326,"url":"https://docs.godspeed.systems/docs/springboot-integration/intro","title":"Godspeed Integration with SpringBoot  Godspeed Integration with SpringBoot"}},{"pageContent":"Extend or customize your website layout by reusing React. Docusaurus can be extended while reusing the same header and footer.","metadata":{"source":"scripts/gs.json","line":327,"url":"https://docs.godspeed.systems/docs/springboot-integration/intro#options-for-the-springboot-world","title":"Godspeed Integration with SpringBoot  Options for the Springboot world ​"}}]